{"related-to": {"precision": 0.31359649122807015, "recall": 0.34541062801932365, "f1-score": 0.328735632183908, "support": 414}, "artifact": {"precision": 0.8163841807909604, "recall": 0.9102362204724409, "f1-score": 0.8607594936708861, "support": 635}, "cause-effect": {"precision": 0.0, "recall": 0.0, "f1-score": 0.0, "support": 86}, "compare": {"precision": 0.7647058823529411, "recall": 0.15853658536585366, "f1-score": 0.26262626262626265, "support": 82}, "general-affiliation": {"precision": 0.7372311827956989, "recall": 0.8853914447134786, "f1-score": 0.8045471213788045, "support": 1239}, "named": {"precision": 0.8518518518518519, "recall": 0.6182795698924731, "f1-score": 0.7165109034267911, "support": 558}, "opposite": {"precision": 0.0, "recall": 0.0, "f1-score": 0.0, "support": 128}, "origin": {"precision": 0.5, "recall": 0.3157894736842105, "f1-score": 0.3870967741935484, "support": 304}, "part-of": {"precision": 0.3356401384083045, "recall": 0.40360610263522884, "f1-score": 0.3664987405541562, "support": 721}, "physical": {"precision": 0.7707602339181286, "recall": 0.9058419243986254, "f1-score": 0.8328593996840442, "support": 1455}, "role": {"precision": 0.6413255360623782, "recall": 0.6560319042871385, "f1-score": 0.6485953671759487, "support": 2006}, "social": {"precision": 0.5135135135135135, "recall": 0.18095238095238095, "f1-score": 0.2676056338028169, "support": 105}, "temporal": {"precision": 0.823728813559322, "recall": 0.5955882352941176, "f1-score": 0.6913229018492176, "support": 408}, "topic": {"precision": 0.6, "recall": 0.03529411764705882, "f1-score": 0.06666666666666667, "support": 170}, "type-of": {"precision": 0.8194444444444444, "recall": 0.35119047619047616, "f1-score": 0.49166666666666675, "support": 336}, "usage": {"precision": 0.6545454545454545, "recall": 0.18, "f1-score": 0.2823529411764706, "support": 200}, "win-defeat": {"precision": 0.7894736842105263, "recall": 0.5678233438485805, "f1-score": 0.6605504587155964, "support": 317}, "micro avg": {"precision": 0.6690124596215967, "recall": 0.6328022697512004, "f1-score": 0.6504037685060565, "support": 9164}, "macro avg": {"precision": 0.584247141628329, "recall": 0.41823367102361103, "f1-score": 0.45108205669245793, "support": 9164}, "weighted avg": {"precision": 0.6602094190106399, "recall": 0.6328022697512004, "f1-score": 0.6272625107066633, "support": 9164}, "samples avg": {"precision": 0.6690124596215967, "recall": 0.6436317489616982, "f1-score": 0.652072758037225, "support": 9164}}