{
    "seeds": [
        4012,
        5096,
        8857,
        8878,
        9908
    ],
    "average": {
        "related-to": {
            "precision": 0.17950208561824743,
            "recall": 0.20067744146691516,
            "f1-score": 0.15438096672107657,
            "support": 2070
        },
        "artifact": {
            "precision": 0.6376144962593558,
            "recall": 0.7683376326595839,
            "f1-score": 0.6723709778495823,
            "support": 3175
        },
        "cause-effect": {
            "precision": 0.0,
            "recall": 0.0,
            "f1-score": 0.0,
            "support": 430
        },
        "compare": {
            "precision": 0.0,
            "recall": 0.0,
            "f1-score": 0.0,
            "support": 410
        },
        "general-affiliation": {
            "precision": 0.4727195429610435,
            "recall": 0.5846406532686517,
            "f1-score": 0.48731942074315215,
            "support": 6195
        },
        "named": {
            "precision": 0.5631111237719582,
            "recall": 0.6700415121139931,
            "f1-score": 0.5867271549906148,
            "support": 2790
        },
        "opposite": {
            "precision": 0.26774531024531023,
            "recall": 0.05363839514782911,
            "f1-score": 0.0778192174067083,
            "support": 640
        },
        "origin": {
            "precision": 0.3850291984957469,
            "recall": 0.2228839401221851,
            "f1-score": 0.2573138976951085,
            "support": 1520
        },
        "part-of": {
            "precision": 0.22178618864227023,
            "recall": 0.24347315089721627,
            "f1-score": 0.21137694210555216,
            "support": 3605
        },
        "physical": {
            "precision": 0.7385160626038759,
            "recall": 0.8347603987493768,
            "f1-score": 0.7748464381077674,
            "support": 7275
        },
        "role": {
            "precision": 0.5935446300360642,
            "recall": 0.585363790762756,
            "f1-score": 0.5760605905846454,
            "support": 10030
        },
        "social": {
            "precision": 0.2829771241830065,
            "recall": 0.10273556231003038,
            "f1-score": 0.1029015865543091,
            "support": 525
        },
        "temporal": {
            "precision": 0.45856873361921746,
            "recall": 0.636349576983352,
            "f1-score": 0.4375310066902891,
            "support": 2040
        },
        "topic": {
            "precision": 0.1431908831908832,
            "recall": 0.04586913086913087,
            "f1-score": 0.05220612449919752,
            "support": 850
        },
        "type-of": {
            "precision": 0.5733991566519081,
            "recall": 0.26224305106658047,
            "f1-score": 0.31137316742366494,
            "support": 1680
        },
        "usage": {
            "precision": 0.0,
            "recall": 0.0,
            "f1-score": 0.0,
            "support": 1000
        },
        "win-defeat": {
            "precision": 0.6328009355174053,
            "recall": 0.38896489193535927,
            "f1-score": 0.42315549669118513,
            "support": 1585
        },
        "micro avg": {
            "precision": 0.549658363883917,
            "recall": 0.5243395184454025,
            "f1-score": 0.5363783940031783,
            "support": 45820
        },
        "macro avg": {
            "precision": 999999.0,
            "recall": 999999.0,
            "f1-score": 0.3121897139993222,
            "support": 45820
        },
        "weighted avg": {
            "precision": 0.5442505713414059,
            "recall": 0.5243395184454025,
            "f1-score": 0.5060708703236594,
            "support": 45820
        },
        "samples avg": {
            "precision": 0.549658363883917,
            "recall": 0.5296814367018963,
            "f1-score": 0.5363202850139959,
            "support": 45820
        }
    },
    "ai": {
        "related-to": {
            "precision": 0.28134291339397866,
            "recall": 0.5777777777777777,
            "f1-score": 0.376040255137854,
            "support": 108.0
        },
        "artifact": {
            "precision": 0.5593706684823578,
            "recall": 0.6195121951219512,
            "f1-score": 0.5816102589891878,
            "support": 41.0
        },
        "cause-effect": {
            "precision": 0.0,
            "recall": 0.0,
            "f1-score": 0.0,
            "support": 5.0
        },
        "compare": {
            "precision": 0.0,
            "recall": 0.0,
            "f1-score": 0.0,
            "support": 24.0
        },
        "general-affiliation": {
            "precision": 0.1341211353658162,
            "recall": 0.328,
            "f1-score": 0.1855786495380712,
            "support": 75.0
        },
        "named": {
            "precision": 0.6565864826705106,
            "recall": 0.7467625899280577,
            "f1-score": 0.694915753265272,
            "support": 139.0
        },
        "opposite": {
            "precision": 0.4,
            "recall": 0.09090909090909091,
            "f1-score": 0.13753501400560225,
            "support": 11.0
        },
        "origin": {
            "precision": 0.5824815629264568,
            "recall": 0.26741573033707866,
            "f1-score": 0.34724842941611234,
            "support": 89.0
        },
        "part-of": {
            "precision": 0.34297379248582766,
            "recall": 0.35887850467289717,
            "f1-score": 0.34363101917240707,
            "support": 214.0
        },
        "physical": {
            "precision": 0.8093567293484334,
            "recall": 0.8705882352941176,
            "f1-score": 0.8363889695044296,
            "support": 102.0
        },
        "role": {
            "precision": 0.5952237069579439,
            "recall": 0.6513761467889908,
            "f1-score": 0.6185597261549228,
            "support": 109.0
        },
        "social": {
            "precision": 0.04,
            "recall": 0.2,
            "f1-score": 0.06666666666666668,
            "support": 1.0
        },
        "temporal": {
            "precision": 0.2752380952380952,
            "recall": 0.05714285714285714,
            "f1-score": 0.09372161172161173,
            "support": 21.0
        },
        "topic": {
            "precision": 0.0,
            "recall": 0.0,
            "f1-score": 0.0,
            "support": 41.0
        },
        "type-of": {
            "precision": 0.0,
            "recall": 0.0,
            "f1-score": 0.0,
            "support": 54.0
        },
        "usage": {
            "precision": 0.0,
            "recall": 0.0,
            "f1-score": 0.0,
            "support": 122.0
        },
        "win-defeat": {
            "precision": 0.8,
            "recall": 0.2857142857142857,
            "f1-score": 0.4082051282051283,
            "support": 7.0
        },
        "micro avg": {
            "precision": 0.42679680567879325,
            "recall": 0.413585554600172,
            "f1-score": 0.4200873362445415,
            "support": 1163.0
        },
        "macro avg": {
            "precision": 999999.0,
            "recall": 999999.0,
            "f1-score": 0.27588832245748623,
            "support": 1163.0
        },
        "weighted avg": {
            "precision": 0.38102739418945947,
            "recall": 0.413585554600172,
            "f1-score": 0.37708687146883796,
            "support": 1163.0
        },
        "samples avg": {
            "precision": 0.42679680567879325,
            "recall": 0.41555752735876955,
            "f1-score": 0.4192546583850931,
            "support": 1163.0
        }
    },
    "literature": {
        "related-to": {
            "precision": 0.18853383458646616,
            "recall": 0.07777777777777778,
            "f1-score": 0.10803436244713722,
            "support": 72.0
        },
        "artifact": {
            "precision": 0.7533023745241572,
            "recall": 0.7873333333333334,
            "f1-score": 0.7684921857719769,
            "support": 300.0
        },
        "cause-effect": {
            "precision": 0.0,
            "recall": 0.0,
            "f1-score": 0.0,
            "support": 1.0
        },
        "compare": {
            "precision": 0.0,
            "recall": 0.0,
            "f1-score": 0.0,
            "support": 8.0
        },
        "general-affiliation": {
            "precision": 0.8595429956276289,
            "recall": 0.7195121951219512,
            "f1-score": 0.7786462360044537,
            "support": 328.0
        },
        "named": {
            "precision": 0.6607511215376384,
            "recall": 0.5340425531914893,
            "f1-score": 0.5844933459497342,
            "support": 94.0
        },
        "opposite": {
            "precision": 0.4087445887445888,
            "recall": 0.15714285714285714,
            "f1-score": 0.21730075187969922,
            "support": 14.0
        },
        "origin": {
            "precision": 0.18935191304986415,
            "recall": 0.31489361702127655,
            "f1-score": 0.23571406515362053,
            "support": 47.0
        },
        "part-of": {
            "precision": 0.24661688311688318,
            "recall": 0.22708333333333336,
            "f1-score": 0.22634313990103463,
            "support": 96.0
        },
        "physical": {
            "precision": 0.7810323956036376,
            "recall": 0.810344827586207,
            "f1-score": 0.7913032051155978,
            "support": 174.0
        },
        "role": {
            "precision": 0.5073062285709483,
            "recall": 0.7296442687747036,
            "f1-score": 0.597846356853616,
            "support": 253.0
        },
        "social": {
            "precision": 0.5071895424836601,
            "recall": 0.08510638297872339,
            "f1-score": 0.13422619047619047,
            "support": 47.0
        },
        "temporal": {
            "precision": 0.7264285714285714,
            "recall": 0.6413793103448275,
            "f1-score": 0.6740857850975377,
            "support": 29.0
        },
        "topic": {
            "precision": 0.0962962962962963,
            "recall": 0.023809523809523808,
            "f1-score": 0.03207729468599034,
            "support": 42.0
        },
        "type-of": {
            "precision": 0.6458781362007169,
            "recall": 0.6666666666666667,
            "f1-score": 0.6304296093769778,
            "support": 18.0
        },
        "usage": {
            "precision": 0.0,
            "recall": 0.0,
            "f1-score": 0.0,
            "support": 2.0
        },
        "win-defeat": {
            "precision": 0.6757093311047266,
            "recall": 0.7195876288659793,
            "f1-score": 0.6941235910142133,
            "support": 97.0
        },
        "micro avg": {
            "precision": 0.6275471698113206,
            "recall": 0.6151664611590628,
            "f1-score": 0.6212951432129514,
            "support": 1622.0
        },
        "macro avg": {
            "precision": 999999.0,
            "recall": 999999.0,
            "f1-score": 0.3807715364545753,
            "support": 1622.0
        },
        "weighted avg": {
            "precision": 0.6240872670269549,
            "recall": 0.6151664611590628,
            "f1-score": 0.6037843126657352,
            "support": 1622.0
        },
        "samples avg": {
            "precision": 0.6275471698113206,
            "recall": 0.620754716981132,
            "f1-score": 0.6230188679245282,
            "support": 1622.0
        }
    },
    "music": {
        "related-to": {
            "precision": 0.0039603960396039604,
            "recall": 0.015384615384615385,
            "f1-score": 0.006299212598425197,
            "support": 26.0
        },
        "artifact": {
            "precision": 0.709930462821289,
            "recall": 0.9196911196911197,
            "f1-score": 0.8000463909774153,
            "support": 259.0
        },
        "cause-effect": {
            "precision": 0.0,
            "recall": 0.0,
            "f1-score": 0.0,
            "support": 4.0
        },
        "compare": {
            "precision": 0.0,
            "recall": 0.0,
            "f1-score": 0.0,
            "support": 5.0
        },
        "general-affiliation": {
            "precision": 0.8537609634255994,
            "recall": 0.7963988919667591,
            "f1-score": 0.8227699343032018,
            "support": 722.0
        },
        "named": {
            "precision": 0.6758689309056957,
            "recall": 0.5686746987951807,
            "f1-score": 0.6122482068495372,
            "support": 83.0
        },
        "opposite": {
            "precision": 0.05,
            "recall": 0.03333333333333333,
            "f1-score": 0.04,
            "support": 6.0
        },
        "origin": {
            "precision": 0.27426470588235297,
            "recall": 0.10526315789473684,
            "f1-score": 0.13781918564527257,
            "support": 19.0
        },
        "part-of": {
            "precision": 0.2462160888600426,
            "recall": 0.17386363636363636,
            "f1-score": 0.1961032116884264,
            "support": 176.0
        },
        "physical": {
            "precision": 0.8116156651229984,
            "recall": 0.8450839328537171,
            "f1-score": 0.8275274014646186,
            "support": 417.0
        },
        "role": {
            "precision": 0.6027997320843617,
            "recall": 0.6575197889182058,
            "f1-score": 0.6248878125520942,
            "support": 379.0
        },
        "social": {
            "precision": 0.19,
            "recall": 0.1,
            "f1-score": 0.13088235294117648,
            "support": 22.0
        },
        "temporal": {
            "precision": 0.38642914916206844,
            "recall": 0.775,
            "f1-score": 0.5133384852603584,
            "support": 24.0
        },
        "topic": {
            "precision": 0.21965811965811968,
            "recall": 0.175,
            "f1-score": 0.17221288515406163,
            "support": 8.0
        },
        "type-of": {
            "precision": 0.9730224089635854,
            "recall": 0.4689075630252101,
            "f1-score": 0.6307115508925463,
            "support": 119.0
        },
        "usage": {
            "precision": 0.0,
            "recall": 0.0,
            "f1-score": 0.0,
            "support": 52.0
        },
        "win-defeat": {
            "precision": 0.6553394101452727,
            "recall": 0.7290322580645162,
            "f1-score": 0.6828814954987426,
            "support": 93.0
        },
        "micro avg": {
            "precision": 0.7036878216123499,
            "recall": 0.679784589892295,
            "f1-score": 0.6915297092288242,
            "support": 2414.0
        },
        "macro avg": {
            "precision": 999999.0,
            "recall": 999999.0,
            "f1-score": 0.3645722426956398,
            "support": 2414.0
        },
        "weighted avg": {
            "precision": 0.6893890576805826,
            "recall": 0.679784589892295,
            "f1-score": 0.6738427165734585,
            "support": 2414.0
        },
        "samples avg": {
            "precision": 0.7036878216123499,
            "recall": 0.6898799313893653,
            "f1-score": 0.6944110920526015,
            "support": 2414.0
        }
    },
    "news": {
        "related-to": {
            "precision": 0.06666666666666667,
            "recall": 0.03333333333333333,
            "f1-score": 0.04444444444444444,
            "support": 6.0
        },
        "artifact": {
            "precision": 0,
            "recall": 0,
            "f1-score": 0,
            "support": 0
        },
        "cause-effect": {
            "precision": 0,
            "recall": 0,
            "f1-score": 0,
            "support": 0
        },
        "compare": {
            "precision": 0,
            "recall": 0,
            "f1-score": 0,
            "support": 0
        },
        "general-affiliation": {
            "precision": 0.4342857142857143,
            "recall": 0.36000000000000004,
            "f1-score": 0.38364145658263304,
            "support": 10.0
        },
        "named": {
            "precision": 0.2433760683760684,
            "recall": 0.65,
            "f1-score": 0.34149732620320855,
            "support": 4.0
        },
        "opposite": {
            "precision": 0.4,
            "recall": 0.010256410256410256,
            "f1-score": 0.02,
            "support": 39.0
        },
        "origin": {
            "precision": 0,
            "recall": 0,
            "f1-score": 0,
            "support": 0
        },
        "part-of": {
            "precision": 0.11282051282051282,
            "recall": 0.03571428571428571,
            "f1-score": 0.05279770444763271,
            "support": 28.0
        },
        "physical": {
            "precision": 0.5573344855278359,
            "recall": 0.7953488372093023,
            "f1-score": 0.6496423057263826,
            "support": 129.0
        },
        "role": {
            "precision": 0.5493301242422335,
            "recall": 0.5375,
            "f1-score": 0.5363941907571033,
            "support": 144.0
        },
        "social": {
            "precision": 0,
            "recall": 0,
            "f1-score": 0,
            "support": 0
        },
        "temporal": {
            "precision": 0.027265201955604435,
            "recall": 1.0,
            "f1-score": 0.053078506146542095,
            "support": 1.0
        },
        "topic": {
            "precision": 0,
            "recall": 0,
            "f1-score": 0,
            "support": 0
        },
        "type-of": {
            "precision": 0,
            "recall": 0,
            "f1-score": 0,
            "support": 0
        },
        "usage": {
            "precision": 0,
            "recall": 0,
            "f1-score": 0,
            "support": 0
        },
        "win-defeat": {
            "precision": 0.13333333333333333,
            "recall": 0.011428571428571429,
            "f1-score": 0.021052631578947368,
            "support": 35.0
        },
        "micro avg": {
            "precision": 0.47777777777777775,
            "recall": 0.47777777777777775,
            "f1-score": 0.47777777777777775,
            "support": 396.0
        },
        "macro avg": {
            "precision": 999999.0,
            "recall": 999999.0,
            "f1-score": 0.23361650732076597,
            "support": 396.0
        },
        "weighted avg": {
            "precision": 0.45497210648467307,
            "recall": 0.47777777777777775,
            "f1-score": 0.428186736820645,
            "support": 396.0
        },
        "samples avg": {
            "precision": 0.47777777777777775,
            "recall": 0.47777777777777775,
            "f1-score": 0.47777777777777775,
            "support": 396.0
        }
    },
    "politics": {
        "related-to": {
            "precision": 0.2564499484004128,
            "recall": 0.039473684210526314,
            "f1-score": 0.05537898005276835,
            "support": 76.0
        },
        "artifact": {
            "precision": 0.3511111111111111,
            "recall": 0.8,
            "f1-score": 0.45939393939393947,
            "support": 2.0
        },
        "cause-effect": {
            "precision": 0,
            "recall": 0,
            "f1-score": 0,
            "support": 0
        },
        "compare": {
            "precision": 0.0,
            "recall": 0.0,
            "f1-score": 0.0,
            "support": 6.0
        },
        "general-affiliation": {
            "precision": 0.25726676898717515,
            "recall": 0.7806451612903226,
            "f1-score": 0.38134419759412336,
            "support": 31.0
        },
        "named": {
            "precision": 0.6435979374867095,
            "recall": 0.7707692307692307,
            "f1-score": 0.6931053000205567,
            "support": 130.0
        },
        "opposite": {
            "precision": 0.3477272727272728,
            "recall": 0.03018867924528302,
            "f1-score": 0.05207953855494839,
            "support": 53.0
        },
        "origin": {
            "precision": 0.32206438510068275,
            "recall": 0.1672727272727273,
            "f1-score": 0.21627052794985513,
            "support": 55.0
        },
        "part-of": {
            "precision": 0.26740576196530047,
            "recall": 0.3230769230769231,
            "f1-score": 0.28087706858932276,
            "support": 117.0
        },
        "physical": {
            "precision": 0.636158621075149,
            "recall": 0.945232273838631,
            "f1-score": 0.7598206698724541,
            "support": 409.0
        },
        "role": {
            "precision": 0.7452633450549074,
            "recall": 0.4613173652694611,
            "f1-score": 0.5667464930021155,
            "support": 835.0
        },
        "social": {
            "precision": 0.5875,
            "recall": 0.08571428571428572,
            "f1-score": 0.1333968593099028,
            "support": 21.0
        },
        "temporal": {
            "precision": 0.8510436319929809,
            "recall": 0.6214983713355048,
            "f1-score": 0.7148433918386148,
            "support": 307.0
        },
        "topic": {
            "precision": 0.2,
            "recall": 0.015384615384615385,
            "f1-score": 0.028571428571428574,
            "support": 13.0
        },
        "type-of": {
            "precision": 0.7814285714285714,
            "recall": 0.15,
            "f1-score": 0.2490007215007215,
            "support": 28.0
        },
        "usage": {
            "precision": 0,
            "recall": 0,
            "f1-score": 0,
            "support": 0
        },
        "win-defeat": {
            "precision": 0.6,
            "recall": 0.024390243902439025,
            "f1-score": 0.04632034632034632,
            "support": 41.0
        },
        "micro avg": {
            "precision": 0.6266521026761331,
            "recall": 0.5402071563088512,
            "f1-score": 0.580227560050569,
            "support": 2124.0
        },
        "macro avg": {
            "precision": 999999.0,
            "recall": 999999.0,
            "f1-score": 0.3091432975047398,
            "support": 2124.0
        },
        "weighted avg": {
            "precision": 0.6518063300188229,
            "recall": 0.5402071563088512,
            "f1-score": 0.550881108777608,
            "support": 2124.0
        },
        "samples avg": {
            "precision": 0.6266521026761331,
            "recall": 0.5572364827962861,
            "f1-score": 0.5803750227562352,
            "support": 2124.0
        }
    },
    "science": {
        "related-to": {
            "precision": 0.28005875462235635,
            "recall": 0.4603174603174603,
            "f1-score": 0.3360885456458302,
            "support": 126.0
        },
        "artifact": {
            "precision": 0.8143578643578643,
            "recall": 0.7151515151515152,
            "f1-score": 0.7523121141153928,
            "support": 33.0
        },
        "cause-effect": {
            "precision": 0.0,
            "recall": 0.0,
            "f1-score": 0.0,
            "support": 76.0
        },
        "compare": {
            "precision": 0.0,
            "recall": 0.0,
            "f1-score": 0.0,
            "support": 39.0
        },
        "general-affiliation": {
            "precision": 0.2973396800743274,
            "recall": 0.5232876712328767,
            "f1-score": 0.3719360504364297,
            "support": 73.0
        },
        "named": {
            "precision": 0.49848620165512675,
            "recall": 0.75,
            "f1-score": 0.59410299765538,
            "support": 108.0
        },
        "opposite": {
            "precision": 0.0,
            "recall": 0.0,
            "f1-score": 0.0,
            "support": 5.0
        },
        "origin": {
            "precision": 0.5569834255193781,
            "recall": 0.25957446808510637,
            "f1-score": 0.34951728031068174,
            "support": 94.0
        },
        "part-of": {
            "precision": 0.11468409260505472,
            "recall": 0.3422222222222222,
            "f1-score": 0.1685095088344895,
            "support": 90.0
        },
        "physical": {
            "precision": 0.8355984789452012,
            "recall": 0.7419642857142856,
            "f1-score": 0.7843960769631219,
            "support": 224.0
        },
        "role": {
            "precision": 0.5613446433059903,
            "recall": 0.47482517482517483,
            "f1-score": 0.5119289641880205,
            "support": 286.0
        },
        "social": {
            "precision": 0.09019607843137253,
            "recall": 0.04285714285714286,
            "f1-score": 0.04933586337760911,
            "support": 14.0
        },
        "temporal": {
            "precision": 0.48500775193798445,
            "recall": 0.723076923076923,
            "f1-score": 0.5761182600770702,
            "support": 26.0
        },
        "topic": {
            "precision": 0.2,
            "recall": 0.015151515151515152,
            "f1-score": 0.028169014084507043,
            "support": 66.0
        },
        "type-of": {
            "precision": 0.4666666666666667,
            "recall": 0.02564102564102564,
            "f1-score": 0.046723955348079174,
            "support": 117.0
        },
        "usage": {
            "precision": 0.0,
            "recall": 0.0,
            "f1-score": 0.0,
            "support": 24.0
        },
        "win-defeat": {
            "precision": 0.9324235385210995,
            "recall": 0.5636363636363637,
            "f1-score": 0.6863497875297324,
            "support": 44.0
        },
        "micro avg": {
            "precision": 0.4354885057471264,
            "recall": 0.41951557093425607,
            "f1-score": 0.42735283750440606,
            "support": 1445.0
        },
        "macro avg": {
            "precision": 999999.0,
            "recall": 999999.0,
            "f1-score": 0.30914637756272606,
            "support": 1445.0
        },
        "weighted avg": {
            "precision": 0.4642212726479419,
            "recall": 0.41951557093425607,
            "f1-score": 0.4026434756356717,
            "support": 1445.0
        },
        "samples avg": {
            "precision": 0.4354885057471264,
            "recall": 0.416882183908046,
            "f1-score": 0.4230842911877395,
            "support": 1445.0
        }
    }
}