{
    "seeds": [
        4012,
        5096,
        8857,
        8878,
        9908
    ],
    "average": {
        "related-to": {
            "precision": 0.1556507958207668,
            "recall": 0.18961845496933216,
            "f1-score": 0.1551493719377396,
            "support": 2070
        },
        "artifact": {
            "precision": 0.6085910190149771,
            "recall": 0.7623361179361179,
            "f1-score": 0.6542949923783886,
            "support": 3175
        },
        "cause-effect": {
            "precision": 0.0,
            "recall": 0.0,
            "f1-score": 0.0,
            "support": 430
        },
        "compare": {
            "precision": 0.0,
            "recall": 0.0,
            "f1-score": 0.0,
            "support": 410
        },
        "general-affiliation": {
            "precision": 0.4540183624074059,
            "recall": 0.5016152854444635,
            "f1-score": 0.4432143853679483,
            "support": 6195
        },
        "named": {
            "precision": 0.5628072813598326,
            "recall": 0.7031360204321266,
            "f1-score": 0.5956842242253361,
            "support": 2790
        },
        "opposite": {
            "precision": 0.20513227513227514,
            "recall": 0.0445261866016583,
            "f1-score": 0.06473531209762302,
            "support": 640
        },
        "origin": {
            "precision": 0.37132105047722147,
            "recall": 0.21695559264143888,
            "f1-score": 0.26284224993049865,
            "support": 1520
        },
        "part-of": {
            "precision": 0.27261972678346535,
            "recall": 0.20796812524616262,
            "f1-score": 0.2047209895706888,
            "support": 3605
        },
        "physical": {
            "precision": 0.7321547575945636,
            "recall": 0.8849380496653133,
            "f1-score": 0.7843224178843942,
            "support": 7275
        },
        "role": {
            "precision": 0.6040966885189807,
            "recall": 0.5757339410051879,
            "f1-score": 0.5725496484139287,
            "support": 10030
        },
        "social": {
            "precision": 0.32011017740429504,
            "recall": 0.10385189278806299,
            "f1-score": 0.12715243333215684,
            "support": 525
        },
        "temporal": {
            "precision": 0.5068398071891718,
            "recall": 0.6761012188480457,
            "f1-score": 0.5128855594213768,
            "support": 2040
        },
        "topic": {
            "precision": 0.16504761904761905,
            "recall": 0.024678654678654675,
            "f1-score": 0.03767464612702818,
            "support": 850
        },
        "type-of": {
            "precision": 0.564592846454636,
            "recall": 0.24838253250017953,
            "f1-score": 0.3166668271990315,
            "support": 1680
        },
        "usage": {
            "precision": 0.0,
            "recall": 0.0,
            "f1-score": 0.0,
            "support": 1000
        },
        "win-defeat": {
            "precision": 0.48511983893890387,
            "recall": 0.4420434459226059,
            "f1-score": 0.4438179975746556,
            "support": 1585
        },
        "micro avg": {
            "precision": 0.542742541876315,
            "recall": 0.5170703867090785,
            "f1-score": 0.5292706854419907,
            "support": 45820
        },
        "macro avg": {
            "precision": 999999.0,
            "recall": 999999.0,
            "f1-score": 0.31798267679166015,
            "support": 45820
        },
        "weighted avg": {
            "precision": 0.5258002131133167,
            "recall": 0.5170703867090785,
            "f1-score": 0.48855296830489436,
            "support": 45820
        },
        "samples avg": {
            "precision": 0.542742541876315,
            "recall": 0.5223010147477005,
            "f1-score": 0.5290924003352663,
            "support": 45820
        }
    },
    "ai": {
        "related-to": {
            "precision": 0.28364406228178485,
            "recall": 0.412962962962963,
            "f1-score": 0.33589248766569246,
            "support": 108.0
        },
        "artifact": {
            "precision": 0.40880039190384015,
            "recall": 0.4,
            "f1-score": 0.3911009492503418,
            "support": 41.0
        },
        "cause-effect": {
            "precision": 0.0,
            "recall": 0.0,
            "f1-score": 0.0,
            "support": 5.0
        },
        "compare": {
            "precision": 0.0,
            "recall": 0.0,
            "f1-score": 0.0,
            "support": 24.0
        },
        "general-affiliation": {
            "precision": 0.134449149487433,
            "recall": 0.2693333333333333,
            "f1-score": 0.16284850610120008,
            "support": 75.0
        },
        "named": {
            "precision": 0.5326696155135712,
            "recall": 0.7985611510791366,
            "f1-score": 0.628744339328,
            "support": 139.0
        },
        "opposite": {
            "precision": 0.6,
            "recall": 0.10909090909090909,
            "f1-score": 0.1805860805860806,
            "support": 11.0
        },
        "origin": {
            "precision": 0.4909111439599244,
            "recall": 0.25617977528089886,
            "f1-score": 0.33448831788366673,
            "support": 89.0
        },
        "part-of": {
            "precision": 0.30892986184944504,
            "recall": 0.33364485981308406,
            "f1-score": 0.3122072604045764,
            "support": 214.0
        },
        "physical": {
            "precision": 0.7931847811342039,
            "recall": 0.8647058823529413,
            "f1-score": 0.8266082766228802,
            "support": 102.0
        },
        "role": {
            "precision": 0.5973640101201771,
            "recall": 0.655045871559633,
            "f1-score": 0.6206563398537419,
            "support": 109.0
        },
        "social": {
            "precision": 0.0,
            "recall": 0.0,
            "f1-score": 0.0,
            "support": 1.0
        },
        "temporal": {
            "precision": 0.4632367149758455,
            "recall": 0.3904761904761905,
            "f1-score": 0.4153323099664563,
            "support": 21.0
        },
        "topic": {
            "precision": 0.0,
            "recall": 0.0,
            "f1-score": 0.0,
            "support": 41.0
        },
        "type-of": {
            "precision": 0.0,
            "recall": 0.0,
            "f1-score": 0.0,
            "support": 54.0
        },
        "usage": {
            "precision": 0.0,
            "recall": 0.0,
            "f1-score": 0.0,
            "support": 122.0
        },
        "win-defeat": {
            "precision": 0.43666666666666665,
            "recall": 0.5428571428571429,
            "f1-score": 0.4623041561122056,
            "support": 7.0
        },
        "micro avg": {
            "precision": 0.40745341614906827,
            "recall": 0.3948409286328461,
            "f1-score": 0.4010480349344978,
            "support": 1163.0
        },
        "macro avg": {
            "precision": 999999.0,
            "recall": 999999.0,
            "f1-score": 0.274751119045579,
            "support": 1163.0
        },
        "weighted avg": {
            "precision": 0.34971915930403796,
            "recall": 0.3948409286328461,
            "f1-score": 0.35633068140815655,
            "support": 1163.0
        },
        "samples avg": {
            "precision": 0.40745341614906827,
            "recall": 0.3957704821058858,
            "f1-score": 0.3996154983732623,
            "support": 1163.0
        }
    },
    "literature": {
        "related-to": {
            "precision": 0.10782410992306043,
            "recall": 0.03888888888888888,
            "f1-score": 0.05600683102482732,
            "support": 72.0
        },
        "artifact": {
            "precision": 0.6093850952183073,
            "recall": 0.8553333333333333,
            "f1-score": 0.7103989836103123,
            "support": 300.0
        },
        "cause-effect": {
            "precision": 0.0,
            "recall": 0.0,
            "f1-score": 0.0,
            "support": 1.0
        },
        "compare": {
            "precision": 0.0,
            "recall": 0.0,
            "f1-score": 0.0,
            "support": 8.0
        },
        "general-affiliation": {
            "precision": 0.8209198800568857,
            "recall": 0.41280487804878047,
            "f1-score": 0.540809958110218,
            "support": 328.0
        },
        "named": {
            "precision": 0.675789119350701,
            "recall": 0.46170212765957447,
            "f1-score": 0.5329358890029567,
            "support": 94.0
        },
        "opposite": {
            "precision": 0.17936507936507934,
            "recall": 0.07142857142857142,
            "f1-score": 0.09993098688750862,
            "support": 14.0
        },
        "origin": {
            "precision": 0.26834893774861546,
            "recall": 0.2680851063829787,
            "f1-score": 0.26347661949414314,
            "support": 47.0
        },
        "part-of": {
            "precision": 0.16169991953428425,
            "recall": 0.15416666666666665,
            "f1-score": 0.15363926884903178,
            "support": 96.0
        },
        "physical": {
            "precision": 0.7703963261895252,
            "recall": 0.8873563218390805,
            "f1-score": 0.8244273887869962,
            "support": 174.0
        },
        "role": {
            "precision": 0.46988497667165774,
            "recall": 0.750197628458498,
            "f1-score": 0.577169242337525,
            "support": 253.0
        },
        "social": {
            "precision": 0.4,
            "recall": 0.01276595744680851,
            "f1-score": 0.02465986394557823,
            "support": 47.0
        },
        "temporal": {
            "precision": 0.6110366336172788,
            "recall": 0.7655172413793103,
            "f1-score": 0.6748707216619916,
            "support": 29.0
        },
        "topic": {
            "precision": 0.03333333333333333,
            "recall": 0.009523809523809523,
            "f1-score": 0.014814814814814814,
            "support": 42.0
        },
        "type-of": {
            "precision": 0.9349206349206348,
            "recall": 0.5,
            "f1-score": 0.6310185185185185,
            "support": 18.0
        },
        "usage": {
            "precision": 0.0,
            "recall": 0.0,
            "f1-score": 0.0,
            "support": 2.0
        },
        "win-defeat": {
            "precision": 0.6442138493268842,
            "recall": 0.6618556701030928,
            "f1-score": 0.6497034181098342,
            "support": 97.0
        },
        "micro avg": {
            "precision": 0.5705660377358489,
            "recall": 0.5593094944512946,
            "f1-score": 0.5648816936488169,
            "support": 1622.0
        },
        "macro avg": {
            "precision": 999999.0,
            "recall": 999999.0,
            "f1-score": 0.3384625003031916,
            "support": 1622.0
        },
        "weighted avg": {
            "precision": 0.5697772520722881,
            "recall": 0.5593094944512946,
            "f1-score": 0.5292058366779581,
            "support": 1622.0
        },
        "samples avg": {
            "precision": 0.5705660377358489,
            "recall": 0.5636687631027254,
            "f1-score": 0.5659538784067086,
            "support": 1622.0
        }
    },
    "music": {
        "related-to": {
            "precision": 0.03030385487528344,
            "recall": 0.023076923076923078,
            "f1-score": 0.022025062656641604,
            "support": 26.0
        },
        "artifact": {
            "precision": 0.7475952150886906,
            "recall": 0.9351351351351352,
            "f1-score": 0.8270630888968228,
            "support": 259.0
        },
        "cause-effect": {
            "precision": 0.0,
            "recall": 0.0,
            "f1-score": 0.0,
            "support": 4.0
        },
        "compare": {
            "precision": 0.0,
            "recall": 0.0,
            "f1-score": 0.0,
            "support": 5.0
        },
        "general-affiliation": {
            "precision": 0.8368266603897266,
            "recall": 0.8094182825484765,
            "f1-score": 0.8217231716653721,
            "support": 722.0
        },
        "named": {
            "precision": 0.6399591204683591,
            "recall": 0.6216867469879518,
            "f1-score": 0.6211547614352823,
            "support": 83.0
        },
        "opposite": {
            "precision": 0.0,
            "recall": 0.0,
            "f1-score": 0.0,
            "support": 6.0
        },
        "origin": {
            "precision": 0.23966666666666664,
            "recall": 0.12631578947368421,
            "f1-score": 0.1468013468013468,
            "support": 19.0
        },
        "part-of": {
            "precision": 0.2365796946991506,
            "recall": 0.12954545454545455,
            "f1-score": 0.1560143804257462,
            "support": 176.0
        },
        "physical": {
            "precision": 0.865649822792431,
            "recall": 0.9266187050359713,
            "f1-score": 0.8927603376697739,
            "support": 417.0
        },
        "role": {
            "precision": 0.6480697100681332,
            "recall": 0.695514511873351,
            "f1-score": 0.6695456849861829,
            "support": 379.0
        },
        "social": {
            "precision": 0.19206349206349205,
            "recall": 0.06363636363636364,
            "f1-score": 0.08206349206349207,
            "support": 22.0
        },
        "temporal": {
            "precision": 0.37665458895022164,
            "recall": 0.6499999999999999,
            "f1-score": 0.47590834285983225,
            "support": 24.0
        },
        "topic": {
            "precision": 0.09523809523809523,
            "recall": 0.05,
            "f1-score": 0.06303030303030303,
            "support": 8.0
        },
        "type-of": {
            "precision": 0.9439088702909892,
            "recall": 0.4873949579831933,
            "f1-score": 0.6385422617188871,
            "support": 119.0
        },
        "usage": {
            "precision": 0.0,
            "recall": 0.0,
            "f1-score": 0.0,
            "support": 52.0
        },
        "win-defeat": {
            "precision": 0.7071147909881271,
            "recall": 0.7182795698924731,
            "f1-score": 0.7086715899003121,
            "support": 93.0
        },
        "micro avg": {
            "precision": 0.7273584905660377,
            "recall": 0.7026512013256007,
            "f1-score": 0.7147914032869785,
            "support": 2414.0
        },
        "macro avg": {
            "precision": 999999.0,
            "recall": 999999.0,
            "f1-score": 0.3603119896535292,
            "support": 2414.0
        },
        "weighted avg": {
            "precision": 0.7028253723022363,
            "recall": 0.7026512013256007,
            "f1-score": 0.692432901922388,
            "support": 2414.0
        },
        "samples avg": {
            "precision": 0.7273584905660377,
            "recall": 0.7124785591766724,
            "f1-score": 0.7173670668953687,
            "support": 2414.0
        }
    },
    "news": {
        "related-to": {
            "precision": 0.09333333333333334,
            "recall": 0.13333333333333333,
            "f1-score": 0.10046620046620044,
            "support": 6.0
        },
        "artifact": {
            "precision": 0,
            "recall": 0,
            "f1-score": 0,
            "support": 0
        },
        "cause-effect": {
            "precision": 0,
            "recall": 0,
            "f1-score": 0,
            "support": 0
        },
        "compare": {
            "precision": 0,
            "recall": 0,
            "f1-score": 0,
            "support": 0
        },
        "general-affiliation": {
            "precision": 0.25348390739695087,
            "recall": 0.38,
            "f1-score": 0.29743108504398824,
            "support": 10.0
        },
        "named": {
            "precision": 0.54,
            "recall": 0.75,
            "f1-score": 0.6166666666666666,
            "support": 4.0
        },
        "opposite": {
            "precision": 0.1,
            "recall": 0.005128205128205128,
            "f1-score": 0.009756097560975608,
            "support": 39.0
        },
        "origin": {
            "precision": 0,
            "recall": 0,
            "f1-score": 0,
            "support": 0
        },
        "part-of": {
            "precision": 0.4992424242424242,
            "recall": 0.12857142857142856,
            "f1-score": 0.19128205128205128,
            "support": 28.0
        },
        "physical": {
            "precision": 0.4806717190265937,
            "recall": 0.9798449612403101,
            "f1-score": 0.6444000203838858,
            "support": 129.0
        },
        "role": {
            "precision": 0.525943215563898,
            "recall": 0.2847222222222222,
            "f1-score": 0.36824608663099917,
            "support": 144.0
        },
        "social": {
            "precision": 0,
            "recall": 0,
            "f1-score": 0,
            "support": 0
        },
        "temporal": {
            "precision": 0.09283613445378151,
            "recall": 1.0,
            "f1-score": 0.1657516339869281,
            "support": 1.0
        },
        "topic": {
            "precision": 0,
            "recall": 0,
            "f1-score": 0,
            "support": 0
        },
        "type-of": {
            "precision": 0,
            "recall": 0,
            "f1-score": 0,
            "support": 0
        },
        "usage": {
            "precision": 0,
            "recall": 0,
            "f1-score": 0,
            "support": 0
        },
        "win-defeat": {
            "precision": 0.0,
            "recall": 0.0,
            "f1-score": 0.0,
            "support": 35.0
        },
        "micro avg": {
            "precision": 0.4540404040404041,
            "recall": 0.4540404040404041,
            "f1-score": 0.4540404040404041,
            "support": 396.0
        },
        "macro avg": {
            "precision": 999999.0,
            "recall": 999999.0,
            "f1-score": 0.2659999824468551,
            "support": 396.0
        },
        "weighted avg": {
            "precision": 0.4064872168758663,
            "recall": 0.4540404040404041,
            "f1-score": 0.37399229974507914,
            "support": 396.0
        },
        "samples avg": {
            "precision": 0.4540404040404041,
            "recall": 0.4540404040404041,
            "f1-score": 0.4540404040404041,
            "support": 396.0
        }
    },
    "politics": {
        "related-to": {
            "precision": 0.12896551724137933,
            "recall": 0.03421052631578947,
            "f1-score": 0.05204872646733112,
            "support": 76.0
        },
        "artifact": {
            "precision": 0.49469696969696975,
            "recall": 0.9,
            "f1-score": 0.5948717948717949,
            "support": 2.0
        },
        "cause-effect": {
            "precision": 0,
            "recall": 0,
            "f1-score": 0,
            "support": 0
        },
        "compare": {
            "precision": 0.0,
            "recall": 0.0,
            "f1-score": 0.0,
            "support": 6.0
        },
        "general-affiliation": {
            "precision": 0.40183231486179816,
            "recall": 0.6258064516129032,
            "f1-score": 0.48150105708245244,
            "support": 31.0
        },
        "named": {
            "precision": 0.6404596661537628,
            "recall": 0.7553846153846153,
            "f1-score": 0.6891536021970806,
            "support": 130.0
        },
        "opposite": {
            "precision": 0.3314285714285714,
            "recall": 0.04150943396226415,
            "f1-score": 0.07147204088450669,
            "support": 53.0
        },
        "origin": {
            "precision": 0.3345928301573463,
            "recall": 0.14909090909090908,
            "f1-score": 0.20095723252204983,
            "support": 55.0
        },
        "part-of": {
            "precision": 0.2878573142818307,
            "recall": 0.23076923076923078,
            "f1-score": 0.23483049456927207,
            "support": 117.0
        },
        "physical": {
            "precision": 0.6380065420949289,
            "recall": 0.971638141809291,
            "f1-score": 0.7701818393781891,
            "support": 409.0
        },
        "role": {
            "precision": 0.7335583531602283,
            "recall": 0.5276646706586826,
            "f1-score": 0.61124822429358,
            "support": 835.0
        },
        "social": {
            "precision": 0.5833333333333333,
            "recall": 0.11428571428571428,
            "f1-score": 0.16969696969696968,
            "support": 21.0
        },
        "temporal": {
            "precision": 0.8085452397996755,
            "recall": 0.5583061889250814,
            "f1-score": 0.658035382066658,
            "support": 307.0
        },
        "topic": {
            "precision": 0.05,
            "recall": 0.015384615384615385,
            "f1-score": 0.023529411764705882,
            "support": 13.0
        },
        "type-of": {
            "precision": 0.4619918699186992,
            "recall": 0.23571428571428568,
            "f1-score": 0.2779874835309618,
            "support": 28.0
        },
        "usage": {
            "precision": 0,
            "recall": 0,
            "f1-score": 0,
            "support": 0
        },
        "win-defeat": {
            "precision": 0.18888888888888888,
            "recall": 0.029268292682926834,
            "f1-score": 0.04397066100066944,
            "support": 41.0
        },
        "micro avg": {
            "precision": 0.6440196613872201,
            "recall": 0.5551789077212806,
            "f1-score": 0.5963084702907712,
            "support": 2124.0
        },
        "macro avg": {
            "precision": 999999.0,
            "recall": 999999.0,
            "f1-score": 0.3252989946884147,
            "support": 2124.0
        },
        "weighted avg": {
            "precision": 0.6268476757778112,
            "recall": 0.5551789077212806,
            "f1-score": 0.5616041661574332,
            "support": 2124.0
        },
        "samples avg": {
            "precision": 0.6440196613872201,
            "recall": 0.5732932823593664,
            "f1-score": 0.5968687420353176,
            "support": 2124.0
        }
    },
    "science": {
        "related-to": {
            "precision": 0.2898338972697593,
            "recall": 0.49523809523809526,
            "f1-score": 0.3644569233457446,
            "support": 126.0
        },
        "artifact": {
            "precision": 0.7824774231670784,
            "recall": 0.7212121212121211,
            "f1-score": 0.7480401452626714,
            "support": 33.0
        },
        "cause-effect": {
            "precision": 0.0,
            "recall": 0.0,
            "f1-score": 0.0,
            "support": 76.0
        },
        "compare": {
            "precision": 0.0,
            "recall": 0.0,
            "f1-score": 0.0,
            "support": 39.0
        },
        "general-affiliation": {
            "precision": 0.27659826225164114,
            "recall": 0.5123287671232877,
            "f1-score": 0.354972534204459,
            "support": 73.0
        },
        "named": {
            "precision": 0.3479661666726018,
            "recall": 0.8314814814814813,
            "f1-score": 0.48545008672203027,
            "support": 108.0
        },
        "opposite": {
            "precision": 0.02,
            "recall": 0.04,
            "f1-score": 0.026666666666666665,
            "support": 5.0
        },
        "origin": {
            "precision": 0.5230856738535545,
            "recall": 0.2851063829787234,
            "f1-score": 0.3684877329512866,
            "support": 94.0
        },
        "part-of": {
            "precision": 0.1414091460936573,
            "recall": 0.2711111111111111,
            "f1-score": 0.18035248189345487,
            "support": 90.0
        },
        "physical": {
            "precision": 0.8450193543296992,
            "recall": 0.6794642857142857,
            "f1-score": 0.7475566444646394,
            "support": 224.0
        },
        "role": {
            "precision": 0.6497598655297897,
            "recall": 0.5412587412587413,
            "f1-score": 0.5884323123815438,
            "support": 286.0
        },
        "social": {
            "precision": 0.42515406162464986,
            "recall": 0.32857142857142857,
            "f1-score": 0.35934184095474425,
            "support": 14.0
        },
        "temporal": {
            "precision": 0.688729531338227,
            "recall": 0.6923076923076923,
            "f1-score": 0.6874149659863945,
            "support": 26.0
        },
        "topic": {
            "precision": 0.6466666666666667,
            "recall": 0.048484848484848485,
            "f1-score": 0.08699870102531718,
            "support": 66.0
        },
        "type-of": {
            "precision": 0.4821428571428571,
            "recall": 0.018803418803418803,
            "f1-score": 0.035785872226789944,
            "support": 117.0
        },
        "usage": {
            "precision": 0.0,
            "recall": 0.0,
            "f1-score": 0.0,
            "support": 24.0
        },
        "win-defeat": {
            "precision": 0.9338348377628565,
            "recall": 0.7000000000000001,
            "f1-score": 0.7982581603249125,
            "support": 44.0
        },
        "micro avg": {
            "precision": 0.4530172413793103,
            "recall": 0.43640138408304496,
            "f1-score": 0.4445541064504758,
            "support": 1445.0
        },
        "macro avg": {
            "precision": 999999.0,
            "recall": 999999.0,
            "f1-score": 0.34307147461239146,
            "support": 1445.0
        },
        "weighted avg": {
            "precision": 0.49914460234766,
            "recall": 0.43640138408304496,
            "f1-score": 0.4177519239183508,
            "support": 1445.0
        },
        "samples avg": {
            "precision": 0.4530172413793103,
            "recall": 0.43455459770114946,
            "f1-score": 0.4407088122605364,
            "support": 1445.0
        }
    }
}