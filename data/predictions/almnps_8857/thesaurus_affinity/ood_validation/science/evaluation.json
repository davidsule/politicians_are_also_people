{"related-to": {"precision": 0.08333333333333333, "recall": 0.15079365079365079, "f1-score": 0.10734463276836158, "support": 126}, "artifact": {"precision": 0.041666666666666664, "recall": 0.030303030303030304, "f1-score": 0.03508771929824561, "support": 33}, "cause-effect": {"precision": 0.0, "recall": 0.0, "f1-score": 0.0, "support": 76}, "compare": {"precision": 0.0, "recall": 0.0, "f1-score": 0.0, "support": 39}, "general-affiliation": {"precision": 0.0958904109589041, "recall": 0.1917808219178082, "f1-score": 0.1278538812785388, "support": 73}, "named": {"precision": 0.11224489795918367, "recall": 0.2037037037037037, "f1-score": 0.14473684210526316, "support": 108}, "opposite": {"precision": 0.0, "recall": 0.0, "f1-score": 0.0, "support": 5}, "origin": {"precision": 0.020833333333333332, "recall": 0.010638297872340425, "f1-score": 0.014084507042253521, "support": 94}, "part-of": {"precision": 0.07058823529411765, "recall": 0.2, "f1-score": 0.10434782608695652, "support": 90}, "physical": {"precision": 0.16083916083916083, "recall": 0.10267857142857142, "f1-score": 0.1253405994550409, "support": 224}, "role": {"precision": 0.19291338582677164, "recall": 0.17132867132867133, "f1-score": 0.18148148148148147, "support": 286}, "social": {"precision": 0.0, "recall": 0.0, "f1-score": 0.0, "support": 14}, "temporal": {"precision": 0.05, "recall": 0.07692307692307693, "f1-score": 0.060606060606060615, "support": 26}, "topic": {"precision": 0.0, "recall": 0.0, "f1-score": 0.0, "support": 66}, "type-of": {"precision": 0.07692307692307693, "recall": 0.008547008547008548, "f1-score": 0.015384615384615387, "support": 117}, "usage": {"precision": 0.0, "recall": 0.0, "f1-score": 0.0, "support": 24}, "win-defeat": {"precision": 0.0, "recall": 0.0, "f1-score": 0.0, "support": 44}, "micro avg": {"precision": 0.10775862068965517, "recall": 0.10380622837370242, "f1-score": 0.10574550581600281, "support": 1445}, "macro avg": {"precision": 0.053248970654973415, "recall": 0.06745275487163892, "f1-score": 0.05389812738275397, "support": 1445}, "weighted avg": {"precision": 0.09744631409261209, "recall": 0.10380622837370242, "f1-score": 0.09253926250072371, "support": 1445}, "samples avg": {"precision": 0.10775862068965517, "recall": 0.10201149425287356, "f1-score": 0.10392720306513409, "support": 1445}}