{"related-to": {"precision": 0.06387665198237885, "recall": 0.07004830917874397, "f1-score": 0.06682027649769585, "support": 414}, "artifact": {"precision": 0.07134502923976609, "recall": 0.09606299212598425, "f1-score": 0.0818791946308725, "support": 635}, "cause-effect": {"precision": 0.0, "recall": 0.0, "f1-score": 0.0, "support": 86}, "compare": {"precision": 0.0, "recall": 0.0, "f1-score": 0.0, "support": 82}, "general-affiliation": {"precision": 0.1371841155234657, "recall": 0.15334947538337368, "f1-score": 0.1448170731707317, "support": 1239}, "named": {"precision": 0.058823529411764705, "recall": 0.06810035842293907, "f1-score": 0.06312292358803988, "support": 558}, "opposite": {"precision": 0.01818181818181818, "recall": 0.0078125, "f1-score": 0.01092896174863388, "support": 128}, "origin": {"precision": 0.05699481865284974, "recall": 0.03618421052631579, "f1-score": 0.04426559356136821, "support": 304}, "part-of": {"precision": 0.07903055848261328, "recall": 0.10402219140083217, "f1-score": 0.08982035928143713, "support": 721}, "physical": {"precision": 0.17289073305670816, "recall": 0.1718213058419244, "f1-score": 0.1723543605653223, "support": 1455}, "role": {"precision": 0.22563496751329, "recall": 0.19042871385842472, "f1-score": 0.20654230873208973, "support": 2006}, "social": {"precision": 0.0125, "recall": 0.009523809523809525, "f1-score": 0.010810810810810811, "support": 105}, "temporal": {"precision": 0.048728813559322036, "recall": 0.056372549019607844, "f1-score": 0.052272727272727276, "support": 408}, "topic": {"precision": 0.0, "recall": 0.0, "f1-score": 0.0, "support": 170}, "type-of": {"precision": 0.029197080291970802, "recall": 0.011904761904761904, "f1-score": 0.01691331923890063, "support": 336}, "usage": {"precision": 0.047619047619047616, "recall": 0.005, "f1-score": 0.00904977375565611, "support": 200}, "win-defeat": {"precision": 0.04938271604938271, "recall": 0.03785488958990536, "f1-score": 0.04285714285714286, "support": 317}, "micro avg": {"precision": 0.12436548223350254, "recall": 0.11763422086425142, "f1-score": 0.1209062359802602, "support": 9164}, "macro avg": {"precision": 0.06302293409202223, "recall": 0.059910945104507216, "f1-score": 0.05955616621831935, "support": 9164}, "weighted avg": {"precision": 0.12129423539370775, "recall": 0.11763422086425142, "f1-score": 0.11813229733439, "support": 9164}, "samples avg": {"precision": 0.12436548223350254, "recall": 0.11692431933548685, "f1-score": 0.11938547915705275, "support": 9164}}