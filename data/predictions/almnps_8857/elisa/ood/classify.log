Saved arguments to data/predictions/almnps_8857/elisa/ood/args.json.
Saved category mapping to data/predictions/almnps_8857/elisa/ood/mapping.json.
Loaded category mapping: elisa.
Loaded <torch.utils.data.dataloader.DataLoader object at 0x7f20b430c8b0> (train).
Loaded <torch.utils.data.dataloader.DataLoader object at 0x7f20b430ceb0> (dev).
Starting training on ['literature', 'music', 'news', 'politics', 'science'] data.
Loaded <TransformerEmbeddings: dim=768>.
Using classifier: <LinearClassifier: emb_model = <TransformerEmbeddings: dim=768>>
Using criterion: <LabelLoss: loss=XEnt>.
Optimizing using: AdamW with learning rate 2e-05.
[Epoch 1/50] Train completed with Micro-f1: 0.4170, Macro-f1: 0.2323, Weighted-f1: 0.3409, Loss: 2.0188
[Epoch 1/50] Evaluation completed with Micro-f1: 0.5310, Macro-f1: 0.3485, Weighted-f1: 0.4802, Loss: 1.6056
Saved models from epoch 1 to 'data/predictions/almnps_8857/elisa/ood/ai/newest.pt'.
Saved model with best loss 1.6056 to 'data/predictions/almnps_8857/elisa/ood/ai/best.pt'.
[Epoch 2/50] Train completed with Micro-f1: 0.7029, Macro-f1: 0.5638, Weighted-f1: 0.6642, Loss: 1.0555
[Epoch 2/50] Evaluation completed with Micro-f1: 0.5522, Macro-f1: 0.3768, Weighted-f1: 0.5093, Loss: 1.4635
Saved models from epoch 2 to 'data/predictions/almnps_8857/elisa/ood/ai/newest.pt'.
Saved model with best loss 1.4635 to 'data/predictions/almnps_8857/elisa/ood/ai/best.pt'.
[Epoch 3/50] Train completed with Micro-f1: 0.8330, Macro-f1: 0.7204, Weighted-f1: 0.8154, Loss: 0.6514
[Epoch 3/50] Evaluation completed with Micro-f1: 0.5641, Macro-f1: 0.3897, Weighted-f1: 0.5233, Loss: 1.3573
Saved models from epoch 3 to 'data/predictions/almnps_8857/elisa/ood/ai/newest.pt'.
Saved model with best loss 1.3573 to 'data/predictions/almnps_8857/elisa/ood/ai/best.pt'.
[Epoch 4/50] Train completed with Micro-f1: 0.8965, Macro-f1: 0.8217, Weighted-f1: 0.8880, Loss: 0.4229
[Epoch 4/50] Evaluation completed with Micro-f1: 0.5752, Macro-f1: 0.4051, Weighted-f1: 0.5376, Loss: 1.4129
Saved models from epoch 4 to 'data/predictions/almnps_8857/elisa/ood/ai/newest.pt'.
[Epoch 5/50] Train completed with Micro-f1: 0.9431, Macro-f1: 0.9002, Weighted-f1: 0.9397, Loss: 0.2769
[Epoch 5/50] Evaluation completed with Micro-f1: 0.5821, Macro-f1: 0.4126, Weighted-f1: 0.5463, Loss: 1.4047
Saved models from epoch 5 to 'data/predictions/almnps_8857/elisa/ood/ai/newest.pt'.
[Epoch 6/50] Train completed with Micro-f1: 0.9698, Macro-f1: 0.9475, Weighted-f1: 0.9676, Loss: 0.1754
[Epoch 6/50] Evaluation completed with Micro-f1: 0.5868, Macro-f1: 0.4182, Weighted-f1: 0.5512, Loss: 1.4685
Saved models from epoch 6 to 'data/predictions/almnps_8857/elisa/ood/ai/newest.pt'.
No improvement since 3 epochs (1.3573 loss). Early stop.
OOD training completed for test topic ai after 6 epochs.
Loaded <torch.utils.data.dataloader.DataLoader object at 0x7f20b62c3d90> (train).
Loaded <torch.utils.data.dataloader.DataLoader object at 0x7f20b430cd30> (dev).
Starting training on ['ai', 'music', 'news', 'politics', 'science'] data.
Loaded <TransformerEmbeddings: dim=768>.
Using classifier: <LinearClassifier: emb_model = <TransformerEmbeddings: dim=768>>
Using criterion: <LabelLoss: loss=XEnt>.
Optimizing using: AdamW with learning rate 2e-05.
[Epoch 1/50] Train completed with Micro-f1: 0.3791, Macro-f1: 0.2048, Weighted-f1: 0.3044, Loss: 2.0884
[Epoch 1/50] Evaluation completed with Micro-f1: 0.5225, Macro-f1: 0.3655, Weighted-f1: 0.4831, Loss: 1.6783
Saved models from epoch 1 to 'data/predictions/almnps_8857/elisa/ood/literature/newest.pt'.
Saved model with best loss 1.6783 to 'data/predictions/almnps_8857/elisa/ood/literature/best.pt'.
[Epoch 2/50] Train completed with Micro-f1: 0.7102, Macro-f1: 0.5772, Weighted-f1: 0.6822, Loss: 1.0984
[Epoch 2/50] Evaluation completed with Micro-f1: 0.5403, Macro-f1: 0.3835, Weighted-f1: 0.5025, Loss: 1.4894
Saved models from epoch 2 to 'data/predictions/almnps_8857/elisa/ood/literature/newest.pt'.
Saved model with best loss 1.4894 to 'data/predictions/almnps_8857/elisa/ood/literature/best.pt'.
[Epoch 3/50] Train completed with Micro-f1: 0.8305, Macro-f1: 0.7266, Weighted-f1: 0.8146, Loss: 0.6669
[Epoch 3/50] Evaluation completed with Micro-f1: 0.5489, Macro-f1: 0.3991, Weighted-f1: 0.5170, Loss: 1.4197
Saved models from epoch 3 to 'data/predictions/almnps_8857/elisa/ood/literature/newest.pt'.
Saved model with best loss 1.4197 to 'data/predictions/almnps_8857/elisa/ood/literature/best.pt'.
[Epoch 4/50] Train completed with Micro-f1: 0.9068, Macro-f1: 0.8412, Weighted-f1: 0.8989, Loss: 0.4232
[Epoch 4/50] Evaluation completed with Micro-f1: 0.5576, Macro-f1: 0.4083, Weighted-f1: 0.5277, Loss: 1.4211
Saved models from epoch 4 to 'data/predictions/almnps_8857/elisa/ood/literature/newest.pt'.
[Epoch 5/50] Train completed with Micro-f1: 0.9454, Macro-f1: 0.9041, Weighted-f1: 0.9422, Loss: 0.2714
[Epoch 5/50] Evaluation completed with Micro-f1: 0.5653, Macro-f1: 0.4162, Weighted-f1: 0.5367, Loss: 1.4234
Saved models from epoch 5 to 'data/predictions/almnps_8857/elisa/ood/literature/newest.pt'.
[Epoch 6/50] Train completed with Micro-f1: 0.9706, Macro-f1: 0.9483, Weighted-f1: 0.9687, Loss: 0.1743
[Epoch 6/50] Evaluation completed with Micro-f1: 0.5710, Macro-f1: 0.4231, Weighted-f1: 0.5434, Loss: 1.4747
Saved models from epoch 6 to 'data/predictions/almnps_8857/elisa/ood/literature/newest.pt'.
No improvement since 3 epochs (1.4197 loss). Early stop.
OOD training completed for test topic literature after 6 epochs.
Loaded <torch.utils.data.dataloader.DataLoader object at 0x7f2091746040> (train).
Loaded <torch.utils.data.dataloader.DataLoader object at 0x7f20b5dec9d0> (dev).
Starting training on ['ai', 'literature', 'news', 'politics', 'science'] data.
Loaded <TransformerEmbeddings: dim=768>.
Using classifier: <LinearClassifier: emb_model = <TransformerEmbeddings: dim=768>>
Using criterion: <LabelLoss: loss=XEnt>.
Optimizing using: AdamW with learning rate 2e-05.
[Epoch 1/50] Train completed with Micro-f1: 0.3225, Macro-f1: 0.1739, Weighted-f1: 0.2511, Loss: 2.2409
[Epoch 1/50] Evaluation completed with Micro-f1: 0.4772, Macro-f1: 0.3166, Weighted-f1: 0.4345, Loss: 1.8673
Saved models from epoch 1 to 'data/predictions/almnps_8857/elisa/ood/music/newest.pt'.
Saved model with best loss 1.8673 to 'data/predictions/almnps_8857/elisa/ood/music/best.pt'.
[Epoch 2/50] Train completed with Micro-f1: 0.6553, Macro-f1: 0.5056, Weighted-f1: 0.6201, Loss: 1.2598
[Epoch 2/50] Evaluation completed with Micro-f1: 0.5009, Macro-f1: 0.3415, Weighted-f1: 0.4617, Loss: 1.6372
Saved models from epoch 2 to 'data/predictions/almnps_8857/elisa/ood/music/newest.pt'.
Saved model with best loss 1.6372 to 'data/predictions/almnps_8857/elisa/ood/music/best.pt'.
[Epoch 3/50] Train completed with Micro-f1: 0.8022, Macro-f1: 0.6853, Weighted-f1: 0.7803, Loss: 0.7946
[Epoch 3/50] Evaluation completed with Micro-f1: 0.5144, Macro-f1: 0.3595, Weighted-f1: 0.4786, Loss: 1.5620
Saved models from epoch 3 to 'data/predictions/almnps_8857/elisa/ood/music/newest.pt'.
Saved model with best loss 1.5620 to 'data/predictions/almnps_8857/elisa/ood/music/best.pt'.
[Epoch 4/50] Train completed with Micro-f1: 0.8817, Macro-f1: 0.8097, Weighted-f1: 0.8713, Loss: 0.5194
[Epoch 4/50] Evaluation completed with Micro-f1: 0.5229, Macro-f1: 0.3679, Weighted-f1: 0.4894, Loss: 1.5228
Saved models from epoch 4 to 'data/predictions/almnps_8857/elisa/ood/music/newest.pt'.
Saved model with best loss 1.5228 to 'data/predictions/almnps_8857/elisa/ood/music/best.pt'.
[Epoch 5/50] Train completed with Micro-f1: 0.9332, Macro-f1: 0.8752, Weighted-f1: 0.9270, Loss: 0.3492
[Epoch 5/50] Evaluation completed with Micro-f1: 0.5293, Macro-f1: 0.3762, Weighted-f1: 0.4974, Loss: 1.5515
Saved models from epoch 5 to 'data/predictions/almnps_8857/elisa/ood/music/newest.pt'.
[Epoch 6/50] Train completed with Micro-f1: 0.9673, Macro-f1: 0.9429, Weighted-f1: 0.9654, Loss: 0.2208
[Epoch 6/50] Evaluation completed with Micro-f1: 0.5350, Macro-f1: 0.3836, Weighted-f1: 0.5048, Loss: 1.5505
Saved models from epoch 6 to 'data/predictions/almnps_8857/elisa/ood/music/newest.pt'.
[Epoch 7/50] Train completed with Micro-f1: 0.9821, Macro-f1: 0.9608, Weighted-f1: 0.9807, Loss: 0.1479
[Epoch 7/50] Evaluation completed with Micro-f1: 0.5392, Macro-f1: 0.3896, Weighted-f1: 0.5105, Loss: 1.5726
Saved models from epoch 7 to 'data/predictions/almnps_8857/elisa/ood/music/newest.pt'.
No improvement since 3 epochs (1.5228 loss). Early stop.
OOD training completed for test topic music after 7 epochs.
Loaded <torch.utils.data.dataloader.DataLoader object at 0x7f20b3fe1520> (train).
Loaded <torch.utils.data.dataloader.DataLoader object at 0x7f209172bb20> (dev).
Starting training on ['ai', 'literature', 'music', 'politics', 'science'] data.
Loaded <TransformerEmbeddings: dim=768>.
Using classifier: <LinearClassifier: emb_model = <TransformerEmbeddings: dim=768>>
Using criterion: <LabelLoss: loss=XEnt>.
Optimizing using: AdamW with learning rate 2e-05.
