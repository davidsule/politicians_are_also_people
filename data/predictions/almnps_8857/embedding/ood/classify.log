Saved arguments to data/predictions/almnps_8857/embedding/ood/args.json.
loading projection weights from /home/davidsule/gensim-data/word2vec-google-news-300/word2vec-google-news-300.gz
KeyedVectors lifecycle event {'msg': 'loaded (3000000, 300) matrix of type float32 from /home/davidsule/gensim-data/word2vec-google-news-300/word2vec-google-news-300.gz', 'binary': True, 'encoding': 'utf8', 'datetime': '2023-05-08T10:06:50.554229', 'gensim': '4.3.0', 'python': '3.9.16 | packaged by conda-forge | (main, Feb  1 2023, 21:39:03) \n[GCC 11.3.0]', 'platform': 'Linux-5.15.90.1-microsoft-standard-WSL2-x86_64-with-glibc2.31', 'event': 'load_word2vec_format'}
Saved category mapping to data/predictions/almnps_8857/embedding/ood/mapping.json.
Loaded category mapping: embedding.
Loaded <torch.utils.data.dataloader.DataLoader object at 0x7f13be4d4b80> (train).
Loaded <torch.utils.data.dataloader.DataLoader object at 0x7f13be4d4340> (dev).
Starting training on ['literature', 'music', 'news', 'politics', 'science'] data.
Loaded <TransformerEmbeddings: dim=768>.
Using classifier: <LinearClassifier: emb_model = <TransformerEmbeddings: dim=768>>
Using criterion: <LabelLoss: loss=XEnt>.
Optimizing using: AdamW with learning rate 2e-05.
[Epoch 1/50] Train completed with Micro-f1: 0.3801, Macro-f1: 0.1926, Weighted-f1: 0.3050, Loss: 2.1143
[Epoch 1/50] Evaluation completed with Micro-f1: 0.4690, Macro-f1: 0.2891, Weighted-f1: 0.4090, Loss: 1.8086
Saved models from epoch 1 to 'data/predictions/almnps_8857/embedding/ood/ai/newest.pt'.
Saved model with best loss 1.8086 to 'data/predictions/almnps_8857/embedding/ood/ai/best.pt'.
[Epoch 2/50] Train completed with Micro-f1: 0.7008, Macro-f1: 0.5299, Weighted-f1: 0.6605, Loss: 1.1242
[Epoch 2/50] Evaluation completed with Micro-f1: 0.5019, Macro-f1: 0.3240, Weighted-f1: 0.4455, Loss: 1.5641
Saved models from epoch 2 to 'data/predictions/almnps_8857/embedding/ood/ai/newest.pt'.
Saved model with best loss 1.5641 to 'data/predictions/almnps_8857/embedding/ood/ai/best.pt'.
[Epoch 3/50] Train completed with Micro-f1: 0.8238, Macro-f1: 0.7057, Weighted-f1: 0.8047, Loss: 0.6975
[Epoch 3/50] Evaluation completed with Micro-f1: 0.5236, Macro-f1: 0.3516, Weighted-f1: 0.4734, Loss: 1.5324
Saved models from epoch 3 to 'data/predictions/almnps_8857/embedding/ood/ai/newest.pt'.
Saved model with best loss 1.5324 to 'data/predictions/almnps_8857/embedding/ood/ai/best.pt'.
[Epoch 4/50] Train completed with Micro-f1: 0.8970, Macro-f1: 0.8200, Weighted-f1: 0.8852, Loss: 0.4319
[Epoch 4/50] Evaluation completed with Micro-f1: 0.5394, Macro-f1: 0.3696, Weighted-f1: 0.4943, Loss: 1.4108
Saved models from epoch 4 to 'data/predictions/almnps_8857/embedding/ood/ai/newest.pt'.
Saved model with best loss 1.4108 to 'data/predictions/almnps_8857/embedding/ood/ai/best.pt'.
[Epoch 5/50] Train completed with Micro-f1: 0.9457, Macro-f1: 0.9000, Weighted-f1: 0.9411, Loss: 0.2810
[Epoch 5/50] Evaluation completed with Micro-f1: 0.5505, Macro-f1: 0.3846, Weighted-f1: 0.5090, Loss: 1.4745
Saved models from epoch 5 to 'data/predictions/almnps_8857/embedding/ood/ai/newest.pt'.
[Epoch 6/50] Train completed with Micro-f1: 0.9728, Macro-f1: 0.9485, Weighted-f1: 0.9692, Loss: 0.1765
[Epoch 6/50] Evaluation completed with Micro-f1: 0.5588, Macro-f1: 0.3959, Weighted-f1: 0.5203, Loss: 1.5002
Saved models from epoch 6 to 'data/predictions/almnps_8857/embedding/ood/ai/newest.pt'.
[Epoch 7/50] Train completed with Micro-f1: 0.9841, Macro-f1: 0.9693, Weighted-f1: 0.9830, Loss: 0.1140
[Epoch 7/50] Evaluation completed with Micro-f1: 0.5655, Macro-f1: 0.4049, Weighted-f1: 0.5290, Loss: 1.5638
Saved models from epoch 7 to 'data/predictions/almnps_8857/embedding/ood/ai/newest.pt'.
No improvement since 3 epochs (1.4108 loss). Early stop.
OOD training completed for test topic ai after 7 epochs.
Loaded <torch.utils.data.dataloader.DataLoader object at 0x7f13a83b9f10> (train).
Loaded <torch.utils.data.dataloader.DataLoader object at 0x7f13be4d41c0> (dev).
Starting training on ['ai', 'music', 'news', 'politics', 'science'] data.
Loaded <TransformerEmbeddings: dim=768>.
Using classifier: <LinearClassifier: emb_model = <TransformerEmbeddings: dim=768>>
Using criterion: <LabelLoss: loss=XEnt>.
Optimizing using: AdamW with learning rate 2e-05.
[Epoch 1/50] Train completed with Micro-f1: 0.3643, Macro-f1: 0.2027, Weighted-f1: 0.2936, Loss: 2.1056
[Epoch 1/50] Evaluation completed with Micro-f1: 0.4793, Macro-f1: 0.3257, Weighted-f1: 0.4463, Loss: 1.7785
Saved models from epoch 1 to 'data/predictions/almnps_8857/embedding/ood/literature/newest.pt'.
Saved model with best loss 1.7785 to 'data/predictions/almnps_8857/embedding/ood/literature/best.pt'.
[Epoch 2/50] Train completed with Micro-f1: 0.6829, Macro-f1: 0.5508, Weighted-f1: 0.6525, Loss: 1.1718
[Epoch 2/50] Evaluation completed with Micro-f1: 0.4927, Macro-f1: 0.3405, Weighted-f1: 0.4615, Loss: 1.5605
Saved models from epoch 2 to 'data/predictions/almnps_8857/embedding/ood/literature/newest.pt'.
Saved model with best loss 1.5605 to 'data/predictions/almnps_8857/embedding/ood/literature/best.pt'.
[Epoch 3/50] Train completed with Micro-f1: 0.8358, Macro-f1: 0.7443, Weighted-f1: 0.8220, Loss: 0.7183
[Epoch 3/50] Evaluation completed with Micro-f1: 0.5035, Macro-f1: 0.3554, Weighted-f1: 0.4760, Loss: 1.5237
Saved models from epoch 3 to 'data/predictions/almnps_8857/embedding/ood/literature/newest.pt'.
Saved model with best loss 1.5237 to 'data/predictions/almnps_8857/embedding/ood/literature/best.pt'.
[Epoch 4/50] Train completed with Micro-f1: 0.9062, Macro-f1: 0.8298, Weighted-f1: 0.8981, Loss: 0.4569
[Epoch 4/50] Evaluation completed with Micro-f1: 0.5127, Macro-f1: 0.3669, Weighted-f1: 0.4864, Loss: 1.5413
Saved models from epoch 4 to 'data/predictions/almnps_8857/embedding/ood/literature/newest.pt'.
[Epoch 5/50] Train completed with Micro-f1: 0.9531, Macro-f1: 0.9212, Weighted-f1: 0.9507, Loss: 0.2900
[Epoch 5/50] Evaluation completed with Micro-f1: 0.5211, Macro-f1: 0.3766, Weighted-f1: 0.4964, Loss: 1.5213
Saved models from epoch 5 to 'data/predictions/almnps_8857/embedding/ood/literature/newest.pt'.
Saved model with best loss 1.5213 to 'data/predictions/almnps_8857/embedding/ood/literature/best.pt'.
[Epoch 6/50] Train completed with Micro-f1: 0.9740, Macro-f1: 0.9481, Weighted-f1: 0.9726, Loss: 0.1869
[Epoch 6/50] Evaluation completed with Micro-f1: 0.5274, Macro-f1: 0.3839, Weighted-f1: 0.5045, Loss: 1.5539
Saved models from epoch 6 to 'data/predictions/almnps_8857/embedding/ood/literature/newest.pt'.
[Epoch 7/50] Train completed with Micro-f1: 0.9878, Macro-f1: 0.9799, Weighted-f1: 0.9877, Loss: 0.1196
[Epoch 7/50] Evaluation completed with Micro-f1: 0.5323, Macro-f1: 0.3902, Weighted-f1: 0.5106, Loss: 1.5960
Saved models from epoch 7 to 'data/predictions/almnps_8857/embedding/ood/literature/newest.pt'.
[Epoch 8/50] Train completed with Micro-f1: 0.9947, Macro-f1: 0.9873, Weighted-f1: 0.9950, Loss: 0.0800
[Epoch 8/50] Evaluation completed with Micro-f1: 0.5367, Macro-f1: 0.3955, Weighted-f1: 0.5163, Loss: 1.6488
Saved models from epoch 8 to 'data/predictions/almnps_8857/embedding/ood/literature/newest.pt'.
No improvement since 3 epochs (1.5213 loss). Early stop.
OOD training completed for test topic literature after 8 epochs.
Loaded <torch.utils.data.dataloader.DataLoader object at 0x7f141fd0f6a0> (train).
Loaded <torch.utils.data.dataloader.DataLoader object at 0x7f13a8438a60> (dev).
Starting training on ['ai', 'literature', 'news', 'politics', 'science'] data.
Loaded <TransformerEmbeddings: dim=768>.
Using classifier: <LinearClassifier: emb_model = <TransformerEmbeddings: dim=768>>
Using criterion: <LabelLoss: loss=XEnt>.
Optimizing using: AdamW with learning rate 2e-05.
[Epoch 1/50] Train completed with Micro-f1: 0.3139, Macro-f1: 0.1688, Weighted-f1: 0.2401, Loss: 2.2196
[Epoch 1/50] Evaluation completed with Micro-f1: 0.4545, Macro-f1: 0.3034, Weighted-f1: 0.4145, Loss: 1.9118
Saved models from epoch 1 to 'data/predictions/almnps_8857/embedding/ood/music/newest.pt'.
Saved model with best loss 1.9118 to 'data/predictions/almnps_8857/embedding/ood/music/best.pt'.
[Epoch 2/50] Train completed with Micro-f1: 0.6649, Macro-f1: 0.5200, Weighted-f1: 0.6312, Loss: 1.2567
[Epoch 2/50] Evaluation completed with Micro-f1: 0.4755, Macro-f1: 0.3249, Weighted-f1: 0.4390, Loss: 1.6766
Saved models from epoch 2 to 'data/predictions/almnps_8857/embedding/ood/music/newest.pt'.
Saved model with best loss 1.6766 to 'data/predictions/almnps_8857/embedding/ood/music/best.pt'.
[Epoch 3/50] Train completed with Micro-f1: 0.8015, Macro-f1: 0.7006, Weighted-f1: 0.7887, Loss: 0.7691
[Epoch 3/50] Evaluation completed with Micro-f1: 0.4891, Macro-f1: 0.3385, Weighted-f1: 0.4547, Loss: 1.5654
Saved models from epoch 3 to 'data/predictions/almnps_8857/embedding/ood/music/newest.pt'.
Saved model with best loss 1.5654 to 'data/predictions/almnps_8857/embedding/ood/music/best.pt'.
[Epoch 4/50] Train completed with Micro-f1: 0.8895, Macro-f1: 0.8184, Weighted-f1: 0.8804, Loss: 0.4951
[Epoch 4/50] Evaluation completed with Micro-f1: 0.5012, Macro-f1: 0.3510, Weighted-f1: 0.4687, Loss: 1.5366
Saved models from epoch 4 to 'data/predictions/almnps_8857/embedding/ood/music/newest.pt'.
Saved model with best loss 1.5366 to 'data/predictions/almnps_8857/embedding/ood/music/best.pt'.
[Epoch 5/50] Train completed with Micro-f1: 0.9457, Macro-f1: 0.9117, Weighted-f1: 0.9407, Loss: 0.3200
[Epoch 5/50] Evaluation completed with Micro-f1: 0.5100, Macro-f1: 0.3607, Weighted-f1: 0.4791, Loss: 1.5413
Saved models from epoch 5 to 'data/predictions/almnps_8857/embedding/ood/music/newest.pt'.
[Epoch 6/50] Train completed with Micro-f1: 0.9706, Macro-f1: 0.9498, Weighted-f1: 0.9682, Loss: 0.2075
[Epoch 6/50] Evaluation completed with Micro-f1: 0.5175, Macro-f1: 0.3667, Weighted-f1: 0.4871, Loss: 1.5983
Saved models from epoch 6 to 'data/predictions/almnps_8857/embedding/ood/music/newest.pt'.
[Epoch 7/50] Train completed with Micro-f1: 0.9872, Macro-f1: 0.9730, Weighted-f1: 0.9853, Loss: 0.1336
[Epoch 7/50] Evaluation completed with Micro-f1: 0.5224, Macro-f1: 0.3727, Weighted-f1: 0.4928, Loss: 1.5779
Saved models from epoch 7 to 'data/predictions/almnps_8857/embedding/ood/music/newest.pt'.
No improvement since 3 epochs (1.5366 loss). Early stop.
OOD training completed for test topic music after 7 epochs.
Loaded <torch.utils.data.dataloader.DataLoader object at 0x7f13be533400> (train).
Loaded <torch.utils.data.dataloader.DataLoader object at 0x7f1430a927f0> (dev).
Starting training on ['ai', 'literature', 'music', 'politics', 'science'] data.
Loaded <TransformerEmbeddings: dim=768>.
Using classifier: <LinearClassifier: emb_model = <TransformerEmbeddings: dim=768>>
Using criterion: <LabelLoss: loss=XEnt>.
Optimizing using: AdamW with learning rate 2e-05.
[Epoch 1/50] Train completed with Micro-f1: 0.3743, Macro-f1: 0.2115, Weighted-f1: 0.3090, Loss: 2.1218
[Epoch 1/50] Evaluation completed with Micro-f1: 0.5058, Macro-f1: 0.3339, Weighted-f1: 0.4586, Loss: 1.7127
Saved models from epoch 1 to 'data/predictions/almnps_8857/embedding/ood/news/newest.pt'.
Saved model with best loss 1.7127 to 'data/predictions/almnps_8857/embedding/ood/news/best.pt'.
[Epoch 2/50] Train completed with Micro-f1: 0.6965, Macro-f1: 0.5496, Weighted-f1: 0.6598, Loss: 1.0921
[Epoch 2/50] Evaluation completed with Micro-f1: 0.5344, Macro-f1: 0.3631, Weighted-f1: 0.4899, Loss: 1.4598
Saved models from epoch 2 to 'data/predictions/almnps_8857/embedding/ood/news/newest.pt'.
Saved model with best loss 1.4598 to 'data/predictions/almnps_8857/embedding/ood/news/best.pt'.
[Epoch 3/50] Train completed with Micro-f1: 0.8398, Macro-f1: 0.7400, Weighted-f1: 0.8214, Loss: 0.6349
[Epoch 3/50] Evaluation completed with Micro-f1: 0.5499, Macro-f1: 0.3831, Weighted-f1: 0.5100, Loss: 1.3737
Saved models from epoch 3 to 'data/predictions/almnps_8857/embedding/ood/news/newest.pt'.
Saved model with best loss 1.3737 to 'data/predictions/almnps_8857/embedding/ood/news/best.pt'.
[Epoch 4/50] Train completed with Micro-f1: 0.9149, Macro-f1: 0.8545, Weighted-f1: 0.9070, Loss: 0.3832
[Epoch 4/50] Evaluation completed with Micro-f1: 0.5610, Macro-f1: 0.3968, Weighted-f1: 0.5239, Loss: 1.3393
Saved models from epoch 4 to 'data/predictions/almnps_8857/embedding/ood/news/newest.pt'.
Saved model with best loss 1.3393 to 'data/predictions/almnps_8857/embedding/ood/news/best.pt'.
[Epoch 5/50] Train completed with Micro-f1: 0.9602, Macro-f1: 0.9244, Weighted-f1: 0.9575, Loss: 0.2286
[Epoch 5/50] Evaluation completed with Micro-f1: 0.5686, Macro-f1: 0.4059, Weighted-f1: 0.5343, Loss: 1.4078
Saved models from epoch 5 to 'data/predictions/almnps_8857/embedding/ood/news/newest.pt'.
[Epoch 6/50] Train completed with Micro-f1: 0.9763, Macro-f1: 0.9497, Weighted-f1: 0.9749, Loss: 0.1512
[Epoch 6/50] Evaluation completed with Micro-f1: 0.5755, Macro-f1: 0.4153, Weighted-f1: 0.5434, Loss: 1.4802
Saved models from epoch 6 to 'data/predictions/almnps_8857/embedding/ood/news/newest.pt'.
[Epoch 7/50] Train completed with Micro-f1: 0.9869, Macro-f1: 0.9786, Weighted-f1: 0.9859, Loss: 0.1006
[Epoch 7/50] Evaluation completed with Micro-f1: 0.5806, Macro-f1: 0.4231, Weighted-f1: 0.5503, Loss: 1.5291
Saved models from epoch 7 to 'data/predictions/almnps_8857/embedding/ood/news/newest.pt'.
No improvement since 3 epochs (1.3393 loss). Early stop.
OOD training completed for test topic news after 7 epochs.
Loaded <torch.utils.data.dataloader.DataLoader object at 0x7f14285a3970> (train).
Loaded <torch.utils.data.dataloader.DataLoader object at 0x7f14283a7c70> (dev).
Starting training on ['ai', 'literature', 'music', 'news', 'science'] data.
Loaded <TransformerEmbeddings: dim=768>.
Using classifier: <LinearClassifier: emb_model = <TransformerEmbeddings: dim=768>>
Using criterion: <LabelLoss: loss=XEnt>.
Optimizing using: AdamW with learning rate 2e-05.
[Epoch 1/50] Train completed with Micro-f1: 0.3519, Macro-f1: 0.1995, Weighted-f1: 0.2950, Loss: 2.2179
[Epoch 1/50] Evaluation completed with Micro-f1: 0.4780, Macro-f1: 0.2929, Weighted-f1: 0.4270, Loss: 1.8178
Saved models from epoch 1 to 'data/predictions/almnps_8857/embedding/ood/politics/newest.pt'.
Saved model with best loss 1.8178 to 'data/predictions/almnps_8857/embedding/ood/politics/best.pt'.
[Epoch 2/50] Train completed with Micro-f1: 0.6745, Macro-f1: 0.5094, Weighted-f1: 0.6341, Loss: 1.2329
[Epoch 2/50] Evaluation completed with Micro-f1: 0.5011, Macro-f1: 0.3247, Weighted-f1: 0.4580, Loss: 1.5226
Saved models from epoch 2 to 'data/predictions/almnps_8857/embedding/ood/politics/newest.pt'.
Saved model with best loss 1.5226 to 'data/predictions/almnps_8857/embedding/ood/politics/best.pt'.
[Epoch 3/50] Train completed with Micro-f1: 0.8082, Macro-f1: 0.7011, Weighted-f1: 0.7915, Loss: 0.7566
[Epoch 3/50] Evaluation completed with Micro-f1: 0.5234, Macro-f1: 0.3530, Weighted-f1: 0.4852, Loss: 1.4241
Saved models from epoch 3 to 'data/predictions/almnps_8857/embedding/ood/politics/newest.pt'.
Saved model with best loss 1.4241 to 'data/predictions/almnps_8857/embedding/ood/politics/best.pt'.
[Epoch 4/50] Train completed with Micro-f1: 0.8852, Macro-f1: 0.7996, Weighted-f1: 0.8731, Loss: 0.4838
[Epoch 4/50] Evaluation completed with Micro-f1: 0.5337, Macro-f1: 0.3667, Weighted-f1: 0.4979, Loss: 1.4450
Saved models from epoch 4 to 'data/predictions/almnps_8857/embedding/ood/politics/newest.pt'.
[Epoch 5/50] Train completed with Micro-f1: 0.9327, Macro-f1: 0.8770, Weighted-f1: 0.9263, Loss: 0.3206
[Epoch 5/50] Evaluation completed with Micro-f1: 0.5442, Macro-f1: 0.3791, Weighted-f1: 0.5102, Loss: 1.4213
Saved models from epoch 5 to 'data/predictions/almnps_8857/embedding/ood/politics/newest.pt'.
Saved model with best loss 1.4213 to 'data/predictions/almnps_8857/embedding/ood/politics/best.pt'.
[Epoch 6/50] Train completed with Micro-f1: 0.9656, Macro-f1: 0.9389, Weighted-f1: 0.9624, Loss: 0.2039
[Epoch 6/50] Evaluation completed with Micro-f1: 0.5497, Macro-f1: 0.3865, Weighted-f1: 0.5163, Loss: 1.5327
Saved models from epoch 6 to 'data/predictions/almnps_8857/embedding/ood/politics/newest.pt'.
[Epoch 7/50] Train completed with Micro-f1: 0.9851, Macro-f1: 0.9650, Weighted-f1: 0.9833, Loss: 0.1350
[Epoch 7/50] Evaluation completed with Micro-f1: 0.5563, Macro-f1: 0.3937, Weighted-f1: 0.5246, Loss: 1.4799
Saved models from epoch 7 to 'data/predictions/almnps_8857/embedding/ood/politics/newest.pt'.
[Epoch 8/50] Train completed with Micro-f1: 0.9911, Macro-f1: 0.9809, Weighted-f1: 0.9907, Loss: 0.0892
[Epoch 8/50] Evaluation completed with Micro-f1: 0.5619, Macro-f1: 0.4001, Weighted-f1: 0.5314, Loss: 1.5383
Saved models from epoch 8 to 'data/predictions/almnps_8857/embedding/ood/politics/newest.pt'.
No improvement since 3 epochs (1.4213 loss). Early stop.
OOD training completed for test topic politics after 8 epochs.
Loaded <torch.utils.data.dataloader.DataLoader object at 0x7f1430b2caf0> (train).
Loaded <torch.utils.data.dataloader.DataLoader object at 0x7f142859b3d0> (dev).
Starting training on ['ai', 'literature', 'music', 'news', 'politics'] data.
Loaded <TransformerEmbeddings: dim=768>.
Using classifier: <LinearClassifier: emb_model = <TransformerEmbeddings: dim=768>>
Using criterion: <LabelLoss: loss=XEnt>.
Optimizing using: AdamW with learning rate 2e-05.
[Epoch 1/50] Train completed with Micro-f1: 0.3732, Macro-f1: 0.2133, Weighted-f1: 0.3047, Loss: 2.1101
[Epoch 1/50] Evaluation completed with Micro-f1: 0.5270, Macro-f1: 0.3480, Weighted-f1: 0.4787, Loss: 1.6585
Saved models from epoch 1 to 'data/predictions/almnps_8857/embedding/ood/science/newest.pt'.
Saved model with best loss 1.6585 to 'data/predictions/almnps_8857/embedding/ood/science/best.pt'.
[Epoch 2/50] Train completed with Micro-f1: 0.6764, Macro-f1: 0.5184, Weighted-f1: 0.6412, Loss: 1.1649
[Epoch 2/50] Evaluation completed with Micro-f1: 0.5455, Macro-f1: 0.3684, Weighted-f1: 0.5032, Loss: 1.4661
Saved models from epoch 2 to 'data/predictions/almnps_8857/embedding/ood/science/newest.pt'.
Saved model with best loss 1.4661 to 'data/predictions/almnps_8857/embedding/ood/science/best.pt'.
[Epoch 3/50] Train completed with Micro-f1: 0.8145, Macro-f1: 0.7084, Weighted-f1: 0.7940, Loss: 0.7393
[Epoch 3/50] Evaluation completed with Micro-f1: 0.5549, Macro-f1: 0.3820, Weighted-f1: 0.5163, Loss: 1.4000
Saved models from epoch 3 to 'data/predictions/almnps_8857/embedding/ood/science/newest.pt'.
Saved model with best loss 1.4000 to 'data/predictions/almnps_8857/embedding/ood/science/best.pt'.
[Epoch 4/50] Train completed with Micro-f1: 0.8859, Macro-f1: 0.7924, Weighted-f1: 0.8752, Loss: 0.4805
[Epoch 4/50] Evaluation completed with Micro-f1: 0.5662, Macro-f1: 0.3965, Weighted-f1: 0.5311, Loss: 1.3764
Saved models from epoch 4 to 'data/predictions/almnps_8857/embedding/ood/science/newest.pt'.
Saved model with best loss 1.3764 to 'data/predictions/almnps_8857/embedding/ood/science/best.pt'.
[Epoch 5/50] Train completed with Micro-f1: 0.9369, Macro-f1: 0.8878, Weighted-f1: 0.9334, Loss: 0.3060
[Epoch 5/50] Evaluation completed with Micro-f1: 0.5738, Macro-f1: 0.4078, Weighted-f1: 0.5412, Loss: 1.3838
Saved models from epoch 5 to 'data/predictions/almnps_8857/embedding/ood/science/newest.pt'.
[Epoch 6/50] Train completed with Micro-f1: 0.9671, Macro-f1: 0.9458, Weighted-f1: 0.9650, Loss: 0.2002
[Epoch 6/50] Evaluation completed with Micro-f1: 0.5802, Macro-f1: 0.4167, Weighted-f1: 0.5500, Loss: 1.4402
Saved models from epoch 6 to 'data/predictions/almnps_8857/embedding/ood/science/newest.pt'.
[Epoch 7/50] Train completed with Micro-f1: 0.9864, Macro-f1: 0.9712, Weighted-f1: 0.9845, Loss: 0.1370
[Epoch 7/50] Evaluation completed with Micro-f1: 0.5837, Macro-f1: 0.4219, Weighted-f1: 0.5557, Loss: 1.4437
Saved models from epoch 7 to 'data/predictions/almnps_8857/embedding/ood/science/newest.pt'.
No improvement since 3 epochs (1.3764 loss). Early stop.
OOD training completed for test topic science after 7 epochs.
TRAINING COMPLETED with:
	Domains:		['ai', 'literature', 'music', 'news', 'politics', 'science']
	OOD validaation:	True
	Mapping type:		embedding
