Saved arguments to data/predictions/almnps_8857/no_mapping/ood/args.json.
Saved category mapping to data/predictions/almnps_8857/no_mapping/ood/mapping.json.
Loaded category mapping: no_mapping.
Loaded <torch.utils.data.dataloader.DataLoader object at 0x7fab100608b0> (train).
Loaded <torch.utils.data.dataloader.DataLoader object at 0x7fab10060eb0> (dev).
Starting training on ['literature', 'music', 'news', 'politics', 'science'] data.
Loaded <TransformerEmbeddings: dim=768>.
Using classifier: <LinearClassifier: emb_model = <TransformerEmbeddings: dim=768>>
Using criterion: <LabelLoss: loss=XEnt>.
Optimizing using: AdamW with learning rate 2e-05.
[Epoch 1/50] Train completed with Micro-f1: 0.3776, Macro-f1: 0.1904, Weighted-f1: 0.2898, Loss: 2.1266
[Epoch 1/50] Evaluation completed with Micro-f1: 0.5025, Macro-f1: 0.3189, Weighted-f1: 0.4419, Loss: 1.7791
Saved models from epoch 1 to 'data/predictions/almnps_8857/no_mapping/ood/ai/newest.pt'.
Saved model with best loss 1.7791 to 'data/predictions/almnps_8857/no_mapping/ood/ai/best.pt'.
[Epoch 2/50] Train completed with Micro-f1: 0.6865, Macro-f1: 0.5151, Weighted-f1: 0.6372, Loss: 1.1368
[Epoch 2/50] Evaluation completed with Micro-f1: 0.5267, Macro-f1: 0.3417, Weighted-f1: 0.4717, Loss: 1.5541
Saved models from epoch 2 to 'data/predictions/almnps_8857/no_mapping/ood/ai/newest.pt'.
Saved model with best loss 1.5541 to 'data/predictions/almnps_8857/no_mapping/ood/ai/best.pt'.
[Epoch 3/50] Train completed with Micro-f1: 0.8443, Macro-f1: 0.7389, Weighted-f1: 0.8264, Loss: 0.6697
[Epoch 3/50] Evaluation completed with Micro-f1: 0.5412, Macro-f1: 0.3583, Weighted-f1: 0.4902, Loss: 1.4610
Saved models from epoch 3 to 'data/predictions/almnps_8857/no_mapping/ood/ai/newest.pt'.
Saved model with best loss 1.4610 to 'data/predictions/almnps_8857/no_mapping/ood/ai/best.pt'.
[Epoch 4/50] Train completed with Micro-f1: 0.8955, Macro-f1: 0.8185, Weighted-f1: 0.8842, Loss: 0.4422
[Epoch 4/50] Evaluation completed with Micro-f1: 0.5524, Macro-f1: 0.3742, Weighted-f1: 0.5060, Loss: 1.4629
Saved models from epoch 4 to 'data/predictions/almnps_8857/no_mapping/ood/ai/newest.pt'.
[Epoch 5/50] Train completed with Micro-f1: 0.9472, Macro-f1: 0.8958, Weighted-f1: 0.9435, Loss: 0.2786
[Epoch 5/50] Evaluation completed with Micro-f1: 0.5612, Macro-f1: 0.3869, Weighted-f1: 0.5184, Loss: 1.5037
Saved models from epoch 5 to 'data/predictions/almnps_8857/no_mapping/ood/ai/newest.pt'.
[Epoch 6/50] Train completed with Micro-f1: 0.9785, Macro-f1: 0.9501, Weighted-f1: 0.9760, Loss: 0.1781
[Epoch 6/50] Evaluation completed with Micro-f1: 0.5671, Macro-f1: 0.3929, Weighted-f1: 0.5253, Loss: 1.5316
Saved models from epoch 6 to 'data/predictions/almnps_8857/no_mapping/ood/ai/newest.pt'.
No improvement since 3 epochs (1.4610 loss). Early stop.
OOD training completed for test topic ai after 6 epochs.
Loaded <torch.utils.data.dataloader.DataLoader object at 0x7fab11a9c7f0> (train).
Loaded <torch.utils.data.dataloader.DataLoader object at 0x7fab10060d30> (dev).
Starting training on ['ai', 'music', 'news', 'politics', 'science'] data.
Loaded <TransformerEmbeddings: dim=768>.
Using classifier: <LinearClassifier: emb_model = <TransformerEmbeddings: dim=768>>
Using criterion: <LabelLoss: loss=XEnt>.
Optimizing using: AdamW with learning rate 2e-05.
[Epoch 1/50] Train completed with Micro-f1: 0.3632, Macro-f1: 0.2001, Weighted-f1: 0.2970, Loss: 2.1635
[Epoch 1/50] Evaluation completed with Micro-f1: 0.4929, Macro-f1: 0.3325, Weighted-f1: 0.4524, Loss: 1.7570
Saved models from epoch 1 to 'data/predictions/almnps_8857/no_mapping/ood/literature/newest.pt'.
Saved model with best loss 1.7570 to 'data/predictions/almnps_8857/no_mapping/ood/literature/best.pt'.
[Epoch 2/50] Train completed with Micro-f1: 0.6900, Macro-f1: 0.5482, Weighted-f1: 0.6575, Loss: 1.1696
[Epoch 2/50] Evaluation completed with Micro-f1: 0.5116, Macro-f1: 0.3509, Weighted-f1: 0.4723, Loss: 1.5415
Saved models from epoch 2 to 'data/predictions/almnps_8857/no_mapping/ood/literature/newest.pt'.
Saved model with best loss 1.5415 to 'data/predictions/almnps_8857/no_mapping/ood/literature/best.pt'.
[Epoch 3/50] Train completed with Micro-f1: 0.8175, Macro-f1: 0.7255, Weighted-f1: 0.8033, Loss: 0.7050
[Epoch 3/50] Evaluation completed with Micro-f1: 0.5287, Macro-f1: 0.3694, Weighted-f1: 0.4936, Loss: 1.4386
Saved models from epoch 3 to 'data/predictions/almnps_8857/no_mapping/ood/literature/newest.pt'.
Saved model with best loss 1.4386 to 'data/predictions/almnps_8857/no_mapping/ood/literature/best.pt'.
[Epoch 4/50] Train completed with Micro-f1: 0.8977, Macro-f1: 0.8292, Weighted-f1: 0.8912, Loss: 0.4336
[Epoch 4/50] Evaluation completed with Micro-f1: 0.5405, Macro-f1: 0.3825, Weighted-f1: 0.5067, Loss: 1.4596
Saved models from epoch 4 to 'data/predictions/almnps_8857/no_mapping/ood/literature/newest.pt'.
[Epoch 5/50] Train completed with Micro-f1: 0.9526, Macro-f1: 0.9120, Weighted-f1: 0.9492, Loss: 0.2665
[Epoch 5/50] Evaluation completed with Micro-f1: 0.5490, Macro-f1: 0.3920, Weighted-f1: 0.5159, Loss: 1.4624
Saved models from epoch 5 to 'data/predictions/almnps_8857/no_mapping/ood/literature/newest.pt'.
[Epoch 6/50] Train completed with Micro-f1: 0.9796, Macro-f1: 0.9584, Weighted-f1: 0.9788, Loss: 0.1693
[Epoch 6/50] Evaluation completed with Micro-f1: 0.5554, Macro-f1: 0.3995, Weighted-f1: 0.5246, Loss: 1.4780
Saved models from epoch 6 to 'data/predictions/almnps_8857/no_mapping/ood/literature/newest.pt'.
No improvement since 3 epochs (1.4386 loss). Early stop.
OOD training completed for test topic literature after 6 epochs.
Loaded <torch.utils.data.dataloader.DataLoader object at 0x7fab0fd76340> (train).
Loaded <torch.utils.data.dataloader.DataLoader object at 0x7fab11b45040> (dev).
Starting training on ['ai', 'literature', 'news', 'politics', 'science'] data.
Loaded <TransformerEmbeddings: dim=768>.
Using classifier: <LinearClassifier: emb_model = <TransformerEmbeddings: dim=768>>
Using criterion: <LabelLoss: loss=XEnt>.
Optimizing using: AdamW with learning rate 2e-05.
