Saved arguments to data/predictions/almnps_8857/ood_embedding/ood/args.json.
loading projection weights from /home/davidsule/gensim-data/word2vec-google-news-300/word2vec-google-news-300.gz
KeyedVectors lifecycle event {'msg': 'loaded (3000000, 300) matrix of type float32 from /home/davidsule/gensim-data/word2vec-google-news-300/word2vec-google-news-300.gz', 'binary': True, 'encoding': 'utf8', 'datetime': '2023-05-08T11:25:39.795550', 'gensim': '4.3.0', 'python': '3.9.16 | packaged by conda-forge | (main, Feb  1 2023, 21:39:03) \n[GCC 11.3.0]', 'platform': 'Linux-5.15.90.1-microsoft-standard-WSL2-x86_64-with-glibc2.31', 'event': 'load_word2vec_format'}
Saved category mapping to data/predictions/almnps_8857/ood_embedding/ood/mapping.json.
Loaded category mapping: ood_embedding.
Loaded <torch.utils.data.dataloader.DataLoader object at 0x7f4553a906d0> (train).
Loaded <torch.utils.data.dataloader.DataLoader object at 0x7f4553a90340> (dev).
Starting training on ['literature', 'music', 'news', 'politics', 'science'] data.
Loaded <TransformerEmbeddings: dim=768>.
Using classifier: <LinearClassifier: emb_model = <TransformerEmbeddings: dim=768>>
Using criterion: <LabelLoss: loss=XEnt>.
Optimizing using: AdamW with learning rate 2e-05.
[Epoch 1/50] Train completed with Micro-f1: 0.4047, Macro-f1: 0.2175, Weighted-f1: 0.3261, Loss: 2.0591
[Epoch 1/50] Evaluation completed with Micro-f1: 0.5074, Macro-f1: 0.3223, Weighted-f1: 0.4539, Loss: 1.7115
Saved models from epoch 1 to 'data/predictions/almnps_8857/ood_embedding/ood/ai/newest.pt'.
Saved model with best loss 1.7115 to 'data/predictions/almnps_8857/ood_embedding/ood/ai/best.pt'.
[Epoch 2/50] Train completed with Micro-f1: 0.6967, Macro-f1: 0.5462, Weighted-f1: 0.6624, Loss: 1.0768
[Epoch 2/50] Evaluation completed with Micro-f1: 0.5285, Macro-f1: 0.3518, Weighted-f1: 0.4795, Loss: 1.5333
Saved models from epoch 2 to 'data/predictions/almnps_8857/ood_embedding/ood/ai/newest.pt'.
Saved model with best loss 1.5333 to 'data/predictions/almnps_8857/ood_embedding/ood/ai/best.pt'.
[Epoch 3/50] Train completed with Micro-f1: 0.8258, Macro-f1: 0.7091, Weighted-f1: 0.8077, Loss: 0.6579
[Epoch 3/50] Evaluation completed with Micro-f1: 0.5419, Macro-f1: 0.3695, Weighted-f1: 0.4977, Loss: 1.4470
Saved models from epoch 3 to 'data/predictions/almnps_8857/ood_embedding/ood/ai/newest.pt'.
Saved model with best loss 1.4470 to 'data/predictions/almnps_8857/ood_embedding/ood/ai/best.pt'.
[Epoch 4/50] Train completed with Micro-f1: 0.9016, Macro-f1: 0.8335, Weighted-f1: 0.8957, Loss: 0.4249
[Epoch 4/50] Evaluation completed with Micro-f1: 0.5529, Macro-f1: 0.3835, Weighted-f1: 0.5121, Loss: 1.4560
Saved models from epoch 4 to 'data/predictions/almnps_8857/ood_embedding/ood/ai/newest.pt'.
[Epoch 5/50] Train completed with Micro-f1: 0.9524, Macro-f1: 0.9007, Weighted-f1: 0.9477, Loss: 0.2551
[Epoch 5/50] Evaluation completed with Micro-f1: 0.5607, Macro-f1: 0.3944, Weighted-f1: 0.5221, Loss: 1.4944
Saved models from epoch 5 to 'data/predictions/almnps_8857/ood_embedding/ood/ai/newest.pt'.
[Epoch 6/50] Train completed with Micro-f1: 0.9785, Macro-f1: 0.9569, Weighted-f1: 0.9766, Loss: 0.1578
[Epoch 6/50] Evaluation completed with Micro-f1: 0.5659, Macro-f1: 0.4004, Weighted-f1: 0.5289, Loss: 1.5585
Saved models from epoch 6 to 'data/predictions/almnps_8857/ood_embedding/ood/ai/newest.pt'.
No improvement since 3 epochs (1.4470 loss). Early stop.
OOD training completed for test topic ai after 6 epochs.
Loaded <torch.utils.data.dataloader.DataLoader object at 0x7f44f35ce370> (train).
Loaded <torch.utils.data.dataloader.DataLoader object at 0x7f4553a909d0> (dev).
Starting training on ['ai', 'music', 'news', 'politics', 'science'] data.
Loaded <TransformerEmbeddings: dim=768>.
Using classifier: <LinearClassifier: emb_model = <TransformerEmbeddings: dim=768>>
Using criterion: <LabelLoss: loss=XEnt>.
Optimizing using: AdamW with learning rate 2e-05.
[Epoch 1/50] Train completed with Micro-f1: 0.3624, Macro-f1: 0.1972, Weighted-f1: 0.2956, Loss: 2.1522
[Epoch 1/50] Evaluation completed with Micro-f1: 0.4534, Macro-f1: 0.3116, Weighted-f1: 0.4171, Loss: 1.8547
Saved models from epoch 1 to 'data/predictions/almnps_8857/ood_embedding/ood/literature/newest.pt'.
Saved model with best loss 1.8547 to 'data/predictions/almnps_8857/ood_embedding/ood/literature/best.pt'.
[Epoch 2/50] Train completed with Micro-f1: 0.6755, Macro-f1: 0.5296, Weighted-f1: 0.6428, Loss: 1.1874
[Epoch 2/50] Evaluation completed with Micro-f1: 0.4797, Macro-f1: 0.3316, Weighted-f1: 0.4443, Loss: 1.5923
Saved models from epoch 2 to 'data/predictions/almnps_8857/ood_embedding/ood/literature/newest.pt'.
Saved model with best loss 1.5923 to 'data/predictions/almnps_8857/ood_embedding/ood/literature/best.pt'.
[Epoch 3/50] Train completed with Micro-f1: 0.8085, Macro-f1: 0.7072, Weighted-f1: 0.7943, Loss: 0.7417
[Epoch 3/50] Evaluation completed with Micro-f1: 0.4976, Macro-f1: 0.3479, Weighted-f1: 0.4637, Loss: 1.5465
Saved models from epoch 3 to 'data/predictions/almnps_8857/ood_embedding/ood/literature/newest.pt'.
Saved model with best loss 1.5465 to 'data/predictions/almnps_8857/ood_embedding/ood/literature/best.pt'.
[Epoch 4/50] Train completed with Micro-f1: 0.8914, Macro-f1: 0.8270, Weighted-f1: 0.8842, Loss: 0.4722
[Epoch 4/50] Evaluation completed with Micro-f1: 0.5129, Macro-f1: 0.3612, Weighted-f1: 0.4806, Loss: 1.4967
Saved models from epoch 4 to 'data/predictions/almnps_8857/ood_embedding/ood/literature/newest.pt'.
Saved model with best loss 1.4967 to 'data/predictions/almnps_8857/ood_embedding/ood/literature/best.pt'.
[Epoch 5/50] Train completed with Micro-f1: 0.9433, Macro-f1: 0.8890, Weighted-f1: 0.9388, Loss: 0.3099
[Epoch 5/50] Evaluation completed with Micro-f1: 0.5236, Macro-f1: 0.3732, Weighted-f1: 0.4939, Loss: 1.5214
Saved models from epoch 5 to 'data/predictions/almnps_8857/ood_embedding/ood/literature/newest.pt'.
[Epoch 6/50] Train completed with Micro-f1: 0.9722, Macro-f1: 0.9476, Weighted-f1: 0.9703, Loss: 0.1934
[Epoch 6/50] Evaluation completed with Micro-f1: 0.5313, Macro-f1: 0.3802, Weighted-f1: 0.5023, Loss: 1.5305
Saved models from epoch 6 to 'data/predictions/almnps_8857/ood_embedding/ood/literature/newest.pt'.
[Epoch 7/50] Train completed with Micro-f1: 0.9862, Macro-f1: 0.9683, Weighted-f1: 0.9844, Loss: 0.1221
[Epoch 7/50] Evaluation completed with Micro-f1: 0.5375, Macro-f1: 0.3863, Weighted-f1: 0.5094, Loss: 1.6085
Saved models from epoch 7 to 'data/predictions/almnps_8857/ood_embedding/ood/literature/newest.pt'.
No improvement since 3 epochs (1.4967 loss). Early stop.
OOD training completed for test topic literature after 7 epochs.
Loaded <torch.utils.data.dataloader.DataLoader object at 0x7f456d0f5c10> (train).
Loaded <torch.utils.data.dataloader.DataLoader object at 0x7f44f3591cd0> (dev).
Starting training on ['ai', 'literature', 'news', 'politics', 'science'] data.
Loaded <TransformerEmbeddings: dim=768>.
Using classifier: <LinearClassifier: emb_model = <TransformerEmbeddings: dim=768>>
Using criterion: <LabelLoss: loss=XEnt>.
Optimizing using: AdamW with learning rate 2e-05.
[Epoch 1/50] Train completed with Micro-f1: 0.3338, Macro-f1: 0.1951, Weighted-f1: 0.2658, Loss: 2.2250
[Epoch 1/50] Evaluation completed with Micro-f1: 0.4399, Macro-f1: 0.2731, Weighted-f1: 0.3883, Loss: 1.9369
Saved models from epoch 1 to 'data/predictions/almnps_8857/ood_embedding/ood/music/newest.pt'.
Saved model with best loss 1.9369 to 'data/predictions/almnps_8857/ood_embedding/ood/music/best.pt'.
[Epoch 2/50] Train completed with Micro-f1: 0.6462, Macro-f1: 0.5007, Weighted-f1: 0.6099, Loss: 1.3248
[Epoch 2/50] Evaluation completed with Micro-f1: 0.4590, Macro-f1: 0.3025, Weighted-f1: 0.4176, Loss: 1.7195
Saved models from epoch 2 to 'data/predictions/almnps_8857/ood_embedding/ood/music/newest.pt'.
Saved model with best loss 1.7195 to 'data/predictions/almnps_8857/ood_embedding/ood/music/best.pt'.
[Epoch 3/50] Train completed with Micro-f1: 0.7935, Macro-f1: 0.6886, Weighted-f1: 0.7728, Loss: 0.8554
[Epoch 3/50] Evaluation completed with Micro-f1: 0.4710, Macro-f1: 0.3171, Weighted-f1: 0.4347, Loss: 1.6698
Saved models from epoch 3 to 'data/predictions/almnps_8857/ood_embedding/ood/music/newest.pt'.
Saved model with best loss 1.6698 to 'data/predictions/almnps_8857/ood_embedding/ood/music/best.pt'.
[Epoch 4/50] Train completed with Micro-f1: 0.8762, Macro-f1: 0.7769, Weighted-f1: 0.8651, Loss: 0.5652
[Epoch 4/50] Evaluation completed with Micro-f1: 0.4827, Macro-f1: 0.3311, Weighted-f1: 0.4497, Loss: 1.6079
Saved models from epoch 4 to 'data/predictions/almnps_8857/ood_embedding/ood/music/newest.pt'.
Saved model with best loss 1.6079 to 'data/predictions/almnps_8857/ood_embedding/ood/music/best.pt'.
[Epoch 5/50] Train completed with Micro-f1: 0.9278, Macro-f1: 0.8740, Weighted-f1: 0.9211, Loss: 0.3693
[Epoch 5/50] Evaluation completed with Micro-f1: 0.4919, Macro-f1: 0.3435, Weighted-f1: 0.4625, Loss: 1.6253
Saved models from epoch 5 to 'data/predictions/almnps_8857/ood_embedding/ood/music/newest.pt'.
[Epoch 6/50] Train completed with Micro-f1: 0.9704, Macro-f1: 0.9433, Weighted-f1: 0.9667, Loss: 0.2275
[Epoch 6/50] Evaluation completed with Micro-f1: 0.4980, Macro-f1: 0.3513, Weighted-f1: 0.4699, Loss: 1.6301
Saved models from epoch 6 to 'data/predictions/almnps_8857/ood_embedding/ood/music/newest.pt'.
[Epoch 7/50] Train completed with Micro-f1: 0.9827, Macro-f1: 0.9684, Weighted-f1: 0.9817, Loss: 0.1547
[Epoch 7/50] Evaluation completed with Micro-f1: 0.5023, Macro-f1: 0.3586, Weighted-f1: 0.4766, Loss: 1.6739
Saved models from epoch 7 to 'data/predictions/almnps_8857/ood_embedding/ood/music/newest.pt'.
No improvement since 3 epochs (1.6079 loss). Early stop.
OOD training completed for test topic music after 7 epochs.
Loaded <torch.utils.data.dataloader.DataLoader object at 0x7f456431cc70> (train).
Loaded <torch.utils.data.dataloader.DataLoader object at 0x7f456d0f5760> (dev).
Starting training on ['ai', 'literature', 'music', 'politics', 'science'] data.
Loaded <TransformerEmbeddings: dim=768>.
Using classifier: <LinearClassifier: emb_model = <TransformerEmbeddings: dim=768>>
Using criterion: <LabelLoss: loss=XEnt>.
Optimizing using: AdamW with learning rate 2e-05.
[Epoch 1/50] Train completed with Micro-f1: 0.3566, Macro-f1: 0.2142, Weighted-f1: 0.3033, Loss: 2.1121
[Epoch 1/50] Evaluation completed with Micro-f1: 0.4847, Macro-f1: 0.3230, Weighted-f1: 0.4427, Loss: 1.7976
Saved models from epoch 1 to 'data/predictions/almnps_8857/ood_embedding/ood/news/newest.pt'.
Saved model with best loss 1.7976 to 'data/predictions/almnps_8857/ood_embedding/ood/news/best.pt'.
[Epoch 2/50] Train completed with Micro-f1: 0.6829, Macro-f1: 0.5391, Weighted-f1: 0.6506, Loss: 1.1778
[Epoch 2/50] Evaluation completed with Micro-f1: 0.5156, Macro-f1: 0.3560, Weighted-f1: 0.4768, Loss: 1.5316
Saved models from epoch 2 to 'data/predictions/almnps_8857/ood_embedding/ood/news/newest.pt'.
Saved model with best loss 1.5316 to 'data/predictions/almnps_8857/ood_embedding/ood/news/best.pt'.
[Epoch 3/50] Train completed with Micro-f1: 0.8321, Macro-f1: 0.7417, Weighted-f1: 0.8177, Loss: 0.7102
[Epoch 3/50] Evaluation completed with Micro-f1: 0.5303, Macro-f1: 0.3759, Weighted-f1: 0.4947, Loss: 1.4846
Saved models from epoch 3 to 'data/predictions/almnps_8857/ood_embedding/ood/news/newest.pt'.
Saved model with best loss 1.4846 to 'data/predictions/almnps_8857/ood_embedding/ood/news/best.pt'.
[Epoch 4/50] Train completed with Micro-f1: 0.9050, Macro-f1: 0.8436, Weighted-f1: 0.8962, Loss: 0.4485
[Epoch 4/50] Evaluation completed with Micro-f1: 0.5412, Macro-f1: 0.3880, Weighted-f1: 0.5082, Loss: 1.4509
Saved models from epoch 4 to 'data/predictions/almnps_8857/ood_embedding/ood/news/newest.pt'.
Saved model with best loss 1.4509 to 'data/predictions/almnps_8857/ood_embedding/ood/news/best.pt'.
[Epoch 5/50] Train completed with Micro-f1: 0.9504, Macro-f1: 0.9073, Weighted-f1: 0.9460, Loss: 0.2850
[Epoch 5/50] Evaluation completed with Micro-f1: 0.5515, Macro-f1: 0.4007, Weighted-f1: 0.5197, Loss: 1.4659
Saved models from epoch 5 to 'data/predictions/almnps_8857/ood_embedding/ood/news/newest.pt'.
[Epoch 6/50] Train completed with Micro-f1: 0.9782, Macro-f1: 0.9558, Weighted-f1: 0.9752, Loss: 0.1747
[Epoch 6/50] Evaluation completed with Micro-f1: 0.5600, Macro-f1: 0.4107, Weighted-f1: 0.5302, Loss: 1.4591
Saved models from epoch 6 to 'data/predictions/almnps_8857/ood_embedding/ood/news/newest.pt'.
[Epoch 7/50] Train completed with Micro-f1: 0.9882, Macro-f1: 0.9776, Weighted-f1: 0.9871, Loss: 0.1187
[Epoch 7/50] Evaluation completed with Micro-f1: 0.5657, Macro-f1: 0.4172, Weighted-f1: 0.5374, Loss: 1.4929
Saved models from epoch 7 to 'data/predictions/almnps_8857/ood_embedding/ood/news/newest.pt'.
No improvement since 3 epochs (1.4509 loss). Early stop.
OOD training completed for test topic news after 7 epochs.
Loaded <torch.utils.data.dataloader.DataLoader object at 0x7f45537c1d90> (train).
Loaded <torch.utils.data.dataloader.DataLoader object at 0x7f456431ce20> (dev).
Starting training on ['ai', 'literature', 'music', 'news', 'science'] data.
Loaded <TransformerEmbeddings: dim=768>.
Using classifier: <LinearClassifier: emb_model = <TransformerEmbeddings: dim=768>>
Using criterion: <LabelLoss: loss=XEnt>.
Optimizing using: AdamW with learning rate 2e-05.
[Epoch 1/50] Train completed with Micro-f1: 0.3571, Macro-f1: 0.2017, Weighted-f1: 0.2999, Loss: 2.1753
[Epoch 1/50] Evaluation completed with Micro-f1: 0.4654, Macro-f1: 0.2964, Weighted-f1: 0.4146, Loss: 1.8114
Saved models from epoch 1 to 'data/predictions/almnps_8857/ood_embedding/ood/politics/newest.pt'.
Saved model with best loss 1.8114 to 'data/predictions/almnps_8857/ood_embedding/ood/politics/best.pt'.
[Epoch 2/50] Train completed with Micro-f1: 0.6516, Macro-f1: 0.4892, Weighted-f1: 0.6130, Loss: 1.2529
[Epoch 2/50] Evaluation completed with Micro-f1: 0.5029, Macro-f1: 0.3313, Weighted-f1: 0.4595, Loss: 1.5435
Saved models from epoch 2 to 'data/predictions/almnps_8857/ood_embedding/ood/politics/newest.pt'.
Saved model with best loss 1.5435 to 'data/predictions/almnps_8857/ood_embedding/ood/politics/best.pt'.
[Epoch 3/50] Train completed with Micro-f1: 0.8077, Macro-f1: 0.6919, Weighted-f1: 0.7910, Loss: 0.7795
[Epoch 3/50] Evaluation completed with Micro-f1: 0.5260, Macro-f1: 0.3559, Weighted-f1: 0.4866, Loss: 1.4297
Saved models from epoch 3 to 'data/predictions/almnps_8857/ood_embedding/ood/politics/newest.pt'.
Saved model with best loss 1.4297 to 'data/predictions/almnps_8857/ood_embedding/ood/politics/best.pt'.
[Epoch 4/50] Train completed with Micro-f1: 0.8867, Macro-f1: 0.8167, Weighted-f1: 0.8769, Loss: 0.5101
[Epoch 4/50] Evaluation completed with Micro-f1: 0.5383, Macro-f1: 0.3693, Weighted-f1: 0.5018, Loss: 1.4063
Saved models from epoch 4 to 'data/predictions/almnps_8857/ood_embedding/ood/politics/newest.pt'.
Saved model with best loss 1.4063 to 'data/predictions/almnps_8857/ood_embedding/ood/politics/best.pt'.
[Epoch 5/50] Train completed with Micro-f1: 0.9327, Macro-f1: 0.8919, Weighted-f1: 0.9276, Loss: 0.3405
[Epoch 5/50] Evaluation completed with Micro-f1: 0.5489, Macro-f1: 0.3818, Weighted-f1: 0.5146, Loss: 1.3944
Saved models from epoch 5 to 'data/predictions/almnps_8857/ood_embedding/ood/politics/newest.pt'.
Saved model with best loss 1.3944 to 'data/predictions/almnps_8857/ood_embedding/ood/politics/best.pt'.
[Epoch 6/50] Train completed with Micro-f1: 0.9639, Macro-f1: 0.9337, Weighted-f1: 0.9603, Loss: 0.2173
[Epoch 6/50] Evaluation completed with Micro-f1: 0.5566, Macro-f1: 0.3901, Weighted-f1: 0.5242, Loss: 1.4147
Saved models from epoch 6 to 'data/predictions/almnps_8857/ood_embedding/ood/politics/newest.pt'.
[Epoch 7/50] Train completed with Micro-f1: 0.9855, Macro-f1: 0.9700, Weighted-f1: 0.9846, Loss: 0.1349
[Epoch 7/50] Evaluation completed with Micro-f1: 0.5638, Macro-f1: 0.3988, Weighted-f1: 0.5331, Loss: 1.4176
Saved models from epoch 7 to 'data/predictions/almnps_8857/ood_embedding/ood/politics/newest.pt'.
[Epoch 8/50] Train completed with Micro-f1: 0.9916, Macro-f1: 0.9814, Weighted-f1: 0.9916, Loss: 0.0916
[Epoch 8/50] Evaluation completed with Micro-f1: 0.5687, Macro-f1: 0.4059, Weighted-f1: 0.5402, Loss: 1.4350
Saved models from epoch 8 to 'data/predictions/almnps_8857/ood_embedding/ood/politics/newest.pt'.
No improvement since 3 epochs (1.3944 loss). Early stop.
OOD training completed for test topic politics after 8 epochs.
Loaded <torch.utils.data.dataloader.DataLoader object at 0x7f450bdb69d0> (train).
Loaded <torch.utils.data.dataloader.DataLoader object at 0x7f45537c1550> (dev).
Starting training on ['ai', 'literature', 'music', 'news', 'politics'] data.
Loaded <TransformerEmbeddings: dim=768>.
Using classifier: <LinearClassifier: emb_model = <TransformerEmbeddings: dim=768>>
Using criterion: <LabelLoss: loss=XEnt>.
Optimizing using: AdamW with learning rate 2e-05.
[Epoch 1/50] Train completed with Micro-f1: 0.3644, Macro-f1: 0.2123, Weighted-f1: 0.2972, Loss: 2.1727
[Epoch 1/50] Evaluation completed with Micro-f1: 0.5235, Macro-f1: 0.3489, Weighted-f1: 0.4773, Loss: 1.7279
Saved models from epoch 1 to 'data/predictions/almnps_8857/ood_embedding/ood/science/newest.pt'.
Saved model with best loss 1.7279 to 'data/predictions/almnps_8857/ood_embedding/ood/science/best.pt'.
[Epoch 2/50] Train completed with Micro-f1: 0.6790, Macro-f1: 0.5219, Weighted-f1: 0.6464, Loss: 1.1704
[Epoch 2/50] Evaluation completed with Micro-f1: 0.5397, Macro-f1: 0.3669, Weighted-f1: 0.4966, Loss: 1.4968
Saved models from epoch 2 to 'data/predictions/almnps_8857/ood_embedding/ood/science/newest.pt'.
Saved model with best loss 1.4968 to 'data/predictions/almnps_8857/ood_embedding/ood/science/best.pt'.
[Epoch 3/50] Train completed with Micro-f1: 0.8234, Macro-f1: 0.7153, Weighted-f1: 0.8010, Loss: 0.7105
[Epoch 3/50] Evaluation completed with Micro-f1: 0.5522, Macro-f1: 0.3840, Weighted-f1: 0.5146, Loss: 1.4350
Saved models from epoch 3 to 'data/predictions/almnps_8857/ood_embedding/ood/science/newest.pt'.
Saved model with best loss 1.4350 to 'data/predictions/almnps_8857/ood_embedding/ood/science/best.pt'.
[Epoch 4/50] Train completed with Micro-f1: 0.9005, Macro-f1: 0.8212, Weighted-f1: 0.8901, Loss: 0.4374
[Epoch 4/50] Evaluation completed with Micro-f1: 0.5617, Macro-f1: 0.3937, Weighted-f1: 0.5263, Loss: 1.4289
Saved models from epoch 4 to 'data/predictions/almnps_8857/ood_embedding/ood/science/newest.pt'.
Saved model with best loss 1.4289 to 'data/predictions/almnps_8857/ood_embedding/ood/science/best.pt'.
[Epoch 5/50] Train completed with Micro-f1: 0.9500, Macro-f1: 0.9023, Weighted-f1: 0.9441, Loss: 0.2726
[Epoch 5/50] Evaluation completed with Micro-f1: 0.5682, Macro-f1: 0.4033, Weighted-f1: 0.5352, Loss: 1.5307
Saved models from epoch 5 to 'data/predictions/almnps_8857/ood_embedding/ood/science/newest.pt'.
[Epoch 6/50] Train completed with Micro-f1: 0.9739, Macro-f1: 0.9508, Weighted-f1: 0.9709, Loss: 0.1796
[Epoch 6/50] Evaluation completed with Micro-f1: 0.5735, Macro-f1: 0.4119, Weighted-f1: 0.5437, Loss: 1.4574
Saved models from epoch 6 to 'data/predictions/almnps_8857/ood_embedding/ood/science/newest.pt'.
[Epoch 7/50] Train completed with Micro-f1: 0.9885, Macro-f1: 0.9791, Weighted-f1: 0.9870, Loss: 0.1136
[Epoch 7/50] Evaluation completed with Micro-f1: 0.5782, Macro-f1: 0.4190, Weighted-f1: 0.5500, Loss: 1.5405
Saved models from epoch 7 to 'data/predictions/almnps_8857/ood_embedding/ood/science/newest.pt'.
No improvement since 3 epochs (1.4289 loss). Early stop.
OOD training completed for test topic science after 7 epochs.
TRAINING COMPLETED with:
	Domains:		['ai', 'literature', 'music', 'news', 'politics', 'science']
	OOD validaation:	True
	Mapping type:		ood_embedding
