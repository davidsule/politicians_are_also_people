{
    "related-to": {
        "precision": 0.15714285714285714,
        "recall": 0.1527777777777778,
        "f1-score": 0.15492957746478875,
        "support": 72
    },
    "artifact": {
        "precision": 0.7677053824362606,
        "recall": 0.9033333333333333,
        "f1-score": 0.8300153139356815,
        "support": 300
    },
    "cause-effect": {
        "precision": 0.0,
        "recall": 0.0,
        "f1-score": 0.0,
        "support": 1
    },
    "compare": {
        "precision": 0.0,
        "recall": 0.0,
        "f1-score": 0.0,
        "support": 8
    },
    "general-affiliation": {
        "precision": 0.8549848942598187,
        "recall": 0.8628048780487805,
        "f1-score": 0.858877086494689,
        "support": 328
    },
    "named": {
        "precision": 0.4946236559139785,
        "recall": 0.48936170212765956,
        "f1-score": 0.4919786096256685,
        "support": 94
    },
    "opposite": {
        "precision": 0.3,
        "recall": 0.21428571428571427,
        "f1-score": 0.25,
        "support": 14
    },
    "origin": {
        "precision": 0.5,
        "recall": 0.3404255319148936,
        "f1-score": 0.4050632911392405,
        "support": 47
    },
    "part-of": {
        "precision": 0.40594059405940597,
        "recall": 0.4270833333333333,
        "f1-score": 0.416243654822335,
        "support": 96
    },
    "physical": {
        "precision": 0.7708333333333334,
        "recall": 0.8505747126436781,
        "f1-score": 0.8087431693989071,
        "support": 174
    },
    "role": {
        "precision": 0.6117216117216118,
        "recall": 0.6600790513833992,
        "f1-score": 0.6349809885931559,
        "support": 253
    },
    "social": {
        "precision": 1.0,
        "recall": 0.02127659574468085,
        "f1-score": 0.04166666666666667,
        "support": 47
    },
    "temporal": {
        "precision": 0.5909090909090909,
        "recall": 0.4482758620689655,
        "f1-score": 0.5098039215686274,
        "support": 29
    },
    "topic": {
        "precision": 0.2,
        "recall": 0.023809523809523808,
        "f1-score": 0.0425531914893617,
        "support": 42
    },
    "type-of": {
        "precision": 0.75,
        "recall": 0.8333333333333334,
        "f1-score": 0.7894736842105262,
        "support": 18
    },
    "usage": {
        "precision": 0.0,
        "recall": 0.0,
        "f1-score": 0.0,
        "support": 2
    },
    "win-defeat": {
        "precision": 0.7471264367816092,
        "recall": 0.6701030927835051,
        "f1-score": 0.7065217391304347,
        "support": 97
    },
    "micro avg": {
        "precision": 0.679874213836478,
        "recall": 0.6664611590628853,
        "f1-score": 0.6731008717310086,
        "support": 1622
    },
    "macro avg": {
        "precision": 999999,
        "recall": 999999,
        "f1-score": 0.408285346737652,
        "support": 1622
    },
    "weighted avg": {
        "precision": 0.6674624304671695,
        "recall": 0.6664611590628853,
        "f1-score": 0.6493582494957,
        "support": 1622
    },
    "samples avg": {
        "precision": 0.679874213836478,
        "recall": 0.6737945492662475,
        "f1-score": 0.6757861635220126,
        "support": 1622
    }
}