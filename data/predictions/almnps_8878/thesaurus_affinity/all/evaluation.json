{"related-to": {"precision": 0.05741626794258373, "recall": 0.08695652173913043, "f1-score": 0.06916426512968299, "support": 414}, "artifact": {"precision": 0.061277705345501955, "recall": 0.07401574803149606, "f1-score": 0.06704707560627673, "support": 635}, "cause-effect": {"precision": 0.0, "recall": 0.0, "f1-score": 0.0, "support": 86}, "compare": {"precision": 0.0, "recall": 0.0, "f1-score": 0.0, "support": 82}, "general-affiliation": {"precision": 0.14521242866201647, "recall": 0.1848264729620662, "f1-score": 0.16264204545454547, "support": 1239}, "named": {"precision": 0.0824561403508772, "recall": 0.08422939068100359, "f1-score": 0.08333333333333336, "support": 558}, "opposite": {"precision": 0.023255813953488372, "recall": 0.0078125, "f1-score": 0.011695906432748537, "support": 128}, "origin": {"precision": 0.02631578947368421, "recall": 0.013157894736842105, "f1-score": 0.017543859649122806, "support": 304}, "part-of": {"precision": 0.07109004739336493, "recall": 0.06241331484049931, "f1-score": 0.06646971935007386, "support": 721}, "physical": {"precision": 0.17317207256734468, "recall": 0.21649484536082475, "f1-score": 0.19242516799022602, "support": 1455}, "role": {"precision": 0.23794614902943018, "recall": 0.18943170488534397, "f1-score": 0.2109353316680544, "support": 2006}, "social": {"precision": 0.0, "recall": 0.0, "f1-score": 0.0, "support": 105}, "temporal": {"precision": 0.038636363636363635, "recall": 0.041666666666666664, "f1-score": 0.040094339622641514, "support": 408}, "topic": {"precision": 0.0, "recall": 0.0, "f1-score": 0.0, "support": 170}, "type-of": {"precision": 0.022222222222222223, "recall": 0.005952380952380952, "f1-score": 0.009389671361502348, "support": 336}, "usage": {"precision": 0.030303030303030304, "recall": 0.005, "f1-score": 0.008583690987124463, "support": 200}, "win-defeat": {"precision": 0.058091286307053944, "recall": 0.04416403785488959, "f1-score": 0.05017921146953405, "support": 317}, "micro avg": {"precision": 0.13128749423165667, "recall": 0.12418158009602794, "f1-score": 0.12763571108120234, "support": 9164}, "macro avg": {"precision": 0.06043501865805658, "recall": 0.059771851688890806, "f1-score": 0.05820609517969804, "support": 9164}, "weighted avg": {"precision": 0.12307226745919711, "recall": 0.12418158009602794, "f1-score": 0.12158766185384662, "support": 9164}, "samples avg": {"precision": 0.13128749423165667, "recall": 0.1242885709890786, "f1-score": 0.1266151361329026, "support": 9164}}