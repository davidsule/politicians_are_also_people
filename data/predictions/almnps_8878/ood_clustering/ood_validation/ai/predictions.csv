"labels","position-ent1-marker","position-ent2-marker","text"
"role","6","13","Finally , every other year , <E1:UDBKL> ELRA </E1:UDBKL> organizes a major conference <E2:UDBKL> LREC </E2:UDBKL> , the International Language Resources and Evaluation Conference ."
"origin","16","11","Finally , every other year , ELRA organizes a major conference <E2:UDBKL> LREC </E2:UDBKL> , the <E1:UDBKL> International Language Resources and Evaluation Conference </E1:UDBKL> ."
"related-to","1","12","Unlike <E1:proteins> neural network </E1:proteins> s and Support vector machine , the <E2:proteins> AdaBoost </E2:proteins> training process selects only those features known to improve the predictive power of the model , reducing dimensionality and potentially improving execution time as irrelevant features need not be computed ."
"related-to","5","12","Unlike neural network s and <E1:proteins> Support vector machine </E1:proteins> , the <E2:proteins> AdaBoost </E2:proteins> training process selects only those features known to improve the predictive power of the model , reducing dimensionality and potentially improving execution time as irrelevant features need not be computed ."
"related-to","0","14","<E1:proteins> Troponymy </E1:proteins> is one of the possible relations between verb s in the <E2:proteins> semantic network </E2:proteins> of the WordNet database ."
"part-of","12","18","Troponymy is one of the possible relations between verb s in the <E1:proteins> semantic network </E1:proteins> of the <E2:proteins> WordNet database </E2:proteins> ."
"part-of","8","13","A frame language is a technology used for <E1:UDBKL> knowledge representation </E1:UDBKL> in <E2:UDBKL> artificial intelligence </E2:UDBKL> ."
"related-to","0","6","<E1:UDBKL> NIST </E1:UDBKL> also differs from <E2:UDBKL> Bilingual evaluation understudy </E2:UDBKL> in its calculation of the brevity penalty insofar as small variations in translation length do not impact the overall score as much ."
"role","15","33","The model is initially fit on a training dataset , The model ( e.g. a <E1:proteins> neural net </E1:proteins> or a naive Bayes classifier ) is trained on the training dataset using a <E2:UDBKL> supervised learning </E2:UDBKL> method , for example using optimization methods such as gradient descent or stochastic gradient descent ."
"role","19","33","The model is initially fit on a training dataset , The model ( e.g. a neural net or a <E1:proteins> naive Bayes classifier </E1:proteins> ) is trained on the training dataset using a <E2:UDBKL> supervised learning </E2:UDBKL> method , for example using optimization methods such as gradient descent or stochastic gradient descent ."
"part-of","44","31","The model is initially fit on a training dataset , The model ( e.g. a neural net or a naive Bayes classifier ) is trained on the training dataset using a <E2:UDBKL> supervised learning </E2:UDBKL> method , for example using optimization methods such as <E1:proteins> gradient descent </E1:proteins> or stochastic gradient descent ."
"part-of","47","31","The model is initially fit on a training dataset , The model ( e.g. a neural net or a naive Bayes classifier ) is trained on the training dataset using a <E2:UDBKL> supervised learning </E2:UDBKL> method , for example using optimization methods such as gradient descent or <E1:proteins> stochastic gradient descent </E1:proteins> ."
"related-to","9","0","<E2:proteins> FrameNet </E2:proteins> has been used in applications like <E1:UDBKL> question answering </E1:UDBKL> , paraphrasing , recognizing textual entailment , and information extraction , either directly or by means of Semantic Role Labeling tools ."
"related-to","12","0","<E2:proteins> FrameNet </E2:proteins> has been used in applications like question answering , <E1:UDBKL> paraphrasing </E1:UDBKL> , recognizing textual entailment , and information extraction , either directly or by means of Semantic Role Labeling tools ."
"related-to","14","0","<E2:proteins> FrameNet </E2:proteins> has been used in applications like question answering , paraphrasing , <E1:UDBKL> recognizing textual entailment </E1:UDBKL> , and information extraction , either directly or by means of Semantic Role Labeling tools ."
"related-to","19","0","<E2:proteins> FrameNet </E2:proteins> has been used in applications like question answering , paraphrasing , recognizing textual entailment , and <E1:UDBKL> information extraction </E1:UDBKL> , either directly or by means of Semantic Role Labeling tools ."
"related-to","28","0","<E2:proteins> FrameNet </E2:proteins> has been used in applications like question answering , paraphrasing , recognizing textual entailment , and information extraction , either directly or by means of <E1:UDBKL> Semantic Role Labeling </E1:UDBKL> tools ."
"part-of","17","12","This would include programs such as data analysis and extraction tools , <E2:proteins> spreadsheets </E2:proteins> ( e.g. <E1:proteins> Excel </E1:proteins> ) , databases ( e.g. Access ) , statistical analysis ( e.g. SAS ) , generalized audit software ( e.g. ACL , Arbutus , EAS ) , business intelligence ( e.g. Crystal Reports and Business Objects ) , etc ."
"part-of","23","18","This would include programs such as data analysis and extraction tools , spreadsheets ( e.g. Excel ) , <E2:proteins> databases </E2:proteins> ( e.g. <E1:proteins> Access </E1:proteins> ) , statistical analysis ( e.g. SAS ) , generalized audit software ( e.g. ACL , Arbutus , EAS ) , business intelligence ( e.g. Crystal Reports and Business Objects ) , etc ."
"named","30","24","This would include programs such as data analysis and extraction tools , spreadsheets ( e.g. Excel ) , databases ( e.g. Access ) , <E2:UDBKL> statistical analysis </E2:UDBKL> ( e.g. <E1:proteins> SAS </E1:proteins> ) , generalized audit software ( e.g. ACL , Arbutus , EAS ) , business intelligence ( e.g. Crystal Reports and Business Objects ) , etc ."
"named","38","31","This would include programs such as data analysis and extraction tools , spreadsheets ( e.g. Excel ) , databases ( e.g. Access ) , statistical analysis ( e.g. SAS ) , <E2:proteins> generalized audit software </E2:proteins> ( e.g. <E1:proteins> ACL </E1:proteins> , Arbutus , EAS ) , business intelligence ( e.g. Crystal Reports and Business Objects ) , etc ."
"named","40","31","This would include programs such as data analysis and extraction tools , spreadsheets ( e.g. Excel ) , databases ( e.g. Access ) , statistical analysis ( e.g. SAS ) , <E2:proteins> generalized audit software </E2:proteins> ( e.g. ACL , <E1:proteins> Arbutus </E1:proteins> , EAS ) , business intelligence ( e.g. Crystal Reports and Business Objects ) , etc ."
"named","42","31","This would include programs such as data analysis and extraction tools , spreadsheets ( e.g. Excel ) , databases ( e.g. Access ) , statistical analysis ( e.g. SAS ) , <E2:proteins> generalized audit software </E2:proteins> ( e.g. ACL , Arbutus , <E1:proteins> EAS </E1:proteins> ) , business intelligence ( e.g. Crystal Reports and Business Objects ) , etc ."
"named","49","43","This would include programs such as data analysis and extraction tools , spreadsheets ( e.g. Excel ) , databases ( e.g. Access ) , statistical analysis ( e.g. SAS ) , generalized audit software ( e.g. ACL , Arbutus , EAS ) , <E2:proteins> business intelligence </E2:proteins> ( e.g. <E1:proteins> Crystal Reports </E1:proteins> and Business Objects ) , etc ."
"part-of","52","43","This would include programs such as data analysis and extraction tools , spreadsheets ( e.g. Excel ) , databases ( e.g. Access ) , statistical analysis ( e.g. SAS ) , generalized audit software ( e.g. ACL , Arbutus , EAS ) , <E2:proteins> business intelligence </E2:proteins> ( e.g. Crystal Reports and <E1:proteins> Business Objects </E1:proteins> ) , etc ."
"role","0","7","<E1:UDBKL> Rethink Robotics </E1:UDBKL> - founded by <E2:author> Rodney Brooks </E2:author> , previously with iRobot - introduced Baxter in September 2012 ; as an industrial robot designed to safely interact with neighboring human workers , and be programmable for performing simple tasks ."
"role","5","12","Rethink Robotics - founded by <E1:author> Rodney Brooks </E1:author> , previously with <E2:UDBKL> iRobot </E2:UDBKL> - introduced Baxter in September 2012 ; as an industrial robot designed to safely interact with neighboring human workers , and be programmable for performing simple tasks ."
"related-to","13","22","Rethink Robotics - founded by Rodney Brooks , previously with iRobot - introduced <E1:proteins> Baxter </E1:proteins> in September 2012 ; as an <E2:proteins> industrial robot </E2:proteins> designed to safely interact with neighboring human workers , and be programmable for performing simple tasks ."
"origin","22","5","Rethink Robotics - founded by <E2:author> Rodney Brooks </E2:author> , previously with iRobot - introduced Baxter in September 2012 ; as an <E1:proteins> industrial robot </E1:proteins> designed to safely interact with neighboring human workers , and be programmable for performing simple tasks ."
"related-to","7","1","Typical <E2:UDBKL> text mining </E2:UDBKL> tasks include <E1:UDBKL> text categorization </E1:UDBKL> , text clustering , concept / entity extraction , production of granular taxonomies , sentiment analysis , document summarization , and entity relation modeling ( i.e. , learning relations between named entity recognition ) ."
"part-of","10","1","Typical <E2:UDBKL> text mining </E2:UDBKL> tasks include text categorization , <E1:UDBKL> text clustering </E1:UDBKL> , concept / entity extraction , production of granular taxonomies , sentiment analysis , document summarization , and entity relation modeling ( i.e. , learning relations between named entity recognition ) ."
"part-of","13","1","Typical <E2:UDBKL> text mining </E2:UDBKL> tasks include text categorization , text clustering , <E1:UDBKL> concept / entity extraction </E1:UDBKL> , production of granular taxonomies , sentiment analysis , document summarization , and entity relation modeling ( i.e. , learning relations between named entity recognition ) ."
"part-of","18","1","Typical <E2:UDBKL> text mining </E2:UDBKL> tasks include text categorization , text clustering , concept / entity extraction , <E1:UDBKL> production of granular taxonomies </E1:UDBKL> , sentiment analysis , document summarization , and entity relation modeling ( i.e. , learning relations between named entity recognition ) ."
"part-of","23","1","Typical <E2:UDBKL> text mining </E2:UDBKL> tasks include text categorization , text clustering , concept / entity extraction , production of granular taxonomies , <E1:UDBKL> sentiment analysis </E1:UDBKL> , document summarization , and entity relation modeling ( i.e. , learning relations between named entity recognition ) ."
"part-of","26","1","Typical <E2:UDBKL> text mining </E2:UDBKL> tasks include text categorization , text clustering , concept / entity extraction , production of granular taxonomies , sentiment analysis , <E1:UDBKL> document summarization </E1:UDBKL> , and entity relation modeling ( i.e. , learning relations between named entity recognition ) ."
"part-of","30","1","Typical <E2:UDBKL> text mining </E2:UDBKL> tasks include text categorization , text clustering , concept / entity extraction , production of granular taxonomies , sentiment analysis , document summarization , and <E1:UDBKL> entity relation modeling </E1:UDBKL> ( i.e. , learning relations between named entity recognition ) ."
"part-of","39","1","Typical <E2:UDBKL> text mining </E2:UDBKL> tasks include text categorization , text clustering , concept / entity extraction , production of granular taxonomies , sentiment analysis , document summarization , and entity relation modeling ( i.e. , learning relations between <E1:UDBKL> named entity recognition </E1:UDBKL> ) ."
"named","9","4","A special case of <E2:UDBKL> keyword spotting </E2:UDBKL> is <E1:proteins> wake word </E1:proteins> ( also called hot word ) detection used by personal digital assistants such as Alexa or Siri to wake up when their name is spoken ."
"named","14","7","A special case of keyword spotting is <E2:proteins> wake word </E2:proteins> ( also called <E1:proteins> hot word </E1:proteins> ) detection used by personal digital assistants such as Alexa or Siri to wake up when their name is spoken ."
"part-of","25","7","A special case of keyword spotting is <E2:proteins> wake word </E2:proteins> ( also called hot word ) detection used by personal digital assistants such as <E1:proteins> Alexa </E1:proteins> or Siri to wake up when their name is spoken ."
"named","27","7","A special case of keyword spotting is <E2:proteins> wake word </E2:proteins> ( also called hot word ) detection used by personal digital assistants such as Alexa or <E1:proteins> Siri </E1:proteins> to wake up when their name is spoken ."
"named","11","0","<E2:proteins> Prova </E2:proteins> is an open source programming language that combines <E1:proteins> Prolog </E1:proteins> with Java ."
"part-of","13","0","<E2:proteins> Prova </E2:proteins> is an open source programming language that combines Prolog with <E1:proteins> Java </E1:proteins> ."
"role","3","11","In 1987 , <E1:UDBKL> Tocibai Machine </E1:UDBKL> , a subsidiary of <E2:UDBKL> Toshiba </E2:UDBKL> , was accused of illegally selling CNC milling s used to produce very quiet submarine propellers to the Soviet Union in violation of the CoCom agreement , an international embargo on certain countries to COMECON countries ."
"role","3","30","In 1987 , <E1:UDBKL> Tocibai Machine </E1:UDBKL> , a subsidiary of Toshiba , was accused of illegally selling CNC milling s used to produce very quiet submarine propellers to the <E2:UDBKL> Soviet Union </E2:UDBKL> in violation of the CoCom agreement , an international embargo on certain countries to COMECON countries ."
"related-to","34","46","In 1987 , Tocibai Machine , a subsidiary of Toshiba , was accused of illegally selling CNC milling s used to produce very quiet submarine propellers to the Soviet Union in violation of the <E1:UDBKL> CoCom </E1:UDBKL> agreement , an international embargo on certain countries to <E2:proteins> COMECON </E2:proteins> countries ."
"artifact","9","0","<E2:author> Engelberger </E2:author> 's most famous co-invention , the <E1:proteins> Unimate industrial robotic arm </E1:proteins> , was among the first inductees into the Robot Hall of Fame in 2003 ."
"role","7","21","Engelberger 's most famous co-invention , the <E1:proteins> Unimate industrial robotic arm </E1:proteins> , was among the first inductees into the <E2:UDBKL> Robot Hall of Fame </E2:UDBKL> in 2003 ."
"related-to","3","10","Originally controlled via <E1:proteins> static html </E1:proteins> web pages using <E2:proteins> CGI </E2:proteins> , work by Dalton saw the introduction of an augmented reality Java -based interface that met with limited success ."
"role","12","20","Originally controlled via static html web pages using CGI , work by <E1:UDBKL> Dalton </E1:UDBKL> saw the introduction of an <E2:UDBKL> augmented reality </E2:UDBKL> Java -based interface that met with limited success ."
"related-to","18","22","Originally controlled via static html web pages using CGI , work by Dalton saw the introduction of an <E1:UDBKL> augmented reality </E1:UDBKL> <E2:proteins> Java </E2:proteins> -based interface that met with limited success ."
"role","5","15","The first publication about the <E1:UDBKL> LMF specification </E1:UDBKL> as it has been ratified by <E2:UDBKL> ISO </E2:UDBKL> ( this paper became ( in 2015 ) the 9th most cited paper within the LREC conferences from LREC papers ) :"
"part-of","29","34","The first publication about the LMF specification as it has been ratified by ISO ( this paper became ( in 2015 ) the 9th most cited paper within the <E1:UDBKL> LREC </E1:UDBKL> conferences from <E2:UDBKL> LREC </E2:UDBKL> papers ) :"
"named","17","1","A <E2:UDBKL> confusion matrix </E2:UDBKL> or matching matrix is often used as a tool to validate the <E1:UDBKL> accuracy </E1:UDBKL> of k -NN classification ."
"related-to","15","19","A confusion matrix or matching matrix is often used as a tool to validate the <E1:UDBKL> accuracy </E1:UDBKL> of <E2:proteins> k -NN classification </E2:proteins> ."
"part-of","0","14","<E1:proteins> Decision tree </E1:proteins> learning is one of the predictive modeling approaches used in <E2:UDBKL> statistics </E2:UDBKL> , data mining and machine learning ."
"related-to","0","16","<E1:proteins> Decision tree </E1:proteins> learning is one of the predictive modeling approaches used in statistics , <E2:UDBKL> data mining </E2:UDBKL> and machine learning ."
"role","0","19","<E1:proteins> Decision tree </E1:proteins> learning is one of the predictive modeling approaches used in statistics , data mining and <E2:UDBKL> machine learning </E2:UDBKL> ."
"named","5","20","At runtime , the target <E1:proteins> prosody </E1:proteins> of a sentence is superimposed on these minimal units by means of <E2:UDBKL> signal processing </E2:UDBKL> techniques such as linear predictive coding , PSOLA"
"part-of","25","18","At runtime , the target prosody of a sentence is superimposed on these minimal units by means of <E2:UDBKL> signal processing </E2:UDBKL> techniques such as <E1:proteins> linear predictive coding </E1:proteins> , PSOLA"
"part-of","29","18","At runtime , the target prosody of a sentence is superimposed on these minimal units by means of <E2:UDBKL> signal processing </E2:UDBKL> techniques such as linear predictive coding , <E1:proteins> PSOLA </E1:proteins>"
"named","19","3","This approach utilized <E2:UDBKL> artificial intelligence </E2:UDBKL> and machine learning to allow researchers to visibly compare conventional and thermal <E1:UDBKL> facial imagery </E1:UDBKL> ."
"named","19","6","This approach utilized artificial intelligence and <E2:UDBKL> machine learning </E2:UDBKL> to allow researchers to visibly compare conventional and thermal <E1:UDBKL> facial imagery </E1:UDBKL> ."
"physical","6","1","In <E2:UDBKL> computer science </E2:UDBKL> , <E1:proteins> evolutionary computation </E1:proteins> is a family of algorithms for global optimization inspired by biological evolution , and the subfield of artificial intelligence and soft computing studying these algorithms ."
"part-of","4","14","In computer science , <E1:proteins> evolutionary computation </E1:proteins> is a family of algorithms for <E2:UDBKL> global optimization </E2:UDBKL> inspired by biological evolution , and the subfield of artificial intelligence and soft computing studying these algorithms ."
"related-to","12","18","In computer science , evolutionary computation is a family of algorithms for <E1:UDBKL> global optimization </E1:UDBKL> inspired by <E2:proteins> biological evolution </E2:proteins> , and the subfield of artificial intelligence and soft computing studying these algorithms ."
"named","25","1","In <E2:UDBKL> computer science </E2:UDBKL> , evolutionary computation is a family of algorithms for global optimization inspired by biological evolution , and the subfield of <E1:UDBKL> artificial intelligence </E1:UDBKL> and soft computing studying these algorithms ."
"part-of","25","4","In computer science , <E2:proteins> evolutionary computation </E2:proteins> is a family of algorithms for global optimization inspired by biological evolution , and the subfield of <E1:UDBKL> artificial intelligence </E1:UDBKL> and soft computing studying these algorithms ."
"physical","28","1","In <E2:UDBKL> computer science </E2:UDBKL> , evolutionary computation is a family of algorithms for global optimization inspired by biological evolution , and the subfield of artificial intelligence and <E1:UDBKL> soft computing </E1:UDBKL> studying these algorithms ."
"part-of","28","4","In computer science , <E2:proteins> evolutionary computation </E2:proteins> is a family of algorithms for global optimization inspired by biological evolution , and the subfield of artificial intelligence and <E1:UDBKL> soft computing </E1:UDBKL> studying these algorithms ."
"artifact","6","12","The majority are results of the <E1:proteins> word2vec model </E1:proteins> developed by <E2:author> Mikolov </E2:author> et al or variants of word2vec ."
"related-to","6","18","The majority are results of the <E1:proteins> word2vec model </E1:proteins> developed by Mikolov et al or variants of <E2:proteins> word2vec </E2:proteins> ."
"named","26","18","It was during this time that a total of 43 publications were recognized by the CVPR and the <E2:UDBKL> International Conference on Computer Vision </E2:UDBKL> ( <E1:UDBKL> ICCV </E1:UDBKL> ) ."
"part-of","1","13","The <E1:proteins> AIBO </E1:proteins> has seen much use as an inexpensive platform for <E2:UDBKL> artificial intelligence </E2:UDBKL> education and research , because integrates a computer , Computer vision , and articulators in a package vastly cheaper than conventional research robots ."
"part-of","24","1","The <E2:proteins> AIBO </E2:proteins> has seen much use as an inexpensive platform for artificial intelligence education and research , because integrates a computer , <E1:UDBKL> Computer vision </E1:UDBKL> , and articulators in a package vastly cheaper than conventional research robots ."
"role","0","9","<E1:author> Scheinman </E1:author> , after receiving a fellowship from <E2:UDBKL> Unimation </E2:UDBKL> to develop his designs , sold those designs to Unimation who further developed them with support from General Motors and later marketed it as the Programmable Universal Machine for Assembly ( PUMA ) ."
"role","0","19","<E1:author> Scheinman </E1:author> , after receiving a fellowship from Unimation to develop his designs , sold those designs to <E2:UDBKL> Unimation </E2:UDBKL> who further developed them with support from General Motors and later marketed it as the Programmable Universal Machine for Assembly ( PUMA ) ."
"role","17","27","Scheinman , after receiving a fellowship from Unimation to develop his designs , sold those designs to <E1:UDBKL> Unimation </E1:UDBKL> who further developed them with support from <E2:UDBKL> General Motors </E2:UDBKL> and later marketed it as the Programmable Universal Machine for Assembly ( PUMA ) ."
"named","35","17","Scheinman , after receiving a fellowship from Unimation to develop his designs , sold those designs to <E2:UDBKL> Unimation </E2:UDBKL> who further developed them with support from General Motors and later marketed it as the <E1:proteins> Programmable Universal Machine for Assembly </E1:proteins> ( PUMA ) ."
"named","41","33","Scheinman , after receiving a fellowship from Unimation to develop his designs , sold those designs to Unimation who further developed them with support from General Motors and later marketed it as the <E2:proteins> Programmable Universal Machine for Assembly </E2:proteins> ( <E1:proteins> PUMA </E1:proteins> ) ."
"role","18","6","An overview of calibration methods for <E2:UDBKL> binary classification </E2:UDBKL> and multiclass classification classification tasks is given by <E1:author> Gebel </E1:author> ( 2009 )"
"role","18","9","An overview of calibration methods for binary classification and <E2:UDBKL> multiclass classification classification tasks </E2:UDBKL> is given by <E1:author> Gebel </E1:author> ( 2009 )"
"named","13","7","He is involved in fields such as <E2:UDBKL> optical character recognition </E2:UDBKL> ( <E1:UDBKL> OCR </E1:UDBKL> ) , speech synthesis , speech recognition technology , and electronic keyboard instruments ."
"role","0","8","<E1:author> Johnson-Laird </E1:author> is a Fellow of the <E2:UDBKL> American Philosophical Society </E2:UDBKL> , a Fellow of the Royal Society , a Fellow of the British Academy , a William James Fellow of the Association for Psychological Science , and a Fellow of the Cognitive Science Society ."
"role","0","16","<E1:author> Johnson-Laird </E1:author> is a Fellow of the American Philosophical Society , a Fellow of the <E2:UDBKL> Royal Society </E2:UDBKL> , a Fellow of the British Academy , a William James Fellow of the Association for Psychological Science , and a Fellow of the Cognitive Science Society ."
"role","0","23","<E1:author> Johnson-Laird </E1:author> is a Fellow of the American Philosophical Society , a Fellow of the Royal Society , a Fellow of the <E2:UDBKL> British Academy </E2:UDBKL> , a William James Fellow of the Association for Psychological Science , and a Fellow of the Cognitive Science Society ."
"role","0","32","<E1:author> Johnson-Laird </E1:author> is a Fellow of the American Philosophical Society , a Fellow of the Royal Society , a Fellow of the British Academy , a William James Fellow of the <E2:UDBKL> Association for Psychological Science </E2:UDBKL> , and a Fellow of the Cognitive Science Society ."
"role","0","42","<E1:author> Johnson-Laird </E1:author> is a Fellow of the American Philosophical Society , a Fellow of the Royal Society , a Fellow of the British Academy , a William James Fellow of the Association for Psychological Science , and a Fellow of the <E2:UDBKL> Cognitive Science Society </E2:UDBKL> ."
"temporal","13","2","At the <E2:UDBKL> IEEE International Conference on Image Processing </E2:UDBKL> in 2010 , <E1:author> Rui Hu </E1:author> , Mark Banard , and John Collomosse extended the HOG descriptor for use in sketch based image retrieval ( SBIR ) ."
"temporal","16","2","At the <E2:UDBKL> IEEE International Conference on Image Processing </E2:UDBKL> in 2010 , Rui Hu , <E1:author> Mark Banard </E1:author> , and John Collomosse extended the HOG descriptor for use in sketch based image retrieval ( SBIR ) ."
"temporal","20","2","At the <E2:UDBKL> IEEE International Conference on Image Processing </E2:UDBKL> in 2010 , Rui Hu , Mark Banard , and <E1:author> John Collomosse </E1:author> extended the HOG descriptor for use in sketch based image retrieval ( SBIR ) ."
"origin","24","18","At the IEEE International Conference on Image Processing in 2010 , Rui Hu , Mark Banard , and <E2:author> John Collomosse </E2:author> extended the <E1:proteins> HOG descriptor </E1:proteins> for use in sketch based image retrieval ( SBIR ) ."
"origin","29","18","At the IEEE International Conference on Image Processing in 2010 , Rui Hu , Mark Banard , and <E2:author> John Collomosse </E2:author> extended the HOG descriptor for use in <E1:UDBKL> sketch based image retrieval </E1:UDBKL> ( SBIR ) ."
"named","34","27","At the IEEE International Conference on Image Processing in 2010 , Rui Hu , Mark Banard , and John Collomosse extended the HOG descriptor for use in <E2:UDBKL> sketch based image retrieval </E2:UDBKL> ( <E1:UDBKL> SBIR </E1:UDBKL> ) ."
"related-to","0","8","<E1:UDBKL> BLEU </E1:UDBKL> uses a modified form of <E2:UDBKL> precision </E2:UDBKL> to compare a candidate translation against multiple reference translations ."
"physical","15","10","As of October 2011 , the already-existing partnerships with the <E2:UDBKL> United States </E2:UDBKL> ' <E1:UDBKL> National Park Service </E1:UDBKL> ( NPS ) , the United Kingdom 's Historic Scotland ( HS ) , World Monuments Fund , and Mexico 's Instituto Nacional de Antropología y Historia ( INAH ) had been greatly expanded , , CyArk website"
"named","19","13","As of October 2011 , the already-existing partnerships with the United States ' <E2:UDBKL> National Park Service </E2:UDBKL> ( <E1:UDBKL> NPS </E1:UDBKL> ) , the United Kingdom 's Historic Scotland ( HS ) , World Monuments Fund , and Mexico 's Instituto Nacional de Antropología y Historia ( INAH ) had been greatly expanded , , CyArk website"
"physical","26","21","As of October 2011 , the already-existing partnerships with the United States ' National Park Service ( NPS ) , the <E2:UDBKL> United Kingdom </E2:UDBKL> 's <E1:UDBKL> Historic Scotland </E1:UDBKL> ( HS ) , World Monuments Fund , and Mexico 's Instituto Nacional de Antropología y Historia ( INAH ) had been greatly expanded , , CyArk website"
"named","29","24","As of October 2011 , the already-existing partnerships with the United States ' National Park Service ( NPS ) , the United Kingdom 's <E2:UDBKL> Historic Scotland </E2:UDBKL> ( <E1:UDBKL> HS </E1:UDBKL> ) , World Monuments Fund , and Mexico 's Instituto Nacional de Antropología y Historia ( INAH ) had been greatly expanded , , CyArk website"
"physical","39","35","As of October 2011 , the already-existing partnerships with the United States ' National Park Service ( NPS ) , the United Kingdom 's Historic Scotland ( HS ) , World Monuments Fund , and <E2:UDBKL> Mexico </E2:UDBKL> 's <E1:UDBKL> Instituto Nacional de Antropología y Historia </E1:UDBKL> ( INAH ) had been greatly expanded , , CyArk website"
"named","46","37","As of October 2011 , the already-existing partnerships with the United States ' National Park Service ( NPS ) , the United Kingdom 's Historic Scotland ( HS ) , World Monuments Fund , and Mexico 's <E2:UDBKL> Instituto Nacional de Antropología y Historia </E2:UDBKL> ( <E1:UDBKL> INAH </E1:UDBKL> ) had been greatly expanded , , CyArk website"
"related-to","52","55","As of October 2011 , the already-existing partnerships with the United States ' National Park Service ( NPS ) , the United Kingdom 's Historic Scotland ( HS ) , World Monuments Fund , and Mexico 's Instituto Nacional de Antropología y Historia ( INAH ) had been greatly expanded , , <E1:proteins> CyArk </E1:proteins> <E2:proteins> website </E2:proteins>"
"related-to","0","12","<E1:proteins> Kernel SVMs </E1:proteins> are available in many machine-learning toolkits , including <E2:proteins> LIBSVM </E2:proteins> , MATLAB , and others ."
"related-to","0","14","<E1:proteins> Kernel SVMs </E1:proteins> are available in many machine-learning toolkits , including LIBSVM , <E2:proteins> MATLAB </E2:proteins> , and others ."
"part-of","12","6","Kernel SVMs are available in many <E2:UDBKL> machine-learning </E2:UDBKL> toolkits , including <E1:proteins> LIBSVM </E1:proteins> , MATLAB , and others ."
"part-of","14","6","Kernel SVMs are available in many <E2:UDBKL> machine-learning </E2:UDBKL> toolkits , including LIBSVM , <E1:proteins> MATLAB </E1:proteins> , and others ."
"physical","2","15","The 2009 <E1:proteins> Loebner Prize Competition </E1:proteins> was held September 6 , 2009 at the <E2:UDBKL> Brighton Centre </E2:UDBKL> , Brighton UK in conjunction with the Interspeech 2009 conference ."
"temporal","2","24","The 2009 <E1:proteins> Loebner Prize Competition </E1:proteins> was held September 6 , 2009 at the Brighton Centre , Brighton UK in conjunction with the <E2:UDBKL> Interspeech 2009 conference </E2:UDBKL> ."
"physical","13","18","The 2009 Loebner Prize Competition was held September 6 , 2009 at the <E1:UDBKL> Brighton Centre </E1:UDBKL> , <E2:UDBKL> Brighton </E2:UDBKL> UK in conjunction with the Interspeech 2009 conference ."
"physical","16","19","The 2009 Loebner Prize Competition was held September 6 , 2009 at the Brighton Centre , <E1:UDBKL> Brighton </E1:UDBKL> <E2:UDBKL> UK </E2:UDBKL> in conjunction with the Interspeech 2009 conference ."
"temporal","24","13","The 2009 Loebner Prize Competition was held September 6 , 2009 at the <E2:UDBKL> Brighton Centre </E2:UDBKL> , Brighton UK in conjunction with the <E1:UDBKL> Interspeech 2009 conference </E1:UDBKL> ."
"part-of","20","2","The humanoid <E2:proteins> QRIO robot </E2:proteins> was designed as the successor to AIBO , and runs the same base R-CODE <E1:proteins> Aperios operating system </E1:proteins> ."
"part-of","20","10","The humanoid QRIO robot was designed as the successor to <E2:proteins> AIBO </E2:proteins> , and runs the same base R-CODE <E1:proteins> Aperios operating system </E1:proteins> ."
"part-of","20","17","The humanoid QRIO robot was designed as the successor to AIBO , and runs the same base <E2:proteins> R-CODE </E2:proteins> <E1:proteins> Aperios operating system </E1:proteins> ."
"part-of","7","0","<E2:proteins> Speech waveforms </E2:proteins> are generated from <E1:proteins> HMMs </E1:proteins> themselves based on the maximum likelihood criterion ."
"part-of","12","0","<E2:proteins> Speech waveforms </E2:proteins> are generated from HMMs themselves based on the <E1:proteins> maximum likelihood </E1:proteins> criterion ."
"related-to","0","7","<E1:proteins> Google Translate </E1:proteins> is a free <E2:UDBKL> multilingual statistical machine translation </E2:UDBKL> and neural machine translation service developed by Google , to translate text and websites from one language into another ."
"named","0","12","<E1:proteins> Google Translate </E1:proteins> is a free multilingual statistical machine translation and <E2:UDBKL> neural machine translation </E2:UDBKL> service developed by Google , to translate text and websites from one language into another ."
"role","0","18","<E1:proteins> Google Translate </E1:proteins> is a free multilingual statistical machine translation and neural machine translation service developed by <E2:proteins> Google </E2:proteins> , to translate text and websites from one language into another ."
"related-to","23","5","Skeletons are widely used in <E2:UDBKL> computer vision </E2:UDBKL> , image analysis , pattern recognition and digital image processing for purposes such as <E1:UDBKL> optical character recognition </E1:UDBKL> , fingerprint recognition , visual inspection or compression ."
"part-of","23","8","Skeletons are widely used in computer vision , <E2:UDBKL> image analysis </E2:UDBKL> , pattern recognition and digital image processing for purposes such as <E1:UDBKL> optical character recognition </E1:UDBKL> , fingerprint recognition , visual inspection or compression ."
"part-of","23","11","Skeletons are widely used in computer vision , image analysis , <E2:UDBKL> pattern recognition </E2:UDBKL> and digital image processing for purposes such as <E1:UDBKL> optical character recognition </E1:UDBKL> , fingerprint recognition , visual inspection or compression ."
"related-to","27","5","Skeletons are widely used in <E2:UDBKL> computer vision </E2:UDBKL> , image analysis , pattern recognition and digital image processing for purposes such as optical character recognition , <E1:UDBKL> fingerprint recognition </E1:UDBKL> , visual inspection or compression ."
"part-of","27","8","Skeletons are widely used in computer vision , <E2:UDBKL> image analysis </E2:UDBKL> , pattern recognition and digital image processing for purposes such as optical character recognition , <E1:UDBKL> fingerprint recognition </E1:UDBKL> , visual inspection or compression ."
"part-of","27","11","Skeletons are widely used in computer vision , image analysis , <E2:UDBKL> pattern recognition </E2:UDBKL> and digital image processing for purposes such as optical character recognition , <E1:UDBKL> fingerprint recognition </E1:UDBKL> , visual inspection or compression ."
"related-to","30","5","Skeletons are widely used in <E2:UDBKL> computer vision </E2:UDBKL> , image analysis , pattern recognition and digital image processing for purposes such as optical character recognition , fingerprint recognition , <E1:UDBKL> visual inspection or compression </E1:UDBKL> ."
"part-of","30","8","Skeletons are widely used in computer vision , <E2:UDBKL> image analysis </E2:UDBKL> , pattern recognition and digital image processing for purposes such as optical character recognition , fingerprint recognition , <E1:UDBKL> visual inspection or compression </E1:UDBKL> ."
"part-of","30","11","Skeletons are widely used in computer vision , image analysis , <E2:UDBKL> pattern recognition </E2:UDBKL> and digital image processing for purposes such as optical character recognition , fingerprint recognition , <E1:UDBKL> visual inspection or compression </E1:UDBKL> ."
"part-of","1","13","The <E1:UDBKL> ImageNet Large Scale Visual Recognition Challenge </E1:UDBKL> is a benchmark in <E2:UDBKL> object classification and detection </E2:UDBKL> , with millions of images and hundreds of object classes ."
"related-to","0","19","<E1:author> Bengio </E1:author> , together with Geoffrey Hinton and Yann LeCun , are referred to by some as the <E2:proteins> Godfathers of AI </E2:proteins> and Godfathers of Deep Learning ."
"related-to","0","23","<E1:author> Bengio </E1:author> , together with Geoffrey Hinton and Yann LeCun , are referred to by some as the Godfathers of AI and <E2:proteins> Godfathers of Deep Learning </E2:proteins> ."
"role","4","19","Bengio , together with <E1:author> Geoffrey Hinton </E1:author> and Yann LeCun , are referred to by some as the <E2:proteins> Godfathers of AI </E2:proteins> and Godfathers of Deep Learning ."
"role","4","23","Bengio , together with <E1:author> Geoffrey Hinton </E1:author> and Yann LeCun , are referred to by some as the Godfathers of AI and <E2:proteins> Godfathers of Deep Learning </E2:proteins> ."
"related-to","7","19","Bengio , together with Geoffrey Hinton and <E1:author> Yann LeCun </E1:author> , are referred to by some as the <E2:proteins> Godfathers of AI </E2:proteins> and Godfathers of Deep Learning ."
"part-of","7","23","Bengio , together with Geoffrey Hinton and <E1:author> Yann LeCun </E1:author> , are referred to by some as the Godfathers of AI and <E2:proteins> Godfathers of Deep Learning </E2:proteins> ."
"role","0","16","<E1:UDBKL> NSA Bethesda </E1:UDBKL> is responsible for base operational support for its major tenant , the <E2:UDBKL> Walter Reed National Military Medical Center </E2:UDBKL> ."
"physical","4","17","In July 2011 the <E1:UDBKL> 15th edition of Campus Party Spain </E1:UDBKL> will be held at the <E2:UDBKL> City of Arts and Sciences </E2:UDBKL> in Valencia ."
"physical","15","23","In July 2011 the 15th edition of Campus Party Spain will be held at the <E1:UDBKL> City of Arts and Sciences </E1:UDBKL> in <E2:UDBKL> Valencia </E2:UDBKL> ."
"related-to","4","26","The difference between the <E1:proteins> multinomial logit model </E1:proteins> and numerous other methods , models , algorithms , etc. with the same basic setup ( the <E2:proteins> perceptron algorithm </E2:proteins> , support vector machine s , linear discriminant analysis , etc ."
"part-of","4","29","The difference between the <E1:proteins> multinomial logit model </E1:proteins> and numerous other methods , models , algorithms , etc. with the same basic setup ( the perceptron algorithm , <E2:proteins> support vector machine </E2:proteins> s , linear discriminant analysis , etc ."
"part-of","4","34","The difference between the <E1:proteins> multinomial logit model </E1:proteins> and numerous other methods , models , algorithms , etc. with the same basic setup ( the perceptron algorithm , support vector machine s , <E2:proteins> linear discriminant analysis </E2:proteins> , etc ."
"role","6","16","In 2002 , his son , <E1:UDBKL> Daniel Pearl </E1:UDBKL> , a journalist working for the <E2:UDBKL> Wall Street Journal </E2:UDBKL> was kidnapped and murdered in Pakistan , leading Judea and the other members of the family and friends to create the Daniel Pearl Foundation ."
"physical","6","24","In 2002 , his son , <E1:UDBKL> Daniel Pearl </E1:UDBKL> , a journalist working for the Wall Street Journal was kidnapped and murdered in <E2:UDBKL> Pakistan </E2:UDBKL> , leading Judea and the other members of the family and friends to create the Daniel Pearl Foundation ."
"role","25","40","In 2002 , his son , Daniel Pearl , a journalist working for the Wall Street Journal was kidnapped and murdered in Pakistan , leading <E1:UDBKL> Judea </E1:UDBKL> and the other members of the family and friends to create the <E2:UDBKL> Daniel Pearl Foundation </E2:UDBKL> ."
"role","5","20","As of late 2006 , <E1:UDBKL> Red Envelope Entertainment </E1:UDBKL> also expanded into producing original content with filmmakers such as <E2:UDBKL> John Waters </E2:UDBKL> ."
"related-to","5","21","For instance , the term <E1:UDBKL> neural machine translation </E1:UDBKL> ( NMT ) emphasizes the fact that deep learning-based approaches to <E2:UDBKL> machine translation </E2:UDBKL> directly learn sequence-to-sequence transformations , obviating the need for intermediate steps such as word alignment and language modeling that was used in statistical machine translation ( SMT ) ."
"named","5","45","For instance , the term <E1:UDBKL> neural machine translation </E1:UDBKL> ( NMT ) emphasizes the fact that deep learning-based approaches to machine translation directly learn sequence-to-sequence transformations , obviating the need for intermediate steps such as word alignment and language modeling that was used in <E2:UDBKL> statistical machine translation </E2:UDBKL> ( SMT ) ."
"named","11","5","For instance , the term <E2:UDBKL> neural machine translation </E2:UDBKL> ( <E1:UDBKL> NMT </E1:UDBKL> ) emphasizes the fact that deep learning-based approaches to machine translation directly learn sequence-to-sequence transformations , obviating the need for intermediate steps such as word alignment and language modeling that was used in statistical machine translation ( SMT ) ."
"related-to","34","45","For instance , the term neural machine translation ( NMT ) emphasizes the fact that deep learning-based approaches to machine translation directly learn sequence-to-sequence transformations , obviating the need for intermediate steps such as <E1:UDBKL> word alignment </E1:UDBKL> and language modeling that was used in <E2:UDBKL> statistical machine translation </E2:UDBKL> ( SMT ) ."
"named","37","45","For instance , the term neural machine translation ( NMT ) emphasizes the fact that deep learning-based approaches to machine translation directly learn sequence-to-sequence transformations , obviating the need for intermediate steps such as word alignment and <E1:UDBKL> language modeling </E1:UDBKL> that was used in <E2:UDBKL> statistical machine translation </E2:UDBKL> ( SMT ) ."
"named","45","19","For instance , the term neural machine translation ( NMT ) emphasizes the fact that deep learning-based approaches to <E2:UDBKL> machine translation </E2:UDBKL> directly learn sequence-to-sequence transformations , obviating the need for intermediate steps such as word alignment and language modeling that was used in <E1:UDBKL> statistical machine translation </E1:UDBKL> ( SMT ) ."
"named","49","43","For instance , the term neural machine translation ( NMT ) emphasizes the fact that deep learning-based approaches to machine translation directly learn sequence-to-sequence transformations , obviating the need for intermediate steps such as word alignment and language modeling that was used in <E2:UDBKL> statistical machine translation </E2:UDBKL> ( <E1:UDBKL> SMT </E1:UDBKL> ) ."
"related-to","6","13","Most research in the field of <E1:UDBKL> WSD </E1:UDBKL> is performed by using <E2:proteins> WordNet </E2:proteins> as a reference sense inventory for ."
"general-affiliation","13","2","Notable former <E2:proteins> PhD </E2:proteins> students and postdoctoral researchers from his group include <E1:author> Richard Zemel </E1:author> , and Zoubin Ghahramani ."
"general-affiliation","17","2","Notable former <E2:proteins> PhD </E2:proteins> students and postdoctoral researchers from his group include Richard Zemel , and <E1:author> Zoubin Ghahramani </E1:author> ."
"part-of","7","16","Each prediction result or instance of a <E1:UDBKL> confusion matrix </E1:UDBKL> represents one point in the <E2:UDBKL> ROC </E2:UDBKL> space ."
"physical","2","23","In 1997 <E1:author> Thrun </E1:author> and his colleagues Wolfram Burgard and Dieter Fox developed the world 's first robotic tour guide in the <E2:UDBKL> Deutsches Museum Bonn </E2:UDBKL> ( 1997 ) ."
"physical","6","23","In 1997 Thrun and his colleagues <E1:author> Wolfram Burgard </E1:author> and Dieter Fox developed the world 's first robotic tour guide in the <E2:UDBKL> Deutsches Museum Bonn </E2:UDBKL> ( 1997 ) ."
"physical","9","23","In 1997 Thrun and his colleagues Wolfram Burgard and <E1:author> Dieter Fox </E1:author> developed the world 's first robotic tour guide in the <E2:UDBKL> Deutsches Museum Bonn </E2:UDBKL> ( 1997 ) ."
"artifact","18","2","In 1997 <E2:author> Thrun </E2:author> and his colleagues Wolfram Burgard and Dieter Fox developed the world 's first <E1:proteins> robotic tour guide </E1:proteins> in the Deutsches Museum Bonn ( 1997 ) ."
"origin","18","6","In 1997 Thrun and his colleagues <E2:author> Wolfram Burgard </E2:author> and Dieter Fox developed the world 's first <E1:proteins> robotic tour guide </E1:proteins> in the Deutsches Museum Bonn ( 1997 ) ."
"origin","18","9","In 1997 Thrun and his colleagues Wolfram Burgard and <E2:author> Dieter Fox </E2:author> developed the world 's first <E1:proteins> robotic tour guide </E1:proteins> in the Deutsches Museum Bonn ( 1997 ) ."
"physical","16","23","In 1997 Thrun and his colleagues Wolfram Burgard and Dieter Fox developed the world 's first <E1:proteins> robotic tour guide </E1:proteins> in the <E2:UDBKL> Deutsches Museum Bonn </E2:UDBKL> ( 1997 ) ."
"related-to","8","0","<E2:proteins> WordNet </E2:proteins> is a lexical database of <E1:proteins> semantic relation </E1:proteins> s between word s in more than 200 languages. its primary use is in automatic natural language processing and artificial intelligence applications ."
"related-to","25","0","<E2:proteins> WordNet </E2:proteins> is a lexical database of semantic relation s between word s in more than 200 languages. its primary use is in automatic <E1:UDBKL> natural language processing </E1:UDBKL> and artificial intelligence applications ."
"related-to","29","0","<E2:proteins> WordNet </E2:proteins> is a lexical database of semantic relation s between word s in more than 200 languages. its primary use is in automatic natural language processing and <E1:UDBKL> artificial intelligence </E1:UDBKL> applications ."
"named","13","5","Conferences in the field of <E2:UDBKL> natural language processing </E2:UDBKL> , such as <E1:UDBKL> Association for Computational Linguistics </E1:UDBKL> , North American Chapter of the Association for Computational Linguistics , EMNLP , and HLT , are beginning to include papers on speech processing ."
"named","11","39","Conferences in the field of natural language processing , such as <E1:UDBKL> Association for Computational Linguistics </E1:UDBKL> , North American Chapter of the Association for Computational Linguistics , EMNLP , and HLT , are beginning to include papers on <E2:UDBKL> speech processing </E2:UDBKL> ."
"part-of","18","5","Conferences in the field of <E2:UDBKL> natural language processing </E2:UDBKL> , such as Association for Computational Linguistics , <E1:UDBKL> North American Chapter of the Association for Computational Linguistics </E1:UDBKL> , EMNLP , and HLT , are beginning to include papers on speech processing ."
"part-of","16","39","Conferences in the field of natural language processing , such as Association for Computational Linguistics , <E1:UDBKL> North American Chapter of the Association for Computational Linguistics </E1:UDBKL> , EMNLP , and HLT , are beginning to include papers on <E2:UDBKL> speech processing </E2:UDBKL> ."
"named","28","5","Conferences in the field of <E2:UDBKL> natural language processing </E2:UDBKL> , such as Association for Computational Linguistics , North American Chapter of the Association for Computational Linguistics , <E1:UDBKL> EMNLP </E1:UDBKL> , and HLT , are beginning to include papers on speech processing ."
"named","26","39","Conferences in the field of natural language processing , such as Association for Computational Linguistics , North American Chapter of the Association for Computational Linguistics , <E1:UDBKL> EMNLP </E1:UDBKL> , and HLT , are beginning to include papers on <E2:UDBKL> speech processing </E2:UDBKL> ."
"named","31","5","Conferences in the field of <E2:UDBKL> natural language processing </E2:UDBKL> , such as Association for Computational Linguistics , North American Chapter of the Association for Computational Linguistics , EMNLP , and <E1:UDBKL> HLT </E1:UDBKL> , are beginning to include papers on speech processing ."
"named","29","39","Conferences in the field of natural language processing , such as Association for Computational Linguistics , North American Chapter of the Association for Computational Linguistics , EMNLP , and <E1:UDBKL> HLT </E1:UDBKL> , are beginning to include papers on <E2:UDBKL> speech processing </E2:UDBKL> ."
"role","4","1","The <E2:UDBKL> Mattel </E2:UDBKL> <E1:proteins> Intellivision </E1:proteins> game console offered the Intellivoice Voice Synthesis module in 1982 ."
"part-of","9","2","The Mattel <E2:proteins> Intellivision </E2:proteins> game console offered the <E1:UDBKL> Intellivoice Voice Synthesis </E1:UDBKL> module in 1982 ."
"named","10","4","He also worked on <E2:UDBKL> machine translation </E2:UDBKL> , both <E1:UDBKL> high-accuracy knowledge-based MT </E1:UDBKL> and machine learning for Statistical machine translation ( such as generalized example-based MT ) ."
"named","14","4","He also worked on <E2:UDBKL> machine translation </E2:UDBKL> , both high-accuracy knowledge-based MT and <E1:UDBKL> machine learning </E1:UDBKL> for Statistical machine translation ( such as generalized example-based MT ) ."
"named","17","4","He also worked on <E2:UDBKL> machine translation </E2:UDBKL> , both high-accuracy knowledge-based MT and machine learning for <E1:UDBKL> Statistical machine translation </E1:UDBKL> ( such as generalized example-based MT ) ."
"named","23","15","He also worked on machine translation , both high-accuracy knowledge-based MT and machine learning for <E2:UDBKL> Statistical machine translation </E2:UDBKL> ( such as <E1:UDBKL> generalized example-based MT </E1:UDBKL> ) ."
"related-to","0","22","<E1:proteins> Wolfram Mathematica </E1:proteins> ( usually termed Mathematica ) is a modern technical computing system spanning most areas of technical - including <E2:proteins> neural networks </E2:proteins> , machine learning , image processing , geometry , data science , visualizations , and others ."
"part-of","0","25","<E1:proteins> Wolfram Mathematica </E1:proteins> ( usually termed Mathematica ) is a modern technical computing system spanning most areas of technical - including neural networks , <E2:UDBKL> machine learning </E2:UDBKL> , image processing , geometry , data science , visualizations , and others ."
"role","0","28","<E1:proteins> Wolfram Mathematica </E1:proteins> ( usually termed Mathematica ) is a modern technical computing system spanning most areas of technical - including neural networks , machine learning , <E2:UDBKL> image processing </E2:UDBKL> , geometry , data science , visualizations , and others ."
"role","0","31","<E1:proteins> Wolfram Mathematica </E1:proteins> ( usually termed Mathematica ) is a modern technical computing system spanning most areas of technical - including neural networks , machine learning , image processing , <E2:UDBKL> geometry </E2:UDBKL> , data science , visualizations , and others ."
"role","0","33","<E1:proteins> Wolfram Mathematica </E1:proteins> ( usually termed Mathematica ) is a modern technical computing system spanning most areas of technical - including neural networks , machine learning , image processing , geometry , <E2:UDBKL> data science </E2:UDBKL> , visualizations , and others ."
"role","0","36","<E1:proteins> Wolfram Mathematica </E1:proteins> ( usually termed Mathematica ) is a modern technical computing system spanning most areas of technical - including neural networks , machine learning , image processing , geometry , data science , <E2:UDBKL> visualizations </E2:UDBKL> , and others ."
"named","7","0","<E2:proteins> Wolfram Mathematica </E2:proteins> ( usually termed <E1:proteins> Mathematica </E1:proteins> ) is a modern technical computing system spanning most areas of technical - including neural networks , machine learning , image processing , geometry , data science , visualizations , and others ."
"part-of","21","2","The first <E2:proteins> digitally operated and programmable robot </E2:proteins> was invented by George Devol in 1954 and was ultimately called the <E1:proteins> Unimate </E1:proteins> ."
"artifact","21","10","The first digitally operated and programmable robot was invented by <E2:author> George Devol </E2:author> in 1954 and was ultimately called the <E1:proteins> Unimate </E1:proteins> ."
"related-to","1","5","Like <E1:proteins> DBNs </E1:proteins> , <E2:proteins> DBMs </E2:proteins> can learn complex and abstract internal representations of the input in tasks such as Object recognition or speech recognition , using limited , labeled data to fine-tune the representations built using a large set of unlabeled sensory input data ."
"related-to","3","20","Like DBNs , <E1:proteins> DBMs </E1:proteins> can learn complex and abstract internal representations of the input in tasks such as <E2:UDBKL> Object recognition </E2:UDBKL> or speech recognition , using limited , labeled data to fine-tune the representations built using a large set of unlabeled sensory input data ."
"related-to","3","23","Like DBNs , <E1:proteins> DBMs </E1:proteins> can learn complex and abstract internal representations of the input in tasks such as Object recognition or <E2:UDBKL> speech recognition </E2:UDBKL> , using limited , labeled data to fine-tune the representations built using a large set of unlabeled sensory input data ."
"part-of","13","3","Scientific conferences where <E2:UDBKL> vision based activity recognition </E2:UDBKL> work often appears are <E1:UDBKL> ICCV </E1:UDBKL> and CVPR ."
"part-of","15","3","Scientific conferences where <E2:UDBKL> vision based activity recognition </E2:UDBKL> work often appears are ICCV and <E1:UDBKL> CVPR </E1:UDBKL> ."
"named","6","1","In <E2:UDBKL> statistics </E2:UDBKL> , an <E1:proteins> expectation-maximization </E1:proteins> ( EM ) algorithm is an iterative method to find maximum likelihood or maximum a posteriori ( MAP ) estimates of parameter s in statistical model s , where the model depends on unobserved latent variable s ."
"part-of","4","17","In statistics , an <E1:proteins> expectation-maximization </E1:proteins> ( EM ) algorithm is an iterative method to find <E2:UDBKL> maximum likelihood </E2:UDBKL> or maximum a posteriori ( MAP ) estimates of parameter s in statistical model s , where the model depends on unobserved latent variable s ."
"named","4","20","In statistics , an <E1:proteins> expectation-maximization </E1:proteins> ( EM ) algorithm is an iterative method to find maximum likelihood or <E2:UDBKL> maximum a posteriori </E2:UDBKL> ( MAP ) estimates of parameter s in statistical model s , where the model depends on unobserved latent variable s ."
"related-to","4","41","In statistics , an <E1:proteins> expectation-maximization </E1:proteins> ( EM ) algorithm is an iterative method to find maximum likelihood or maximum a posteriori ( MAP ) estimates of parameter s in statistical model s , where the model depends on unobserved <E2:proteins> latent variable </E2:proteins> s ."
"named","8","4","In statistics , an <E2:proteins> expectation-maximization </E2:proteins> ( <E1:proteins> EM </E1:proteins> ) algorithm is an iterative method to find maximum likelihood or maximum a posteriori ( MAP ) estimates of parameter s in statistical model s , where the model depends on unobserved latent variable s ."
"named","24","18","In statistics , an expectation-maximization ( EM ) algorithm is an iterative method to find maximum likelihood or <E2:UDBKL> maximum a posteriori </E2:UDBKL> ( <E1:UDBKL> MAP </E1:UDBKL> ) estimates of parameter s in statistical model s , where the model depends on unobserved latent variable s ."
"named","12","6","Similarly , investigators sometimes report the <E2:UDBKL> FALSE Positive Rate </E2:UDBKL> ( <E1:UDBKL> FPR </E1:UDBKL> ) as well as the FALSE Negative Rate ( FNR ) ."
"named","22","16","Similarly , investigators sometimes report the FALSE Positive Rate ( FPR ) as well as the <E2:UDBKL> FALSE Negative Rate </E2:UDBKL> ( <E1:UDBKL> FNR </E1:UDBKL> ) ."
"part-of","15","6","The concept is similar to the <E2:UDBKL> signal to noise ratio </E2:UDBKL> used in the <E1:UDBKL> sciences </E1:UDBKL> and confusion matrix used in artificial intelligence ."
"part-of","21","15","The concept is similar to the signal to noise ratio used in the sciences and <E2:UDBKL> confusion matrix </E2:UDBKL> used in <E1:UDBKL> artificial intelligence </E1:UDBKL> ."
"role","5","15","The Code of Ethics on <E1:UDBKL> Human Augmentation </E1:UDBKL> , which was originally introduced by <E2:author> Steve Mann </E2:author> in 2004 and refined with Ray Kurzweil and Marvin Minsky in 2013 , was ultimately ratified at the Virtual Reality Toronto conference on June 25 , 2017 ."
"role","5","22","The Code of Ethics on <E1:UDBKL> Human Augmentation </E1:UDBKL> , which was originally introduced by Steve Mann in 2004 and refined with <E2:author> Ray Kurzweil </E2:author> and Marvin Minsky in 2013 , was ultimately ratified at the Virtual Reality Toronto conference on June 25 , 2017 ."
"role","5","25","The Code of Ethics on <E1:UDBKL> Human Augmentation </E1:UDBKL> , which was originally introduced by Steve Mann in 2004 and refined with Ray Kurzweil and <E2:author> Marvin Minsky </E2:author> in 2013 , was ultimately ratified at the Virtual Reality Toronto conference on June 25 , 2017 ."
"part-of","35","5","The Code of Ethics on <E2:UDBKL> Human Augmentation </E2:UDBKL> , which was originally introduced by Steve Mann in 2004 and refined with Ray Kurzweil and Marvin Minsky in 2013 , was ultimately ratified at the <E1:UDBKL> Virtual Reality Toronto conference </E1:UDBKL> on June 25 , 2017 ."
"role","3","13","In 1913 , <E1:UDBKL> Walter R. Booth </E1:UDBKL> directed 10 films for the <E2:UDBKL> U.K. Kinoplastikon </E2:UDBKL> , presumably in collaboration with Cecil Hepworth ."
"role","3","20","In 1913 , <E1:UDBKL> Walter R. Booth </E1:UDBKL> directed 10 films for the U.K. Kinoplastikon , presumably in collaboration with <E2:UDBKL> Cecil Hepworth </E2:UDBKL> ."
"physical","16","12","They introduced their new robot in 1961 at a trade show at <E2:UDBKL> Chicago </E2:UDBKL> 's <E1:UDBKL> Cow Palace </E1:UDBKL> ."
"related-to","2","8","While some <E1:proteins> chatbot </E1:proteins> applications use extensive <E2:UDBKL> word-classification </E2:UDBKL> processes , natural language processing processors , and sophisticated Artificial intelligence , others simply scan for general keywords and generate responses using common phrases obtained from an associated library or database ."
"related-to","2","11","While some <E1:proteins> chatbot </E1:proteins> applications use extensive word-classification processes , <E2:UDBKL> natural language processing </E2:UDBKL> processors , and sophisticated Artificial intelligence , others simply scan for general keywords and generate responses using common phrases obtained from an associated library or database ."
"related-to","2","18","While some <E1:proteins> chatbot </E1:proteins> applications use extensive word-classification processes , natural language processing processors , and sophisticated <E2:UDBKL> Artificial intelligence </E2:UDBKL> , others simply scan for general keywords and generate responses using common phrases obtained from an associated library or database ."
"related-to","4","8","Organizations known to use <E1:proteins> ALE </E1:proteins> for <E2:proteins> Emergency management </E2:proteins> , disaster relief , ordinary communication or extraordinary situation response : American Red Cross , FEMA , Disaster Medical Assistance Team s , NATO , Federal Bureau of Investigation , United Nations , AT & T , Civil Air Patrol , ( ARES ) ."
"related-to","4","11","Organizations known to use <E1:proteins> ALE </E1:proteins> for Emergency management , <E2:proteins> disaster relief </E2:proteins> , ordinary communication or extraordinary situation response : American Red Cross , FEMA , Disaster Medical Assistance Team s , NATO , Federal Bureau of Investigation , United Nations , AT & T , Civil Air Patrol , ( ARES ) ."
"related-to","4","14","Organizations known to use <E1:proteins> ALE </E1:proteins> for Emergency management , disaster relief , <E2:proteins> ordinary communication </E2:proteins> or extraordinary situation response : American Red Cross , FEMA , Disaster Medical Assistance Team s , NATO , Federal Bureau of Investigation , United Nations , AT & T , Civil Air Patrol , ( ARES ) ."
"related-to","4","17","Organizations known to use <E1:proteins> ALE </E1:proteins> for Emergency management , disaster relief , ordinary communication or <E2:proteins> extraordinary situation response </E2:proteins> : American Red Cross , FEMA , Disaster Medical Assistance Team s , NATO , Federal Bureau of Investigation , United Nations , AT & T , Civil Air Patrol , ( ARES ) ."
"related-to","21","4","Organizations known to use <E2:proteins> ALE </E2:proteins> for Emergency management , disaster relief , ordinary communication or extraordinary situation response : <E1:UDBKL> American Red Cross </E1:UDBKL> , FEMA , Disaster Medical Assistance Team s , NATO , Federal Bureau of Investigation , United Nations , AT & T , Civil Air Patrol , ( ARES ) ."
"part-of","25","4","Organizations known to use <E2:proteins> ALE </E2:proteins> for Emergency management , disaster relief , ordinary communication or extraordinary situation response : American Red Cross , <E1:UDBKL> FEMA </E1:UDBKL> , Disaster Medical Assistance Team s , NATO , Federal Bureau of Investigation , United Nations , AT & T , Civil Air Patrol , ( ARES ) ."
"part-of","27","4","Organizations known to use <E2:proteins> ALE </E2:proteins> for Emergency management , disaster relief , ordinary communication or extraordinary situation response : American Red Cross , FEMA , <E1:UDBKL> Disaster Medical Assistance Team </E1:UDBKL> s , NATO , Federal Bureau of Investigation , United Nations , AT & T , Civil Air Patrol , ( ARES ) ."
"part-of","33","4","Organizations known to use <E2:proteins> ALE </E2:proteins> for Emergency management , disaster relief , ordinary communication or extraordinary situation response : American Red Cross , FEMA , Disaster Medical Assistance Team s , <E1:UDBKL> NATO </E1:UDBKL> , Federal Bureau of Investigation , United Nations , AT & T , Civil Air Patrol , ( ARES ) ."
"part-of","35","4","Organizations known to use <E2:proteins> ALE </E2:proteins> for Emergency management , disaster relief , ordinary communication or extraordinary situation response : American Red Cross , FEMA , Disaster Medical Assistance Team s , NATO , <E1:UDBKL> Federal Bureau of Investigation </E1:UDBKL> , United Nations , AT & T , Civil Air Patrol , ( ARES ) ."
"part-of","40","4","Organizations known to use <E2:proteins> ALE </E2:proteins> for Emergency management , disaster relief , ordinary communication or extraordinary situation response : American Red Cross , FEMA , Disaster Medical Assistance Team s , NATO , Federal Bureau of Investigation , <E1:UDBKL> United Nations </E1:UDBKL> , AT & T , Civil Air Patrol , ( ARES ) ."
"related-to","43","4","Organizations known to use <E2:proteins> ALE </E2:proteins> for Emergency management , disaster relief , ordinary communication or extraordinary situation response : American Red Cross , FEMA , Disaster Medical Assistance Team s , NATO , Federal Bureau of Investigation , United Nations , <E1:UDBKL> AT & T </E1:UDBKL> , Civil Air Patrol , ( ARES ) ."
"named","47","4","Organizations known to use <E2:proteins> ALE </E2:proteins> for Emergency management , disaster relief , ordinary communication or extraordinary situation response : American Red Cross , FEMA , Disaster Medical Assistance Team s , NATO , Federal Bureau of Investigation , United Nations , AT & T , <E1:UDBKL> Civil Air Patrol </E1:UDBKL> , ( ARES ) ."
"named","52","4","Organizations known to use <E2:proteins> ALE </E2:proteins> for Emergency management , disaster relief , ordinary communication or extraordinary situation response : American Red Cross , FEMA , Disaster Medical Assistance Team s , NATO , Federal Bureau of Investigation , United Nations , AT & T , Civil Air Patrol , ( <E1:UDBKL> ARES </E1:UDBKL> ) ."
"general-affiliation","0","12","<E1:proteins> WordNet </E1:proteins> , a freely available database originally designed as a <E2:proteins> semantic network </E2:proteins> based on psycholinguistic principles , was expanded by addition of definitions and is now also viewed as a dictionary ."
"related-to","0","16","<E1:proteins> WordNet </E1:proteins> , a freely available database originally designed as a semantic network based on <E2:proteins> psycholinguistic principles </E2:proteins> , was expanded by addition of definitions and is now also viewed as a dictionary ."
"part-of","18","5","Advances in the field of <E2:UDBKL> computational imaging </E2:UDBKL> research is presented in several venues including publications of <E1:UDBKL> SIGGRAPH </E1:UDBKL> and the ."
"related-to","12","0","<E2:UDBKL> Classification </E2:UDBKL> can be thought of as two separate problems - <E1:UDBKL> binary classification </E1:UDBKL> and multiclass classification ."
"related-to","15","0","<E2:UDBKL> Classification </E2:UDBKL> can be thought of as two separate problems - binary classification and <E1:UDBKL> multiclass classification </E1:UDBKL> ."
"part-of","20","12","Advanced gene finders for both prokaryotic and eukaryotic genomes typically use complex <E2:proteins> probabilistic model </E2:proteins> s , such as <E1:proteins> hidden Markov model </E1:proteins> s ( HMMs ) to combine information from a variety of different signal and content measurements ."
"named","25","18","Advanced gene finders for both prokaryotic and eukaryotic genomes typically use complex probabilistic model s , such as <E2:proteins> hidden Markov model </E2:proteins> s ( <E1:proteins> HMMs </E1:proteins> ) to combine information from a variety of different signal and content measurements ."
"named","0","11","<E1:proteins> Neuroevolution </E1:proteins> , or neuro-evolution , is a form of <E2:UDBKL> artificial intelligence </E2:UDBKL> that uses evolutionary algorithm s to generate artificial neural network s ( ANN ) , parameters , topology and rules. and evolutionary robotics ."
"related-to","0","15","<E1:proteins> Neuroevolution </E1:proteins> , or neuro-evolution , is a form of artificial intelligence that uses <E2:proteins> evolutionary algorithm </E2:proteins> s to generate artificial neural network s ( ANN ) , parameters , topology and rules. and evolutionary robotics ."
"named","5","0","<E2:proteins> Neuroevolution </E2:proteins> , or <E1:proteins> neuro-evolution </E1:proteins> , is a form of artificial intelligence that uses evolutionary algorithm s to generate artificial neural network s ( ANN ) , parameters , topology and rules. and evolutionary robotics ."
"part-of","20","0","<E2:proteins> Neuroevolution </E2:proteins> , or neuro-evolution , is a form of artificial intelligence that uses evolutionary algorithm s to generate <E1:proteins> artificial neural network </E1:proteins> s ( ANN ) , parameters , topology and rules. and evolutionary robotics ."
"named","25","18","Neuroevolution , or neuro-evolution , is a form of artificial intelligence that uses evolutionary algorithm s to generate <E2:proteins> artificial neural network </E2:proteins> s ( <E1:proteins> ANN </E1:proteins> ) , parameters , topology and rules. and evolutionary robotics ."
"named","34","0","<E2:proteins> Neuroevolution </E2:proteins> , or neuro-evolution , is a form of artificial intelligence that uses evolutionary algorithm s to generate artificial neural network s ( ANN ) , parameters , topology and rules. and <E1:proteins> evolutionary robotics </E1:proteins> ."
"origin","10","1","Since <E2:UDBKL> IBM </E2:UDBKL> proposed and realized the system of <E1:UDBKL> BLEU </E1:UDBKL> Papineni et al ."
"named","20","10","In 2009 , experts attended a conference hosted by the <E2:UDBKL> Association for the Advancement of Artificial Intelligence </E2:UDBKL> ( <E1:UDBKL> AAAI </E1:UDBKL> ) to discuss whether computers and robots might be able to acquire any autonomy , and how much these abilities might pose a threat or hazard ."
"named","35","24","After boosting , a classifier constructed from 200 features could yield a 95 % detection rate under a ^ { -5 } / math <E2:UDBKL> FALSE positive rate </E2:UDBKL> .P. Viola , M. Jones , <E1:UDBKL> Robust Real-time Object Detection </E1:UDBKL> , 2001 ."
"part-of","35","27","After boosting , a classifier constructed from 200 features could yield a 95 % detection rate under a ^ { -5 } / math FALSE positive rate <E2:author> .P. Viola </E2:author> , M. Jones , <E1:UDBKL> Robust Real-time Object Detection </E1:UDBKL> , 2001 ."
"origin","35","30","After boosting , a classifier constructed from 200 features could yield a 95 % detection rate under a ^ { -5 } / math FALSE positive rate .P. Viola , <E2:author> M. Jones </E2:author> , <E1:UDBKL> Robust Real-time Object Detection </E1:UDBKL> , 2001 ."
"general-affiliation","10","4","Two very commonly used <E2:proteins> loss functions </E2:proteins> are the <E1:UDBKL> mean squared error </E1:UDBKL> , mathL ( a ) = a ^ 2 / math , and the absolute loss , mathL ( a ) = | a | / math ."
"part-of","27","4","Two very commonly used <E2:proteins> loss functions </E2:proteins> are the mean squared error , mathL ( a ) = a ^ 2 / math , and the <E1:UDBKL> absolute loss </E1:UDBKL> , mathL ( a ) = | a | / math ."
"related-to","2","14","The soft-margin <E1:proteins> support vector machine </E1:proteins> described above is an example of an <E2:proteins> empirical risk minimization </E2:proteins> ( ERM ) for the hinge loss ."
"part-of","12","22","The soft-margin support vector machine described above is an example of an <E1:proteins> empirical risk minimization </E1:proteins> ( ERM ) for the <E2:UDBKL> hinge loss </E2:UDBKL> ."
"named","18","12","The soft-margin support vector machine described above is an example of an <E2:proteins> empirical risk minimization </E2:proteins> ( <E1:proteins> ERM </E1:proteins> ) for the hinge loss ."
"named","10","1","A <E2:UDBKL> deep learning </E2:UDBKL> based approach to MT , <E1:UDBKL> neural machine translation </E1:UDBKL> has made rapid progress in recent years , and Google has announced its translation services are now using this technology in preference to its previous statistical methods ."
"named","10","6","A deep learning based approach to <E2:UDBKL> MT </E2:UDBKL> , <E1:UDBKL> neural machine translation </E1:UDBKL> has made rapid progress in recent years , and Google has announced its translation services are now using this technology in preference to its previous statistical methods ."
"part-of","22","8","A deep learning based approach to MT , <E2:UDBKL> neural machine translation </E2:UDBKL> has made rapid progress in recent years , and <E1:UDBKL> Google </E1:UDBKL> has announced its translation services are now using this technology in preference to its previous statistical methods ."
"related-to","0","20","<E1:UDBKL> Face detection </E1:UDBKL> is used in biometrics , often as a part of ( or together with ) a <E2:proteins> facial recognition system </E2:proteins> ."
"part-of","20","5","Face detection is used in <E2:UDBKL> biometrics </E2:UDBKL> , often as a part of ( or together with ) a <E1:proteins> facial recognition system </E1:proteins> ."
"physical","5","15",", Ltd. in Thailand ; <E1:UDBKL> Komatsu ( Shanghai ) Ltd. </E1:UDBKL> in 1996 in <E2:UDBKL> Shanghai </E2:UDBKL> , China ; Industrial Power Alliance Ltd. in Japan , a joint venture with Cummins , in 1998 ; L & T-Komatsu Limited in India in 1998 ( shares sold in 2013 ) ; and Komatsu Brasil International Ltda. in Brazil in 1998 ."
"physical","13","17",", Ltd. in Thailand ; Komatsu ( Shanghai ) Ltd. in 1996 in <E1:UDBKL> Shanghai </E1:UDBKL> , <E2:UDBKL> China </E2:UDBKL> ; Industrial Power Alliance Ltd. in Japan , a joint venture with Cummins , in 1998 ; L & T-Komatsu Limited in India in 1998 ( shares sold in 2013 ) ; and Komatsu Brasil International Ltda. in Brazil in 1998 ."
"physical","17","24",", Ltd. in Thailand ; Komatsu ( Shanghai ) Ltd. in 1996 in Shanghai , China ; <E1:UDBKL> Industrial Power Alliance Ltd. </E1:UDBKL> in <E2:UDBKL> Japan </E2:UDBKL> , a joint venture with Cummins , in 1998 ; L & T-Komatsu Limited in India in 1998 ( shares sold in 2013 ) ; and Komatsu Brasil International Ltda. in Brazil in 1998 ."
"physical","33","40",", Ltd. in Thailand ; Komatsu ( Shanghai ) Ltd. in 1996 in Shanghai , China ; Industrial Power Alliance Ltd. in Japan , a joint venture with Cummins , in 1998 ; <E1:UDBKL> L & T-Komatsu Limited </E1:UDBKL> in <E2:UDBKL> India </E2:UDBKL> in 1998 ( shares sold in 2013 ) ; and Komatsu Brasil International Ltda. in Brazil in 1998 ."
"physical","49","56",", Ltd. in Thailand ; Komatsu ( Shanghai ) Ltd. in 1996 in Shanghai , China ; Industrial Power Alliance Ltd. in Japan , a joint venture with Cummins , in 1998 ; L & T-Komatsu Limited in India in 1998 ( shares sold in 2013 ) ; and <E1:UDBKL> Komatsu Brasil International Ltda. </E1:UDBKL> in <E2:UDBKL> Brazil </E2:UDBKL> in 1998 ."
"role","14","0","<E2:UDBKL> dgp </E2:UDBKL> also occasionally hosts artists in residence ( e.g. , Oscar -winner <E1:UDBKL> Chris Landreth </E1:UDBKL> ."
"general-affiliation","14","4","dgp also occasionally hosts <E2:proteins> artists in residence </E2:proteins> ( e.g. , Oscar -winner <E1:UDBKL> Chris Landreth </E1:UDBKL> ."
"general-affiliation","14","10","dgp also occasionally hosts artists in residence ( e.g. , <E2:proteins> Oscar </E2:proteins> -winner <E1:UDBKL> Chris Landreth </E1:UDBKL> ."
"related-to","7","23","By the early 2000s , the dominant <E1:UDBKL> speech processing </E1:UDBKL> strategy started to shift away from Hidden Markov model towards more modern <E2:proteins> neural networks </E2:proteins> and deep learning ."
"part-of","7","26","By the early 2000s , the dominant <E1:UDBKL> speech processing </E1:UDBKL> strategy started to shift away from Hidden Markov model towards more modern neural networks and <E2:UDBKL> deep learning </E2:UDBKL> ."
"part-of","16","23","Another equivalent expression , in the case of a binary target rate , is that the <E1:UDBKL> TRUE positive rate </E1:UDBKL> and the <E2:UDBKL> FALSE positive rate </E2:UDBKL> are equal ( and therefore the FALSE negative rate and the TRUE negative rate are equal ) for every value of the sensitive characteristics :"
"named","30","37","Another equivalent expression , in the case of a binary target rate , is that the TRUE positive rate and the FALSE positive rate are equal ( and therefore the <E1:UDBKL> FALSE negative rate </E1:UDBKL> and the <E2:UDBKL> TRUE negative rate </E2:UDBKL> are equal ) for every value of the sensitive characteristics :"
"part-of","9","1","An <E2:proteins> articulated robot </E2:proteins> is a robot with <E1:proteins> rotary joint </E1:proteins> s ( e.g. a legged robot or an industrial robot ) ."
"named","19","1","An <E2:proteins> articulated robot </E2:proteins> is a robot with rotary joint s ( e.g. a legged robot or an <E1:proteins> industrial robot </E1:proteins> ) ."
"general-affiliation","0","15","<E1:proteins> Pandora </E1:proteins> ( also known as Pandora Media or Pandora Radio ) is an <E2:proteins> American </E2:proteins> music streaming and automated Recommender system internet radio service powered by the Music Genome Project and headquartered in Oakland , California ."
"related-to","0","28","<E1:proteins> Pandora </E1:proteins> ( also known as Pandora Media or Pandora Radio ) is an American music streaming and automated Recommender system internet radio service powered by the <E2:proteins> Music Genome Project </E2:proteins> and headquartered in Oakland , California ."
"physical","0","34","<E1:proteins> Pandora </E1:proteins> ( also known as Pandora Media or Pandora Radio ) is an American music streaming and automated Recommender system internet radio service powered by the Music Genome Project and headquartered in <E2:UDBKL> Oakland </E2:UDBKL> , California ."
"named","7","0","<E2:proteins> Pandora </E2:proteins> ( also known as <E1:proteins> Pandora Media </E1:proteins> or Pandora Radio ) is an American music streaming and automated Recommender system internet radio service powered by the Music Genome Project and headquartered in Oakland , California ."
"named","10","0","<E2:proteins> Pandora </E2:proteins> ( also known as Pandora Media or <E1:proteins> Pandora Radio </E1:proteins> ) is an American music streaming and automated Recommender system internet radio service powered by the Music Genome Project and headquartered in Oakland , California ."
"physical","32","36","Pandora ( also known as Pandora Media or Pandora Radio ) is an American music streaming and automated Recommender system internet radio service powered by the Music Genome Project and headquartered in <E1:UDBKL> Oakland </E1:UDBKL> , <E2:UDBKL> California </E2:UDBKL> ."
"role","0","7","<E1:author> James S. Albus </E1:author> of the <E2:UDBKL> National Institute of Standards and Technology </E2:UDBKL> ( NIST ) developed the Robocrane , where the platform hangs from six cables instead of being supported by six jacks ."
"named","14","5","James S. Albus of the <E2:UDBKL> National Institute of Standards and Technology </E2:UDBKL> ( <E1:UDBKL> NIST </E1:UDBKL> ) developed the Robocrane , where the platform hangs from six cables instead of being supported by six jacks ."
"artifact","18","0","<E2:author> James S. Albus </E2:author> of the National Institute of Standards and Technology ( NIST ) developed the <E1:proteins> Robocrane </E1:proteins> , where the platform hangs from six cables instead of being supported by six jacks ."
"part-of","11","3","Another class of <E2:proteins> direct search algorithms </E2:proteins> are the various <E1:proteins> evolutionary algorithm </E1:proteins> s , e.g. genetic algorithm s ."
"part-of","16","9","Another class of direct search algorithms are the various <E2:proteins> evolutionary algorithm </E2:proteins> s , e.g. <E1:proteins> genetic algorithm </E1:proteins> s ."
"named","5","0","<E2:UDBKL> KUKA </E2:UDBKL> is a <E1:proteins> German manufacturer </E1:proteins> of industrial robot s and solution s for factory automation ."
"named","8","0","<E2:UDBKL> KUKA </E2:UDBKL> is a German manufacturer of <E1:proteins> industrial robot </E1:proteins> s and solution s for factory automation ."
"role","15","9","Other films between 2016 to 2020 that captured with <E2:proteins> IMAX </E2:proteins> camera 's were <E1:UDBKL> Zack Snyder </E1:UDBKL> ' s Batman v Superman : Dawn of Justice , Clint Eastwood ' s Sully , Damien Chazelle ' s First Man , Patty Jenkins ' Wonder Woman 1984 , Cary Joji Fukunaga ' s No Time to Die and Joseph Kosinski ' s Top Gun : Maverick ."
"artifact","19","13","Other films between 2016 to 2020 that captured with IMAX camera 's were <E2:UDBKL> Zack Snyder </E2:UDBKL> ' s <E1:proteins> Batman v Superman : Dawn of Justice </E1:proteins> , Clint Eastwood ' s Sully , Damien Chazelle ' s First Man , Patty Jenkins ' Wonder Woman 1984 , Cary Joji Fukunaga ' s No Time to Die and Joseph Kosinski ' s Top Gun : Maverick ."
"role","27","9","Other films between 2016 to 2020 that captured with <E2:proteins> IMAX </E2:proteins> camera 's were Zack Snyder ' s Batman v Superman : Dawn of Justice , <E1:UDBKL> Clint Eastwood </E1:UDBKL> ' s Sully , Damien Chazelle ' s First Man , Patty Jenkins ' Wonder Woman 1984 , Cary Joji Fukunaga ' s No Time to Die and Joseph Kosinski ' s Top Gun : Maverick ."
"artifact","31","25","Other films between 2016 to 2020 that captured with IMAX camera 's were Zack Snyder ' s Batman v Superman : Dawn of Justice , <E2:UDBKL> Clint Eastwood </E2:UDBKL> ' s <E1:proteins> Sully </E1:proteins> , Damien Chazelle ' s First Man , Patty Jenkins ' Wonder Woman 1984 , Cary Joji Fukunaga ' s No Time to Die and Joseph Kosinski ' s Top Gun : Maverick ."
"role","33","9","Other films between 2016 to 2020 that captured with <E2:proteins> IMAX </E2:proteins> camera 's were Zack Snyder ' s Batman v Superman : Dawn of Justice , Clint Eastwood ' s Sully , <E1:UDBKL> Damien Chazelle </E1:UDBKL> ' s First Man , Patty Jenkins ' Wonder Woman 1984 , Cary Joji Fukunaga ' s No Time to Die and Joseph Kosinski ' s Top Gun : Maverick ."
"artifact","37","31","Other films between 2016 to 2020 that captured with IMAX camera 's were Zack Snyder ' s Batman v Superman : Dawn of Justice , Clint Eastwood ' s Sully , <E2:UDBKL> Damien Chazelle </E2:UDBKL> ' s <E1:proteins> First Man </E1:proteins> , Patty Jenkins ' Wonder Woman 1984 , Cary Joji Fukunaga ' s No Time to Die and Joseph Kosinski ' s Top Gun : Maverick ."
"role","40","9","Other films between 2016 to 2020 that captured with <E2:proteins> IMAX </E2:proteins> camera 's were Zack Snyder ' s Batman v Superman : Dawn of Justice , Clint Eastwood ' s Sully , Damien Chazelle ' s First Man , <E1:UDBKL> Patty Jenkins </E1:UDBKL> ' Wonder Woman 1984 , Cary Joji Fukunaga ' s No Time to Die and Joseph Kosinski ' s Top Gun : Maverick ."
"artifact","43","38","Other films between 2016 to 2020 that captured with IMAX camera 's were Zack Snyder ' s Batman v Superman : Dawn of Justice , Clint Eastwood ' s Sully , Damien Chazelle ' s First Man , <E2:UDBKL> Patty Jenkins </E2:UDBKL> ' <E1:proteins> Wonder Woman 1984 </E1:proteins> , Cary Joji Fukunaga ' s No Time to Die and Joseph Kosinski ' s Top Gun : Maverick ."
"role","47","9","Other films between 2016 to 2020 that captured with <E2:proteins> IMAX </E2:proteins> camera 's were Zack Snyder ' s Batman v Superman : Dawn of Justice , Clint Eastwood ' s Sully , Damien Chazelle ' s First Man , Patty Jenkins ' Wonder Woman 1984 , <E1:UDBKL> Cary Joji Fukunaga </E1:UDBKL> ' s No Time to Die and Joseph Kosinski ' s Top Gun : Maverick ."
"artifact","52","45","Other films between 2016 to 2020 that captured with IMAX camera 's were Zack Snyder ' s Batman v Superman : Dawn of Justice , Clint Eastwood ' s Sully , Damien Chazelle ' s First Man , Patty Jenkins ' Wonder Woman 1984 , <E2:UDBKL> Cary Joji Fukunaga </E2:UDBKL> ' s <E1:proteins> No Time to Die </E1:proteins> and Joseph Kosinski ' s Top Gun : Maverick ."
"role","57","9","Other films between 2016 to 2020 that captured with <E2:proteins> IMAX </E2:proteins> camera 's were Zack Snyder ' s Batman v Superman : Dawn of Justice , Clint Eastwood ' s Sully , Damien Chazelle ' s First Man , Patty Jenkins ' Wonder Woman 1984 , Cary Joji Fukunaga ' s No Time to Die and <E1:UDBKL> Joseph Kosinski </E1:UDBKL> ' s Top Gun : Maverick ."
"artifact","61","55","Other films between 2016 to 2020 that captured with IMAX camera 's were Zack Snyder ' s Batman v Superman : Dawn of Justice , Clint Eastwood ' s Sully , Damien Chazelle ' s First Man , Patty Jenkins ' Wonder Woman 1984 , Cary Joji Fukunaga ' s No Time to Die and <E2:UDBKL> Joseph Kosinski </E2:UDBKL> ' s <E1:proteins> Top Gun : Maverick </E1:proteins> ."
"related-to","3","29","The trial of <E1:proteins> MICR E13B </E1:proteins> font was shown to the American Bankers Association ( ABA ) in July 1956 , which adopted it in 1958 as the <E2:proteins> MICR </E2:proteins> standard for negotiable document s in the United States ."
"part-of","12","3","The trial of <E2:proteins> MICR E13B </E2:proteins> font was shown to the <E1:UDBKL> American Bankers Association </E1:UDBKL> ( ABA ) in July 1956 , which adopted it in 1958 as the MICR standard for negotiable document s in the United States ."
"physical","10","37","The trial of MICR E13B font was shown to the <E1:UDBKL> American Bankers Association </E1:UDBKL> ( ABA ) in July 1956 , which adopted it in 1958 as the MICR standard for negotiable document s in the <E2:UDBKL> United States </E2:UDBKL> ."
"named","16","10","The trial of MICR E13B font was shown to the <E2:UDBKL> American Bankers Association </E2:UDBKL> ( <E1:UDBKL> ABA </E1:UDBKL> ) in July 1956 , which adopted it in 1958 as the MICR standard for negotiable document s in the United States ."
"part-of","17","0","<E2:proteins> Local search algorithms </E2:proteins> are widely applied to numerous hard computational problems , including problems from <E1:UDBKL> computer science </E1:UDBKL> ( particularly artificial intelligence ) , mathematics , operations research , engineering , and bioinformatics ."
"named","21","15","Local search algorithms are widely applied to numerous hard computational problems , including problems from <E2:UDBKL> computer science </E2:UDBKL> ( particularly <E1:UDBKL> artificial intelligence </E1:UDBKL> ) , mathematics , operations research , engineering , and bioinformatics ."
"part-of","25","0","<E2:proteins> Local search algorithms </E2:proteins> are widely applied to numerous hard computational problems , including problems from computer science ( particularly artificial intelligence ) , <E1:UDBKL> mathematics </E1:UDBKL> , operations research , engineering , and bioinformatics ."
"part-of","27","0","<E2:proteins> Local search algorithms </E2:proteins> are widely applied to numerous hard computational problems , including problems from computer science ( particularly artificial intelligence ) , mathematics , <E1:UDBKL> operations research </E1:UDBKL> , engineering , and bioinformatics ."
"part-of","30","0","<E2:proteins> Local search algorithms </E2:proteins> are widely applied to numerous hard computational problems , including problems from computer science ( particularly artificial intelligence ) , mathematics , operations research , <E1:UDBKL> engineering </E1:UDBKL> , and bioinformatics ."
"part-of","33","0","<E2:proteins> Local search algorithms </E2:proteins> are widely applied to numerous hard computational problems , including problems from computer science ( particularly artificial intelligence ) , mathematics , operations research , engineering , and <E1:UDBKL> bioinformatics </E1:UDBKL> ."
"physical","0","11","<E1:author> Gerd Gigerenzer </E1:author> ( born September 3 , 1947 , <E2:UDBKL> Wallersdorf </E2:UDBKL> , Germany ) is a Germany psychologist who has studied the use of bounded rationality and heuristic s in decision making ."
"physical","0","17","<E1:author> Gerd Gigerenzer </E1:author> ( born September 3 , 1947 , Wallersdorf , Germany ) is a <E2:UDBKL> Germany </E2:UDBKL> psychologist who has studied the use of bounded rationality and heuristic s in decision making ."
"related-to","0","25","<E1:author> Gerd Gigerenzer </E1:author> ( born September 3 , 1947 , Wallersdorf , Germany ) is a Germany psychologist who has studied the use of <E2:proteins> bounded rationality </E2:proteins> and heuristic s in decision making ."
"related-to","0","28","<E1:author> Gerd Gigerenzer </E1:author> ( born September 3 , 1947 , Wallersdorf , Germany ) is a Germany psychologist who has studied the use of bounded rationality and <E2:proteins> heuristic </E2:proteins> s in decision making ."
"physical","9","13","Gerd Gigerenzer ( born September 3 , 1947 , <E1:UDBKL> Wallersdorf </E1:UDBKL> , <E2:UDBKL> Germany </E2:UDBKL> ) is a Germany psychologist who has studied the use of bounded rationality and heuristic s in decision making ."
"named","26","31","Gerd Gigerenzer ( born September 3 , 1947 , Wallersdorf , Germany ) is a Germany psychologist who has studied the use of bounded rationality and <E1:proteins> heuristic </E1:proteins> s in <E2:UDBKL> decision making </E2:UDBKL> ."
"role","12","18","But even an official language with a regulating academy , such as <E1:proteins> Standard French </E1:proteins> with the <E2:UDBKL> Académie française </E2:UDBKL> , is classified as a natural language ( for example , in the field of natural language processing ) , as its prescriptive points do not make it either constructed enough to be classified as a constructed language or controlled enough to be classified as a controlled natural language ."
"named","54","66","But even an official language with a regulating academy , such as Standard French with the Académie française , is classified as a natural language ( for example , in the field of natural language processing ) , as its prescriptive points do not make it either constructed enough to be classified as a <E1:proteins> constructed language </E1:proteins> or controlled enough to be classified as a <E2:proteins> controlled natural language </E2:proteins> ."
"named","18","13","There are a number of other metrics , most simply the accuracy or <E2:UDBKL> Fraction Correct </E2:UDBKL> ( <E1:UDBKL> FC </E1:UDBKL> ) , which measures the fraction of all instances that are correctly categorized ; the complement is the Fraction Incorrect ( FiC ) ."
"named","40","35","There are a number of other metrics , most simply the accuracy or Fraction Correct ( FC ) , which measures the fraction of all instances that are correctly categorized ; the complement is the <E2:UDBKL> Fraction Incorrect </E2:UDBKL> ( <E1:UDBKL> FiC </E1:UDBKL> ) ."
"role","0","8","<E1:author> Cardie </E1:author> became a Fellow of the <E2:UDBKL> Association for Computational Linguistics </E2:UDBKL> in 2016 ."
"part-of","10","0","<E2:UDBKL> Cluster analysis </E2:UDBKL> , and Non-negative matrix factorization for <E1:UDBKL> descriptive mining </E1:UDBKL> ."
"part-of","10","4","Cluster analysis , and <E2:proteins> Non-negative matrix factorization </E2:proteins> for <E1:UDBKL> descriptive mining </E1:UDBKL> ."
"named","26","1","In <E2:UDBKL> computer science </E2:UDBKL> and the information technology that it enables , it has been a long-term challenge to the ability in computers to do <E1:UDBKL> natural language processing </E1:UDBKL> and machine learning ."
"part-of","26","5","In computer science and the <E2:UDBKL> information technology </E2:UDBKL> that it enables , it has been a long-term challenge to the ability in computers to do <E1:UDBKL> natural language processing </E1:UDBKL> and machine learning ."
"named","30","1","In <E2:UDBKL> computer science </E2:UDBKL> and the information technology that it enables , it has been a long-term challenge to the ability in computers to do natural language processing and <E1:UDBKL> machine learning </E1:UDBKL> ."
"named","30","5","In computer science and the <E2:UDBKL> information technology </E2:UDBKL> that it enables , it has been a long-term challenge to the ability in computers to do natural language processing and <E1:UDBKL> machine learning </E1:UDBKL> ."
"related-to","3","11","( Code for <E1:proteins> Gabor feature extraction </E1:proteins> from images in <E2:proteins> MATLAB </E2:proteins> can be found at"
"related-to","1","18","The <E1:proteins> NeuralExpert </E1:proteins> centers the design specifications around the type of problem the user would like the <E2:proteins> neural network </E2:proteins> to solve ( Classification , Prediction , Function approximation or Cluster analysis ) ."
"named","1","23","The <E1:proteins> NeuralExpert </E1:proteins> centers the design specifications around the type of problem the user would like the neural network to solve ( <E2:UDBKL> Classification </E2:UDBKL> , Prediction , Function approximation or Cluster analysis ) ."
"named","1","25","The <E1:proteins> NeuralExpert </E1:proteins> centers the design specifications around the type of problem the user would like the neural network to solve ( Classification , <E2:UDBKL> Prediction </E2:UDBKL> , Function approximation or Cluster analysis ) ."
"named","1","27","The <E1:proteins> NeuralExpert </E1:proteins> centers the design specifications around the type of problem the user would like the neural network to solve ( Classification , Prediction , <E2:UDBKL> Function approximation </E2:UDBKL> or Cluster analysis ) ."
"role","1","30","The <E1:proteins> NeuralExpert </E1:proteins> centers the design specifications around the type of problem the user would like the neural network to solve ( Classification , Prediction , Function approximation or <E2:UDBKL> Cluster analysis </E2:UDBKL> ) ."
"role","17","0","<E2:UDBKL> Kawasaki </E2:UDBKL> 's portfolio also includes retractable roofs , floors and other giant structures , the <E1:UDBKL> Sapporo Dome </E1:UDBKL> ' retractable surface is one example ."
"part-of","0","17","<E1:UDBKL> Kappa statistics </E1:UDBKL> such as Fleiss ' kappa and Cohen 's kappa are methods for calculating <E2:UDBKL> inter-rater reliability </E2:UDBKL> based on different assumptions about the marginal or prior distributions , and are increasingly used as chance corrected alternatives to accuracy in other contexts ."
"related-to","0","39","<E1:UDBKL> Kappa statistics </E1:UDBKL> such as Fleiss ' kappa and Cohen 's kappa are methods for calculating inter-rater reliability based on different assumptions about the marginal or prior distributions , and are increasingly used as chance corrected alternatives to <E2:UDBKL> accuracy </E2:UDBKL> in other contexts ."
"related-to","6","0","<E2:UDBKL> Kappa statistics </E2:UDBKL> such as <E1:UDBKL> Fleiss ' kappa </E1:UDBKL> and Cohen 's kappa are methods for calculating inter-rater reliability based on different assumptions about the marginal or prior distributions , and are increasingly used as chance corrected alternatives to accuracy in other contexts ."
"related-to","10","0","<E2:UDBKL> Kappa statistics </E2:UDBKL> such as Fleiss ' kappa and <E1:UDBKL> Cohen 's kappa </E1:UDBKL> are methods for calculating inter-rater reliability based on different assumptions about the marginal or prior distributions , and are increasingly used as chance corrected alternatives to accuracy in other contexts ."
"role","3","20","With his students <E1:author> Sepp Hochreiter </E1:author> , Felix Gers , Fred Cummins , Alex Graves , and others , <E2:author> Schmidhuber </E2:author> published increasingly sophisticated versions of a type of recurrent neural network called the long short-term memory ( LSTM ) ."
"role","6","20","With his students Sepp Hochreiter , <E1:author> Felix Gers </E1:author> , Fred Cummins , Alex Graves , and others , <E2:author> Schmidhuber </E2:author> published increasingly sophisticated versions of a type of recurrent neural network called the long short-term memory ( LSTM ) ."
"role","9","20","With his students Sepp Hochreiter , Felix Gers , <E1:author> Fred Cummins </E1:author> , Alex Graves , and others , <E2:author> Schmidhuber </E2:author> published increasingly sophisticated versions of a type of recurrent neural network called the long short-term memory ( LSTM ) ."
"role","12","20","With his students Sepp Hochreiter , Felix Gers , Fred Cummins , <E1:author> Alex Graves </E1:author> , and others , <E2:author> Schmidhuber </E2:author> published increasingly sophisticated versions of a type of recurrent neural network called the long short-term memory ( LSTM ) ."
"origin","34","3","With his students <E2:author> Sepp Hochreiter </E2:author> , Felix Gers , Fred Cummins , Alex Graves , and others , Schmidhuber published increasingly sophisticated versions of a type of recurrent neural network called the <E1:proteins> long short-term memory </E1:proteins> ( LSTM ) ."
"origin","34","6","With his students Sepp Hochreiter , <E2:author> Felix Gers </E2:author> , Fred Cummins , Alex Graves , and others , Schmidhuber published increasingly sophisticated versions of a type of recurrent neural network called the <E1:proteins> long short-term memory </E1:proteins> ( LSTM ) ."
"origin","34","9","With his students Sepp Hochreiter , Felix Gers , <E2:author> Fred Cummins </E2:author> , Alex Graves , and others , Schmidhuber published increasingly sophisticated versions of a type of recurrent neural network called the <E1:proteins> long short-term memory </E1:proteins> ( LSTM ) ."
"origin","34","12","With his students Sepp Hochreiter , Felix Gers , Fred Cummins , <E2:author> Alex Graves </E2:author> , and others , Schmidhuber published increasingly sophisticated versions of a type of recurrent neural network called the <E1:proteins> long short-term memory </E1:proteins> ( LSTM ) ."
"origin","34","18","With his students Sepp Hochreiter , Felix Gers , Fred Cummins , Alex Graves , and others , <E2:author> Schmidhuber </E2:author> published increasingly sophisticated versions of a type of recurrent neural network called the <E1:proteins> long short-term memory </E1:proteins> ( LSTM ) ."
"named","34","27","With his students Sepp Hochreiter , Felix Gers , Fred Cummins , Alex Graves , and others , Schmidhuber published increasingly sophisticated versions of a type of <E2:proteins> recurrent neural network </E2:proteins> called the <E1:proteins> long short-term memory </E1:proteins> ( LSTM ) ."
"named","38","32","With his students Sepp Hochreiter , Felix Gers , Fred Cummins , Alex Graves , and others , Schmidhuber published increasingly sophisticated versions of a type of recurrent neural network called the <E2:proteins> long short-term memory </E2:proteins> ( <E1:proteins> LSTM </E1:proteins> ) ."
"origin","5","14","The first practical forms of <E1:proteins> photography </E1:proteins> were introduced in January 1839 by <E2:UDBKL> Louis Daguerre </E2:UDBKL> and Henry Fox Talbot ."
"origin","5","17","The first practical forms of <E1:proteins> photography </E1:proteins> were introduced in January 1839 by Louis Daguerre and <E2:UDBKL> Henry Fox Talbot </E2:UDBKL> ."
"part-of","3","20","For example , <E1:UDBKL> speech synthesis </E1:UDBKL> , combined with speech recognition , allows for interaction with mobile devices via <E2:UDBKL> language processing </E2:UDBKL> interfaces ."
"part-of","8","20","For example , speech synthesis , combined with <E1:UDBKL> speech recognition </E1:UDBKL> , allows for interaction with mobile devices via <E2:UDBKL> language processing </E2:UDBKL> interfaces ."
"related-to","0","17","<E1:proteins> Phidgets </E1:proteins> can be programmed using a variety of software and programming languages , ranging from <E2:proteins> Java </E2:proteins> to Microsoft Excel ."
"related-to","0","19","<E1:proteins> Phidgets </E1:proteins> can be programmed using a variety of software and programming languages , ranging from Java to <E2:proteins> Microsoft Excel </E2:proteins> ."
"named","2","11","The term <E1:UDBKL> machine learning </E1:UDBKL> was coined in 1959 by <E2:author> Arthur Samuel </E2:author> , an American IBMer and pioneer in the field of computer gaming and artificial intelligence ."
"role","9","23","The term machine learning was coined in 1959 by <E1:author> Arthur Samuel </E1:author> , an American IBMer and pioneer in the field of <E2:UDBKL> computer gaming </E2:UDBKL> and artificial intelligence ."
"role","9","26","The term machine learning was coined in 1959 by <E1:author> Arthur Samuel </E1:author> , an American IBMer and pioneer in the field of computer gaming and <E2:UDBKL> artificial intelligence </E2:UDBKL> ."
"origin","15","9","The term machine learning was coined in 1959 by <E2:author> Arthur Samuel </E2:author> , an <E1:proteins> American IBMer </E1:proteins> and pioneer in the field of computer gaming and artificial intelligence ."
"general-affiliation","5","1","The <E2:proteins> Israeli poet </E2:proteins> <E1:UDBKL> David Avidan </E1:UDBKL> , who was fascinated with future technologies and their relation to art , desired to explore the use of computers for writing literature ."
"role","11","4","As part of the <E2:proteins> GATEway Project </E2:proteins> in 2017 , <E1:UDBKL> Oxbotica </E1:UDBKL> trialled seven autonomous shuttle buses in Greenwich , navigating a two-mile riverside path near London 's The O2 Arena on a route also used by pedestrians and cyclists ."
"physical","28","24","As part of the GATEway Project in 2017 , Oxbotica trialled seven autonomous shuttle buses in Greenwich , navigating a two-mile riverside path near <E2:UDBKL> London </E2:UDBKL> 's <E1:UDBKL> The O2 Arena </E1:UDBKL> on a route also used by pedestrians and cyclists ."
"related-to","14","24","An unrelated but commonly used combination of basic statistics from information retrieval is the <E1:UDBKL> F-score </E1:UDBKL> , being a ( possibly weighted ) <E2:proteins> harmonic mean </E2:proteins> of recall and precision where recall = sensitivity = TRUE positive rate , but specificity and precision are totally different measures ."
"related-to","14","27","An unrelated but commonly used combination of basic statistics from information retrieval is the <E1:UDBKL> F-score </E1:UDBKL> , being a ( possibly weighted ) harmonic mean of <E2:UDBKL> recall </E2:UDBKL> and precision where recall = sensitivity = TRUE positive rate , but specificity and precision are totally different measures ."
"part-of","14","29","An unrelated but commonly used combination of basic statistics from information retrieval is the <E1:UDBKL> F-score </E1:UDBKL> , being a ( possibly weighted ) harmonic mean of recall and <E2:UDBKL> precision </E2:UDBKL> where recall = sensitivity = TRUE positive rate , but specificity and precision are totally different measures ."
"named","25","31","An unrelated but commonly used combination of basic statistics from information retrieval is the F-score , being a ( possibly weighted ) harmonic mean of <E1:UDBKL> recall </E1:UDBKL> and precision where <E2:UDBKL> recall </E2:UDBKL> = sensitivity = TRUE positive rate , but specificity and precision are totally different measures ."
"named","27","42","An unrelated but commonly used combination of basic statistics from information retrieval is the F-score , being a ( possibly weighted ) harmonic mean of recall and <E1:UDBKL> precision </E1:UDBKL> where recall = sensitivity = TRUE positive rate , but specificity and <E2:UDBKL> precision </E2:UDBKL> are totally different measures ."
"named","29","40","An unrelated but commonly used combination of basic statistics from information retrieval is the F-score , being a ( possibly weighted ) harmonic mean of recall and precision where <E1:UDBKL> recall </E1:UDBKL> = sensitivity = TRUE positive rate , but <E2:UDBKL> specificity </E2:UDBKL> and precision are totally different measures ."
"named","29","42","An unrelated but commonly used combination of basic statistics from information retrieval is the F-score , being a ( possibly weighted ) harmonic mean of recall and precision where <E1:UDBKL> recall </E1:UDBKL> = sensitivity = TRUE positive rate , but specificity and <E2:UDBKL> precision </E2:UDBKL> are totally different measures ."
"named","33","29","An unrelated but commonly used combination of basic statistics from information retrieval is the F-score , being a ( possibly weighted ) harmonic mean of recall and precision where <E2:UDBKL> recall </E2:UDBKL> = <E1:UDBKL> sensitivity </E1:UDBKL> = TRUE positive rate , but specificity and precision are totally different measures ."
"named","35","29","An unrelated but commonly used combination of basic statistics from information retrieval is the F-score , being a ( possibly weighted ) harmonic mean of recall and precision where <E2:UDBKL> recall </E2:UDBKL> = sensitivity = <E1:UDBKL> TRUE positive rate </E1:UDBKL> , but specificity and precision are totally different measures ."
"role","0","12","<E1:UDBKL> Neuromorphic engineering </E1:UDBKL> is an interdisciplinary subject that takes inspiration from <E2:UDBKL> biology </E2:UDBKL> , physics , mathematics , computer science , and electronic engineering to design artificial neural systems , such as vision systems , head-eye systems , auditory processors , and autonomous robots , whose physical architecture and design principles are based on those of biological nervous systems ."
"role","0","14","<E1:UDBKL> Neuromorphic engineering </E1:UDBKL> is an interdisciplinary subject that takes inspiration from biology , <E2:UDBKL> physics </E2:UDBKL> , mathematics , computer science , and electronic engineering to design artificial neural systems , such as vision systems , head-eye systems , auditory processors , and autonomous robots , whose physical architecture and design principles are based on those of biological nervous systems ."
"role","0","16","<E1:UDBKL> Neuromorphic engineering </E1:UDBKL> is an interdisciplinary subject that takes inspiration from biology , physics , <E2:UDBKL> mathematics </E2:UDBKL> , computer science , and electronic engineering to design artificial neural systems , such as vision systems , head-eye systems , auditory processors , and autonomous robots , whose physical architecture and design principles are based on those of biological nervous systems ."
"role","0","18","<E1:UDBKL> Neuromorphic engineering </E1:UDBKL> is an interdisciplinary subject that takes inspiration from biology , physics , mathematics , <E2:UDBKL> computer science </E2:UDBKL> , and electronic engineering to design artificial neural systems , such as vision systems , head-eye systems , auditory processors , and autonomous robots , whose physical architecture and design principles are based on those of biological nervous systems ."
"role","0","22","<E1:UDBKL> Neuromorphic engineering </E1:UDBKL> is an interdisciplinary subject that takes inspiration from biology , physics , mathematics , computer science , and <E2:UDBKL> electronic engineering </E2:UDBKL> to design artificial neural systems , such as vision systems , head-eye systems , auditory processors , and autonomous robots , whose physical architecture and design principles are based on those of biological nervous systems ."
"part-of","32","0","<E2:UDBKL> Neuromorphic engineering </E2:UDBKL> is an interdisciplinary subject that takes inspiration from biology , physics , mathematics , computer science , and electronic engineering to design artificial neural systems , such as <E1:proteins> vision systems </E1:proteins> , head-eye systems , auditory processors , and autonomous robots , whose physical architecture and design principles are based on those of biological nervous systems ."
"part-of","35","0","<E2:UDBKL> Neuromorphic engineering </E2:UDBKL> is an interdisciplinary subject that takes inspiration from biology , physics , mathematics , computer science , and electronic engineering to design artificial neural systems , such as vision systems , <E1:proteins> head-eye systems </E1:proteins> , auditory processors , and autonomous robots , whose physical architecture and design principles are based on those of biological nervous systems ."
"part-of","38","0","<E2:UDBKL> Neuromorphic engineering </E2:UDBKL> is an interdisciplinary subject that takes inspiration from biology , physics , mathematics , computer science , and electronic engineering to design artificial neural systems , such as vision systems , head-eye systems , <E1:proteins> auditory processors </E1:proteins> , and autonomous robots , whose physical architecture and design principles are based on those of biological nervous systems ."
"part-of","42","0","<E2:UDBKL> Neuromorphic engineering </E2:UDBKL> is an interdisciplinary subject that takes inspiration from biology , physics , mathematics , computer science , and electronic engineering to design artificial neural systems , such as vision systems , head-eye systems , auditory processors , and <E1:proteins> autonomous robots </E1:proteins> , whose physical architecture and design principles are based on those of biological nervous systems ."
"origin","13","5","To be specific , the <E2:UDBKL> BIBO stability criterion </E2:UDBKL> requires that the <E1:UDBKL> ROC </E1:UDBKL> of the system includes the unit circle ."
"role","1","10","The <E1:UDBKL> MCC </E1:UDBKL> can be calculated directly from the <E2:UDBKL> confusion matrix </E2:UDBKL> using the formula :"
"temporal","8","19","It was developed by a team at the <E1:UDBKL> MIT-IBM Watson AI Lab </E1:UDBKL> and first presented at the <E2:UDBKL> 2018 International Conference on Learning Representations </E2:UDBKL> ."
"named","15","46","When the TRUE prevalence s for the two positive variables are equal as assumed in <E1:UDBKL> Fleiss kappa </E1:UDBKL> and F-score , that is the number of positive predictions matches the number of positive classes in the dichotomous ( two class ) case , the different <E2:UDBKL> kappa </E2:UDBKL> and correlation measure collapse to identity with Youden 's J , and recall , precision and F-score are similarly identical with accuracy ."
"related-to","15","54","When the TRUE prevalence s for the two positive variables are equal as assumed in <E1:UDBKL> Fleiss kappa </E1:UDBKL> and F-score , that is the number of positive predictions matches the number of positive classes in the dichotomous ( two class ) case , the different kappa and correlation measure collapse to identity with <E2:UDBKL> Youden 's J </E2:UDBKL> , and recall , precision and F-score are similarly identical with accuracy ."
"named","18","48","When the TRUE prevalence s for the two positive variables are equal as assumed in Fleiss kappa and <E1:UDBKL> F-score </E1:UDBKL> , that is the number of positive predictions matches the number of positive classes in the dichotomous ( two class ) case , the different kappa and <E2:UDBKL> correlation </E2:UDBKL> measure collapse to identity with Youden 's J , and recall , precision and F-score are similarly identical with accuracy ."
"related-to","18","54","When the TRUE prevalence s for the two positive variables are equal as assumed in Fleiss kappa and <E1:UDBKL> F-score </E1:UDBKL> , that is the number of positive predictions matches the number of positive classes in the dichotomous ( two class ) case , the different kappa and correlation measure collapse to identity with <E2:UDBKL> Youden 's J </E2:UDBKL> , and recall , precision and F-score are similarly identical with accuracy ."
"named","18","63","When the TRUE prevalence s for the two positive variables are equal as assumed in Fleiss kappa and <E1:UDBKL> F-score </E1:UDBKL> , that is the number of positive predictions matches the number of positive classes in the dichotomous ( two class ) case , the different kappa and correlation measure collapse to identity with Youden 's J , and recall , precision and <E2:UDBKL> F-score </E2:UDBKL> are similarly identical with accuracy ."
"named","57","68","When the TRUE prevalence s for the two positive variables are equal as assumed in Fleiss kappa and F-score , that is the number of positive predictions matches the number of positive classes in the dichotomous ( two class ) case , the different kappa and correlation measure collapse to identity with Youden 's J , and <E1:UDBKL> recall </E1:UDBKL> , precision and F-score are similarly identical with <E2:UDBKL> accuracy </E2:UDBKL> ."
"named","59","68","When the TRUE prevalence s for the two positive variables are equal as assumed in Fleiss kappa and F-score , that is the number of positive predictions matches the number of positive classes in the dichotomous ( two class ) case , the different kappa and correlation measure collapse to identity with Youden 's J , and recall , <E1:UDBKL> precision </E1:UDBKL> and F-score are similarly identical with <E2:UDBKL> accuracy </E2:UDBKL> ."
"named","61","68","When the TRUE prevalence s for the two positive variables are equal as assumed in Fleiss kappa and F-score , that is the number of positive predictions matches the number of positive classes in the dichotomous ( two class ) case , the different kappa and correlation measure collapse to identity with Youden 's J , and recall , precision and <E1:UDBKL> F-score </E1:UDBKL> are similarly identical with <E2:UDBKL> accuracy </E2:UDBKL> ."
"physical","1","11","The <E1:proteins> Building Educational Applications workshop </E1:proteins> ( BEA ) at <E2:UDBKL> NAACL </E2:UDBKL> 2013 hosted the inaugural NLI shared task. Tetreault et al , 2013 The competition resulted in 29 entries from teams across the globe , 24 of which also published a paper describing their systems and approaches ."
"named","8","1","The <E2:proteins> Building Educational Applications workshop </E2:proteins> ( <E1:proteins> BEA </E1:proteins> ) at NAACL 2013 hosted the inaugural NLI shared task. Tetreault et al , 2013 The competition resulted in 29 entries from teams across the globe , 24 of which also published a paper describing their systems and approaches ."
"part-of","16","1","The <E2:proteins> Building Educational Applications workshop </E2:proteins> ( BEA ) at NAACL 2013 hosted the inaugural <E1:UDBKL> NLI shared task. </E1:UDBKL> Tetreault et al , 2013 The competition resulted in 29 entries from teams across the globe , 24 of which also published a paper describing their systems and approaches ."
"related-to","1","7","The <E1:proteins> Viterbi algorithm </E1:proteins> is a <E2:proteins> dynamic programming algorithm </E2:proteins> for finding the most likely sequence of hidden states called the Viterbi path that results in a sequence of observed events , especially in the context of Markov information source s and hidden Markov model s ( HMM ) ."
"related-to","1","17","The <E1:proteins> Viterbi algorithm </E1:proteins> is a dynamic programming algorithm for finding the most likely sequence of <E2:proteins> hidden states </E2:proteins> called the Viterbi path that results in a sequence of observed events , especially in the context of Markov information source s and hidden Markov model s ( HMM ) ."
"part-of","21","15","The Viterbi algorithm is a dynamic programming algorithm for finding the most likely sequence of <E2:proteins> hidden states </E2:proteins> called the <E1:proteins> Viterbi path </E1:proteins> that results in a sequence of observed events , especially in the context of Markov information source s and hidden Markov model s ( HMM ) ."
"named","47","40","The Viterbi algorithm is a dynamic programming algorithm for finding the most likely sequence of hidden states called the Viterbi path that results in a sequence of observed events , especially in the context of Markov information source s and <E2:proteins> hidden Markov model </E2:proteins> s ( <E1:proteins> HMM </E1:proteins> ) ."
"named","5","1","In <E2:UDBKL> statistics </E2:UDBKL> , <E1:proteins> multinomial logistic regression </E1:proteins> is a classification method that generalizes logistic regression to multiclass classification , i.e. with more than two possible discrete outcomes ."
"related-to","3","10","In statistics , <E1:proteins> multinomial logistic regression </E1:proteins> is a <E2:proteins> classification method </E2:proteins> that generalizes logistic regression to multiclass classification , i.e. with more than two possible discrete outcomes ."
"related-to","3","14","In statistics , <E1:proteins> multinomial logistic regression </E1:proteins> is a classification method that generalizes <E2:proteins> logistic regression </E2:proteins> to multiclass classification , i.e. with more than two possible discrete outcomes ."
"named","3","17","In statistics , <E1:proteins> multinomial logistic regression </E1:proteins> is a classification method that generalizes logistic regression to <E2:UDBKL> multiclass classification </E2:UDBKL> , i.e. with more than two possible discrete outcomes ."
"related-to","0","11","<E1:proteins> Hidden Markov models </E1:proteins> are known for their applications to <E2:UDBKL> reinforcement learning </E2:UDBKL> and temporal pattern recognition such as speech , handwriting recognition , gesture recognition , Thad Starner , Alex Pentland ."
"related-to","0","14","<E1:proteins> Hidden Markov models </E1:proteins> are known for their applications to reinforcement learning and <E2:UDBKL> temporal pattern recognition </E2:UDBKL> such as speech , handwriting recognition , gesture recognition , Thad Starner , Alex Pentland ."
"related-to","19","0","<E2:proteins> Hidden Markov models </E2:proteins> are known for their applications to reinforcement learning and temporal pattern recognition such as <E1:UDBKL> speech </E1:UDBKL> , handwriting recognition , gesture recognition , Thad Starner , Alex Pentland ."
"related-to","21","0","<E2:proteins> Hidden Markov models </E2:proteins> are known for their applications to reinforcement learning and temporal pattern recognition such as speech , <E1:UDBKL> handwriting recognition </E1:UDBKL> , gesture recognition , Thad Starner , Alex Pentland ."
"related-to","24","0","<E2:proteins> Hidden Markov models </E2:proteins> are known for their applications to reinforcement learning and temporal pattern recognition such as speech , handwriting recognition , <E1:UDBKL> gesture recognition </E1:UDBKL> , Thad Starner , Alex Pentland ."
"named","7","38","Essentially , this means that if the <E1:proteins> n-gram </E1:proteins> has been seen more than k times in training , the conditional probability of a word given its history is proportional to the maximum likelihood estimate of that <E2:proteins> n -gram </E2:proteins> ."
"part-of","31","38","Essentially , this means that if the n-gram has been seen more than k times in training , the conditional probability of a word given its history is proportional to the <E1:UDBKL> maximum likelihood estimate </E1:UDBKL> of that <E2:proteins> n -gram </E2:proteins> ."
"part-of","29","17","He is interested in knowledge representation , commonsense reasoning , and natural language understanding , believing that <E2:UDBKL> deep language understanding </E2:UDBKL> can only currently be achieved by significant <E1:proteins> hand-engineering </E1:proteins> of semantically-rich formalisms coupled with statistical preferences ."
"temporal","1","9","The <E1:proteins> Newcomb Awards </E1:proteins> are announced in the <E2:proteins> AI Magazine </E2:proteins> published by AAAI ."
"role","7","13","The Newcomb Awards are announced in the <E1:proteins> AI Magazine </E1:proteins> published by <E2:UDBKL> AAAI </E2:UDBKL> ."
"related-to","10","1","The <E2:UDBKL> F-score </E2:UDBKL> has been widely used in the <E1:UDBKL> natural language processing </E1:UDBKL> literature , such as the evaluation of named entity recognition ( NER ) and word segmentation ."
"named","20","8","The F-score has been widely used in the <E2:UDBKL> natural language processing </E2:UDBKL> literature , such as the evaluation of <E1:UDBKL> named entity recognition </E1:UDBKL> ( NER ) and word segmentation ."
"named","24","18","The F-score has been widely used in the natural language processing literature , such as the evaluation of <E2:UDBKL> named entity recognition </E2:UDBKL> ( <E1:UDBKL> NER </E1:UDBKL> ) and word segmentation ."
"named","27","8","The F-score has been widely used in the <E2:UDBKL> natural language processing </E2:UDBKL> literature , such as the evaluation of named entity recognition ( NER ) and <E1:UDBKL> word segmentation </E1:UDBKL> ."
"related-to","0","16","<E1:proteins> Chatbots </E1:proteins> are typically used in dialog systems for various purposes including customer service , <E2:proteins> request routing </E2:proteins> , or for information gathering ."
"related-to","0","21","<E1:proteins> Chatbots </E1:proteins> are typically used in dialog systems for various purposes including customer service , request routing , or for <E2:proteins> information gathering </E2:proteins> ."
"part-of","7","0","<E2:proteins> Chatbots </E2:proteins> are typically used in <E1:proteins> dialog systems </E1:proteins> for various purposes including customer service , request routing , or for information gathering ."
"named","16","4","Important journals include the <E2:UDBKL> IEEE Transactions on Speech and Audio Processing </E2:UDBKL> ( later renamed <E1:UDBKL> IEEE Transactions on Audio , Speech and Language Processing </E1:UDBKL> and since Sept 2014 renamed IEEE / ACM Transactions on Audio , Speech and Language Processing - after merging with an ACM publication ) , Computer Speech and Language , and Speech Communication ."
"named","30","4","Important journals include the <E2:UDBKL> IEEE Transactions on Speech and Audio Processing </E2:UDBKL> ( later renamed IEEE Transactions on Audio , Speech and Language Processing and since Sept 2014 renamed <E1:UDBKL> IEEE / ACM Transactions on Audio , Speech and Language Processing </E1:UDBKL> - after merging with an ACM publication ) , Computer Speech and Language , and Speech Communication ."
"named","46","28","Important journals include the IEEE Transactions on Speech and Audio Processing ( later renamed IEEE Transactions on Audio , Speech and Language Processing and since Sept 2014 renamed <E2:UDBKL> IEEE / ACM Transactions on Audio , Speech and Language Processing </E2:UDBKL> - after merging with an <E1:UDBKL> ACM </E1:UDBKL> publication ) , Computer Speech and Language , and Speech Communication ."
"related-to","7","0","<E2:proteins> EM </E2:proteins> is frequently used for <E1:UDBKL> data clustering </E1:UDBKL> in machine learning and computer vision ."
"part-of","5","10","EM is frequently used for <E1:UDBKL> data clustering </E1:UDBKL> in <E2:UDBKL> machine learning </E2:UDBKL> and computer vision ."
"part-of","5","13","EM is frequently used for <E1:UDBKL> data clustering </E1:UDBKL> in machine learning and <E2:UDBKL> computer vision </E2:UDBKL> ."
"related-to","9","26","While there is no perfect way of describing the <E1:UDBKL> confusion matrix </E1:UDBKL> of TRUE and FALSE positives and negatives by a single number , the <E2:UDBKL> Matthews correlation coefficient </E2:UDBKL> is generally regarded as being one of the best such measures ."
"physical","40","30","As data set s have grown in size and complexity , direct hands-on data analysis has been augmented with indirect , automated data processing , aided by other discoveries in <E2:UDBKL> computer science </E2:UDBKL> , specially in the field of <E1:UDBKL> machine learning </E1:UDBKL> , such as neural networks , cluster analysis , genetic algorithms ( 1950s ) , decision tree learning and decision rules ( 1960s ) , and support vector machines ( 1990s ) ."
"part-of","45","38","As data set s have grown in size and complexity , direct hands-on data analysis has been augmented with indirect , automated data processing , aided by other discoveries in computer science , specially in the field of <E2:UDBKL> machine learning </E2:UDBKL> , such as <E1:proteins> neural networks </E1:proteins> , cluster analysis , genetic algorithms ( 1950s ) , decision tree learning and decision rules ( 1960s ) , and support vector machines ( 1990s ) ."
"part-of","48","38","As data set s have grown in size and complexity , direct hands-on data analysis has been augmented with indirect , automated data processing , aided by other discoveries in computer science , specially in the field of <E2:UDBKL> machine learning </E2:UDBKL> , such as neural networks , <E1:UDBKL> cluster analysis </E1:UDBKL> , genetic algorithms ( 1950s ) , decision tree learning and decision rules ( 1960s ) , and support vector machines ( 1990s ) ."
"part-of","51","38","As data set s have grown in size and complexity , direct hands-on data analysis has been augmented with indirect , automated data processing , aided by other discoveries in computer science , specially in the field of <E2:UDBKL> machine learning </E2:UDBKL> , such as neural networks , cluster analysis , <E1:proteins> genetic algorithms </E1:proteins> ( 1950s ) , decision tree learning and decision rules ( 1960s ) , and support vector machines ( 1990s ) ."
"part-of","57","38","As data set s have grown in size and complexity , direct hands-on data analysis has been augmented with indirect , automated data processing , aided by other discoveries in computer science , specially in the field of <E2:UDBKL> machine learning </E2:UDBKL> , such as neural networks , cluster analysis , genetic algorithms ( 1950s ) , <E1:proteins> decision tree learning </E1:proteins> and decision rules ( 1960s ) , and support vector machines ( 1990s ) ."
"part-of","61","38","As data set s have grown in size and complexity , direct hands-on data analysis has been augmented with indirect , automated data processing , aided by other discoveries in computer science , specially in the field of <E2:UDBKL> machine learning </E2:UDBKL> , such as neural networks , cluster analysis , genetic algorithms ( 1950s ) , decision tree learning and <E1:proteins> decision rules </E1:proteins> ( 1960s ) , and support vector machines ( 1990s ) ."
"part-of","68","38","As data set s have grown in size and complexity , direct hands-on data analysis has been augmented with indirect , automated data processing , aided by other discoveries in computer science , specially in the field of <E2:UDBKL> machine learning </E2:UDBKL> , such as neural networks , cluster analysis , genetic algorithms ( 1950s ) , decision tree learning and decision rules ( 1960s ) , and <E1:proteins> support vector machines </E1:proteins> ( 1990s ) ."
"artifact","13","6","In the fall of 2005 , <E2:author> Thrun </E2:author> published a textbook entitled <E1:proteins> Probabilistic Robotics </E1:proteins> together with his long-term co-workers Dieter Fox and Wolfram Burgard ."
"artifact","11","20","In the fall of 2005 , Thrun published a textbook entitled <E1:proteins> Probabilistic Robotics </E1:proteins> together with his long-term co-workers <E2:author> Dieter Fox </E2:author> and Wolfram Burgard ."
"artifact","11","23","In the fall of 2005 , Thrun published a textbook entitled <E1:proteins> Probabilistic Robotics </E1:proteins> together with his long-term co-workers Dieter Fox and <E2:author> Wolfram Burgard </E2:author> ."
"related-to","0","16","<E1:UDBKL> Question answering </E1:UDBKL> ( QA ) is a computer science discipline within the fields of <E2:UDBKL> information retrieval </E2:UDBKL> and natural language processing ( NLP ) , which is concerned with building systems that automatically answer questions posed by humans in a natural language ."
"related-to","0","19","<E1:UDBKL> Question answering </E1:UDBKL> ( QA ) is a computer science discipline within the fields of information retrieval and <E2:UDBKL> natural language processing </E2:UDBKL> ( NLP ) , which is concerned with building systems that automatically answer questions posed by humans in a natural language ."
"named","5","0","<E2:UDBKL> Question answering </E2:UDBKL> ( <E1:UDBKL> QA </E1:UDBKL> ) is a computer science discipline within the fields of information retrieval and natural language processing ( NLP ) , which is concerned with building systems that automatically answer questions posed by humans in a natural language ."
"named","16","7","Question answering ( QA ) is a <E2:UDBKL> computer science </E2:UDBKL> discipline within the fields of <E1:UDBKL> information retrieval </E1:UDBKL> and natural language processing ( NLP ) , which is concerned with building systems that automatically answer questions posed by humans in a natural language ."
"named","19","7","Question answering ( QA ) is a <E2:UDBKL> computer science </E2:UDBKL> discipline within the fields of information retrieval and <E1:UDBKL> natural language processing </E1:UDBKL> ( NLP ) , which is concerned with building systems that automatically answer questions posed by humans in a natural language ."
"named","23","17","Question answering ( QA ) is a computer science discipline within the fields of information retrieval and <E2:UDBKL> natural language processing </E2:UDBKL> ( <E1:UDBKL> NLP </E1:UDBKL> ) , which is concerned with building systems that automatically answer questions posed by humans in a natural language ."
"role","6","20","On August 27 , 2018 , <E1:UDBKL> Toyota </E1:UDBKL> announced an investment of $ 500 Million in Uber ' s <E2:proteins> autonomous car </E2:proteins> s ."
"physical","20","15","On August 27 , 2018 , Toyota announced an investment of $ 500 Million in <E2:UDBKL> Uber </E2:UDBKL> ' s <E1:proteins> autonomous car </E1:proteins> s ."
"related-to","0","5","<E1:UDBKL> LSI </E1:UDBKL> helps overcome <E2:proteins> synonymy </E2:proteins> by increasing recall , one of the most problematic constraints of Boolean keyword queries and vector space models ."
"related-to","0","8","<E1:UDBKL> LSI </E1:UDBKL> helps overcome synonymy by increasing <E2:UDBKL> recall </E2:UDBKL> , one of the most problematic constraints of Boolean keyword queries and vector space models ."
"related-to","3","17","LSI helps overcome <E1:proteins> synonymy </E1:proteins> by increasing recall , one of the most problematic constraints of <E2:proteins> Boolean keyword queries </E2:proteins> and vector space models ."
"related-to","3","21","LSI helps overcome <E1:proteins> synonymy </E1:proteins> by increasing recall , one of the most problematic constraints of Boolean keyword queries and <E2:proteins> vector space models </E2:proteins> ."
"related-to","0","20","<E1:UDBKL> Data acquisition </E1:UDBKL> applications are usually controlled by software programs developed using various general purpose programming languages such as <E2:proteins> Assembly </E2:proteins> , BASIC , C , C + + , C # , Fortran , Java , LabVIEW , Lisp , Pascal , etc ."
"related-to","0","22","<E1:UDBKL> Data acquisition </E1:UDBKL> applications are usually controlled by software programs developed using various general purpose programming languages such as Assembly , <E2:proteins> BASIC </E2:proteins> , C , C + + , C # , Fortran , Java , LabVIEW , Lisp , Pascal , etc ."
"related-to","0","24","<E1:UDBKL> Data acquisition </E1:UDBKL> applications are usually controlled by software programs developed using various general purpose programming languages such as Assembly , BASIC , <E2:proteins> C </E2:proteins> , C + + , C # , Fortran , Java , LabVIEW , Lisp , Pascal , etc ."
"related-to","0","26","<E1:UDBKL> Data acquisition </E1:UDBKL> applications are usually controlled by software programs developed using various general purpose programming languages such as Assembly , BASIC , C , <E2:proteins> C + + </E2:proteins> , C # , Fortran , Java , LabVIEW , Lisp , Pascal , etc ."
"related-to","0","30","<E1:UDBKL> Data acquisition </E1:UDBKL> applications are usually controlled by software programs developed using various general purpose programming languages such as Assembly , BASIC , C , C + + , <E2:proteins> C # </E2:proteins> , Fortran , Java , LabVIEW , Lisp , Pascal , etc ."
"related-to","0","33","<E1:UDBKL> Data acquisition </E1:UDBKL> applications are usually controlled by software programs developed using various general purpose programming languages such as Assembly , BASIC , C , C + + , C # , <E2:proteins> Fortran </E2:proteins> , Java , LabVIEW , Lisp , Pascal , etc ."
"related-to","0","35","<E1:UDBKL> Data acquisition </E1:UDBKL> applications are usually controlled by software programs developed using various general purpose programming languages such as Assembly , BASIC , C , C + + , C # , Fortran , <E2:proteins> Java </E2:proteins> , LabVIEW , Lisp , Pascal , etc ."
"related-to","0","37","<E1:UDBKL> Data acquisition </E1:UDBKL> applications are usually controlled by software programs developed using various general purpose programming languages such as Assembly , BASIC , C , C + + , C # , Fortran , Java , <E2:proteins> LabVIEW </E2:proteins> , Lisp , Pascal , etc ."
"related-to","0","39","<E1:UDBKL> Data acquisition </E1:UDBKL> applications are usually controlled by software programs developed using various general purpose programming languages such as Assembly , BASIC , C , C + + , C # , Fortran , Java , LabVIEW , <E2:proteins> Lisp </E2:proteins> , Pascal , etc ."
"related-to","0","41","<E1:UDBKL> Data acquisition </E1:UDBKL> applications are usually controlled by software programs developed using various general purpose programming languages such as Assembly , BASIC , C , C + + , C # , Fortran , Java , LabVIEW , Lisp , <E2:proteins> Pascal </E2:proteins> , etc ."
"artifact","8","3","In 2003 , <E2:UDBKL> Honda </E2:UDBKL> released its <E1:proteins> Cog </E1:proteins> advertisement in the UK and on the Internet ."
"physical","6","12","In 2003 , Honda released its <E1:proteins> Cog </E1:proteins> advertisement in the <E2:UDBKL> UK </E2:UDBKL> and on the Internet ."
"role","1","8","The <E1:UDBKL> Association for Computational Linguistics </E1:UDBKL> defines <E2:UDBKL> computational linguistics </E2:UDBKL> as :"
"related-to","0","11","<E1:proteins> Expectation-maximization algorithm </E1:proteins> s may be employed to calculate approximate <E2:proteins> maximum likelihood estimates </E2:proteins> of unknown state-space parameters within minimum-variance filters and smoothers ."
"role","7","3","Correspondents included former <E2:proteins> Baywatch </E2:proteins> actresses <E1:UDBKL> Donna D 'Errico </E1:UDBKL> , Carmen Electra , and Traci Bingham , former Playboy Playmate Heidi Mark , comedian Arj Barker and identical twins Randy and Jason Sklar ."
"role","11","3","Correspondents included former <E2:proteins> Baywatch </E2:proteins> actresses Donna D 'Errico , <E1:UDBKL> Carmen Electra </E1:UDBKL> , and Traci Bingham , former Playboy Playmate Heidi Mark , comedian Arj Barker and identical twins Randy and Jason Sklar ."
"role","15","3","Correspondents included former <E2:proteins> Baywatch </E2:proteins> actresses Donna D 'Errico , Carmen Electra , and <E1:UDBKL> Traci Bingham </E1:UDBKL> , former Playboy Playmate Heidi Mark , comedian Arj Barker and identical twins Randy and Jason Sklar ."
"general-affiliation","21","17","Correspondents included former Baywatch actresses Donna D 'Errico , Carmen Electra , and Traci Bingham , former <E2:proteins> Playboy Playmate </E2:proteins> <E1:UDBKL> Heidi Mark </E1:UDBKL> , comedian Arj Barker and identical twins Randy and Jason Sklar ."
"role","28","32","Correspondents included former Baywatch actresses Donna D 'Errico , Carmen Electra , and Traci Bingham , former Playboy Playmate Heidi Mark , comedian Arj Barker and identical twins <E1:UDBKL> Randy </E1:UDBKL> and <E2:UDBKL> Jason Sklar </E2:UDBKL> ."
"named","13","8","It is commonly used to generate representations for <E2:UDBKL> speech recognition </E2:UDBKL> ( <E1:UDBKL> ASR </E1:UDBKL> ) , e.g. the CMU Sphinx system , and speech synthesis ( TTS ) , e.g. the Festival system ."
"part-of","18","8","It is commonly used to generate representations for <E2:UDBKL> speech recognition </E2:UDBKL> ( ASR ) , e.g. the <E1:proteins> CMU Sphinx system </E1:proteins> , and speech synthesis ( TTS ) , e.g. the Festival system ."
"named","26","21","It is commonly used to generate representations for speech recognition ( ASR ) , e.g. the CMU Sphinx system , and <E2:UDBKL> speech synthesis </E2:UDBKL> ( <E1:UDBKL> TTS </E1:UDBKL> ) , e.g. the Festival system ."
"named","31","21","It is commonly used to generate representations for speech recognition ( ASR ) , e.g. the CMU Sphinx system , and <E2:UDBKL> speech synthesis </E2:UDBKL> ( TTS ) , e.g. the <E1:proteins> Festival system </E1:proteins> ."
"named","4","0","<E2:UDBKL> Sensitivity </E2:UDBKL> or <E1:UDBKL> TRUE Positive Rate </E1:UDBKL> ( TPR ) , also known as recall , is the proportion of people that tested positive and are positive ( TRUE Positive , TP ) of all the people that actually are positive ( Condition Positive , CP = TP + FN ) ."
"named","8","2","Sensitivity or <E2:UDBKL> TRUE Positive Rate </E2:UDBKL> ( <E1:UDBKL> TPR </E1:UDBKL> ) , also known as recall , is the proportion of people that tested positive and are positive ( TRUE Positive , TP ) of all the people that actually are positive ( Condition Positive , CP = TP + FN ) ."
"named","14","0","<E2:UDBKL> Sensitivity </E2:UDBKL> or TRUE Positive Rate ( TPR ) , also known as <E1:UDBKL> recall </E1:UDBKL> , is the proportion of people that tested positive and are positive ( TRUE Positive , TP ) of all the people that actually are positive ( Condition Positive , CP = TP + FN ) ."
"named","31","26","Sensitivity or TRUE Positive Rate ( TPR ) , also known as recall , is the proportion of people that tested positive and are positive ( <E2:UDBKL> TRUE Positive </E2:UDBKL> , <E1:UDBKL> TP </E1:UDBKL> ) of all the people that actually are positive ( Condition Positive , CP = TP + FN ) ."
"named","45","40","Sensitivity or TRUE Positive Rate ( TPR ) , also known as recall , is the proportion of people that tested positive and are positive ( TRUE Positive , TP ) of all the people that actually are positive ( <E2:UDBKL> Condition Positive </E2:UDBKL> , <E1:UDBKL> CP </E1:UDBKL> = TP + FN ) ."
"named","47","40","Sensitivity or TRUE Positive Rate ( TPR ) , also known as recall , is the proportion of people that tested positive and are positive ( TRUE Positive , TP ) of all the people that actually are positive ( <E2:UDBKL> Condition Positive </E2:UDBKL> , CP = <E1:UDBKL> TP + FN </E1:UDBKL> ) ."
"named","12","1","Popular <E2:UDBKL> speech recognition </E2:UDBKL> conferences held each year or two include <E1:UDBKL> SpeechTEK </E1:UDBKL> and SpeechTEK Europe , ICASSP , Interspeech / Eurospeech , and the IEEE ASRU ."
"named","14","1","Popular <E2:UDBKL> speech recognition </E2:UDBKL> conferences held each year or two include SpeechTEK and <E1:UDBKL> SpeechTEK Europe </E1:UDBKL> , ICASSP , Interspeech / Eurospeech , and the IEEE ASRU ."
"part-of","17","1","Popular <E2:UDBKL> speech recognition </E2:UDBKL> conferences held each year or two include SpeechTEK and SpeechTEK Europe , <E1:UDBKL> ICASSP </E1:UDBKL> , Interspeech / Eurospeech , and the IEEE ASRU ."
"named","19","1","Popular <E2:UDBKL> speech recognition </E2:UDBKL> conferences held each year or two include SpeechTEK and SpeechTEK Europe , ICASSP , <E1:UDBKL> Interspeech </E1:UDBKL> / Eurospeech , and the IEEE ASRU ."
"named","21","1","Popular <E2:UDBKL> speech recognition </E2:UDBKL> conferences held each year or two include SpeechTEK and SpeechTEK Europe , ICASSP , Interspeech / <E1:UDBKL> Eurospeech </E1:UDBKL> , and the IEEE ASRU ."
"part-of","25","1","Popular <E2:UDBKL> speech recognition </E2:UDBKL> conferences held each year or two include SpeechTEK and SpeechTEK Europe , ICASSP , Interspeech / Eurospeech , and the <E1:UDBKL> IEEE ASRU </E1:UDBKL> ."
"artifact","26","0","<E2:author> Devol </E2:author> collaborated with Engelberger , who served as president of the company , to engineer and produce an industrial robot under the brand name <E1:proteins> Unimate </E1:proteins> ."
"artifact","26","3","Devol collaborated with <E2:author> Engelberger </E2:author> , who served as president of the company , to engineer and produce an industrial robot under the brand name <E1:proteins> Unimate </E1:proteins> ."
"part-of","26","18","Devol collaborated with Engelberger , who served as president of the company , to engineer and produce an <E2:proteins> industrial robot </E2:proteins> under the brand name <E1:proteins> Unimate </E1:proteins> ."
"related-to","1","11","A <E1:proteins> Hidden Markov model </E1:proteins> ( HMM ) is a <E2:proteins> statistical Markov model </E2:proteins> in which the system being modeled is assumed to be a Markov process with unobserved ( hidden ) states ."
"named","7","1","A <E2:proteins> Hidden Markov model </E2:proteins> ( <E1:proteins> HMM </E1:proteins> ) is a statistical Markov model in which the system being modeled is assumed to be a Markov process with unobserved ( hidden ) states ."
"part-of","22","32","Such a sequence ( which depends on the outcome of the investigation of previous attributes at each stage ) is called a <E1:proteins> decision tree </E1:proteins> and applied in the area of <E2:UDBKL> machine learning </E2:UDBKL> known as decision tree learning ."
"related-to","22","36","Such a sequence ( which depends on the outcome of the investigation of previous attributes at each stage ) is called a <E1:proteins> decision tree </E1:proteins> and applied in the area of machine learning known as <E2:proteins> decision tree learning </E2:proteins> ."
"related-to","2","8","As in <E1:UDBKL> factor analysis </E1:UDBKL> , the <E2:proteins> LCA </E2:proteins> can also be used to classify case according to their maximum likelihood class membership ."
"part-of","19","6","As in factor analysis , the <E2:proteins> LCA </E2:proteins> can also be used to classify case according to their <E1:proteins> maximum likelihood </E1:proteins> class membership ."
"related-to","0","8","<E1:proteins> Supervised neural networks </E1:proteins> that use a <E2:UDBKL> mean squared error </E2:UDBKL> ( MSE ) cost function can use formal statistical methods to determine the confidence of the trained model ."
"related-to","6","14","Supervised neural networks that use a <E1:UDBKL> mean squared error </E1:UDBKL> ( MSE ) <E2:proteins> cost function </E2:proteins> can use formal statistical methods to determine the confidence of the trained model ."
"named","12","6","Supervised neural networks that use a <E2:UDBKL> mean squared error </E2:UDBKL> ( <E1:UDBKL> MSE </E1:UDBKL> ) cost function can use formal statistical methods to determine the confidence of the trained model ."
"role","16","22","This can be directly expressed as a linear program , but it is also equivalent to <E1:proteins> Tikhonov regularization </E1:proteins> with the <E2:UDBKL> hinge loss function </E2:UDBKL> , mathV ( f ( x ) , y ) = \ max ( 0 , 1 - yf ( x ) ) / math :"
"role","0","17","<E1:UDBKL> John Ireland </E1:UDBKL> , Joanne Dru and Macdonald Carey starred in the Jack Broder color production <E2:proteins> Hannah Lee </E2:proteins> , which premiered June 19 , 1953 ."
"role","3","17","John Ireland , <E1:UDBKL> Joanne Dru </E1:UDBKL> and Macdonald Carey starred in the Jack Broder color production <E2:proteins> Hannah Lee </E2:proteins> , which premiered June 19 , 1953 ."
"role","6","17","John Ireland , Joanne Dru and <E1:UDBKL> Macdonald Carey </E1:UDBKL> starred in the Jack Broder color production <E2:proteins> Hannah Lee </E2:proteins> , which premiered June 19 , 1953 ."
"origin","17","11","John Ireland , Joanne Dru and Macdonald Carey starred in the <E2:UDBKL> Jack Broder </E2:UDBKL> color production <E1:proteins> Hannah Lee </E1:proteins> , which premiered June 19 , 1953 ."
"related-to","4","14","That process is called <E1:UDBKL> image registration </E1:UDBKL> , and uses different methods of <E2:UDBKL> computer vision </E2:UDBKL> , mostly related to tracking ."
"related-to","20","12","That process is called image registration , and uses different methods of <E2:UDBKL> computer vision </E2:UDBKL> , mostly related to <E1:UDBKL> tracking </E1:UDBKL> ."
"related-to","1","4","The <E1:proteins> VOICEBOX </E1:proteins> <E2:proteins> speech processing toolbox </E2:proteins> for MATLAB implements the conversion and its inverse as :"
"part-of","0","10","<E1:proteins> Prolog </E1:proteins> is a logic programming language associated with <E2:UDBKL> artificial intelligence </E2:UDBKL> and computational linguistics ."
"role","0","13","<E1:proteins> Prolog </E1:proteins> is a logic programming language associated with artificial intelligence and <E2:UDBKL> computational linguistics </E2:UDBKL> ."
"role","0","11","<E1:author> Milner </E1:author> has received numerous awards for her contributions to <E2:UDBKL> neuroscience </E2:UDBKL> and psychology including memberships in the Royal Society of London , the Royal Society of Canada and the National Academy of Sciences ."
"role","0","13","<E1:author> Milner </E1:author> has received numerous awards for her contributions to neuroscience and <E2:UDBKL> psychology </E2:UDBKL> including memberships in the Royal Society of London , the Royal Society of Canada and the National Academy of Sciences ."
"role","0","18","<E1:author> Milner </E1:author> has received numerous awards for her contributions to neuroscience and psychology including memberships in the <E2:UDBKL> Royal Society of London </E2:UDBKL> , the Royal Society of Canada and the National Academy of Sciences ."
"role","0","24","<E1:author> Milner </E1:author> has received numerous awards for her contributions to neuroscience and psychology including memberships in the Royal Society of London , the <E2:UDBKL> Royal Society of Canada </E2:UDBKL> and the National Academy of Sciences ."
"role","0","30","<E1:author> Milner </E1:author> has received numerous awards for her contributions to neuroscience and psychology including memberships in the Royal Society of London , the Royal Society of Canada and the <E2:UDBKL> National Academy of Sciences </E2:UDBKL> ."
"part-of","18","10","By combining these operators one can obtain algorithms for many <E2:UDBKL> image processing </E2:UDBKL> tasks , such as <E1:UDBKL> feature extraction </E1:UDBKL> , image segmentation , image sharpening , image filtering , and classification ."
"part-of","21","10","By combining these operators one can obtain algorithms for many <E2:UDBKL> image processing </E2:UDBKL> tasks , such as feature extraction , <E1:UDBKL> image segmentation </E1:UDBKL> , image sharpening , image filtering , and classification ."
"part-of","24","10","By combining these operators one can obtain algorithms for many <E2:UDBKL> image processing </E2:UDBKL> tasks , such as feature extraction , image segmentation , <E1:UDBKL> image sharpening </E1:UDBKL> , image filtering , and classification ."
"part-of","27","10","By combining these operators one can obtain algorithms for many <E2:UDBKL> image processing </E2:UDBKL> tasks , such as feature extraction , image segmentation , image sharpening , <E1:UDBKL> image filtering </E1:UDBKL> , and classification ."
"part-of","31","10","By combining these operators one can obtain algorithms for many <E2:UDBKL> image processing </E2:UDBKL> tasks , such as feature extraction , image segmentation , image sharpening , image filtering , and <E1:UDBKL> classification </E1:UDBKL> ."
"role","27","21","As of 2017 , he is a professor at the Collège de France and , since 1989 , the director of <E2:UDBKL> INSERM Unit 562 </E2:UDBKL> , <E1:UDBKL> Cognitive Neuroimaging </E1:UDBKL> ."
"origin","22","26","There are many approaches to learning these embeddings , notably using Bayesian clustering frameworks or energy-based frameworks , and more recently , <E1:proteins> TransE </E1:proteins> ( <E2:UDBKL> Conference on Neural Information Processing Systems 2013 </E2:UDBKL> ) ."
"named","12","6","It is an alternative to the <E2:UDBKL> Word error rate </E2:UDBKL> ( <E1:UDBKL> Word Error Rate </E1:UDBKL> ) used in several countries ."
"related-to","13","0","<E2:proteins> ANNs </E2:proteins> have been used on a variety of tasks , including <E1:UDBKL> computer vision </E1:UDBKL> , speech recognition , machine translation , social network filtering , playing board and video games , medical diagnosis , and even in activities that have traditionally been considered as reserved to humans , like painting ."
"related-to","16","0","<E2:proteins> ANNs </E2:proteins> have been used on a variety of tasks , including computer vision , <E1:UDBKL> speech recognition </E1:UDBKL> , machine translation , social network filtering , playing board and video games , medical diagnosis , and even in activities that have traditionally been considered as reserved to humans , like painting ."
"related-to","19","0","<E2:proteins> ANNs </E2:proteins> have been used on a variety of tasks , including computer vision , speech recognition , <E1:UDBKL> machine translation </E1:UDBKL> , social network filtering , playing board and video games , medical diagnosis , and even in activities that have traditionally been considered as reserved to humans , like painting ."
"related-to","22","0","<E2:proteins> ANNs </E2:proteins> have been used on a variety of tasks , including computer vision , speech recognition , machine translation , <E1:UDBKL> social network filtering </E1:UDBKL> , playing board and video games , medical diagnosis , and even in activities that have traditionally been considered as reserved to humans , like painting ."
"related-to","26","0","<E2:proteins> ANNs </E2:proteins> have been used on a variety of tasks , including computer vision , speech recognition , machine translation , social network filtering , <E1:UDBKL> playing board and video games </E1:UDBKL> , medical diagnosis , and even in activities that have traditionally been considered as reserved to humans , like painting ."
"related-to","32","0","<E2:proteins> ANNs </E2:proteins> have been used on a variety of tasks , including computer vision , speech recognition , machine translation , social network filtering , playing board and video games , <E1:UDBKL> medical diagnosis </E1:UDBKL> , and even in activities that have traditionally been considered as reserved to humans , like painting ."
"related-to","50","0","<E2:proteins> ANNs </E2:proteins> have been used on a variety of tasks , including computer vision , speech recognition , machine translation , social network filtering , playing board and video games , medical diagnosis , and even in activities that have traditionally been considered as reserved to humans , like <E1:UDBKL> painting </E1:UDBKL> ."
"part-of","0","26","<E1:proteins> Modular Audio Recognition Framework </E1:proteins> ( MARF ) is an open-source research platform and a collection of voice , sound , speech , text and <E2:UDBKL> natural language processing </E2:UDBKL> ( NLP ) algorithm s written in Java and arranged into a modular and extensible framework that attempts to facilitate addition of new algorithm s ."
"related-to","0","36","<E1:proteins> Modular Audio Recognition Framework </E1:proteins> ( MARF ) is an open-source research platform and a collection of voice , sound , speech , text and natural language processing ( NLP ) algorithm s written in <E2:proteins> Java </E2:proteins> and arranged into a modular and extensible framework that attempts to facilitate addition of new algorithm s ."
"named","7","0","<E2:proteins> Modular Audio Recognition Framework </E2:proteins> ( <E1:proteins> MARF </E1:proteins> ) is an open-source research platform and a collection of voice , sound , speech , text and natural language processing ( NLP ) algorithm s written in Java and arranged into a modular and extensible framework that attempts to facilitate addition of new algorithm s ."
"named","30","24","Modular Audio Recognition Framework ( MARF ) is an open-source research platform and a collection of voice , sound , speech , text and <E2:UDBKL> natural language processing </E2:UDBKL> ( <E1:UDBKL> NLP </E1:UDBKL> ) algorithm s written in Java and arranged into a modular and extensible framework that attempts to facilitate addition of new algorithm s ."
"role","26","19","In 2018 , a report by the civil liberties and rights campaigning organisation Big Brother Watch revealed that two <E2:UDBKL> United Kingdom </E2:UDBKL> police forces , <E1:UDBKL> South Wales Police </E1:UDBKL> and the Metropolitan Police , were using live facial recognition at public events and in public spaces , in September 2019 , South Wales Police use of facial recognition was ruled lawful ."
"named","24","37","In 2018 , a report by the civil liberties and rights campaigning organisation Big Brother Watch revealed that two United Kingdom police forces , <E1:UDBKL> South Wales Police </E1:UDBKL> and the Metropolitan Police , were using live <E2:UDBKL> facial recognition </E2:UDBKL> at public events and in public spaces , in September 2019 , South Wales Police use of facial recognition was ruled lawful ."
"named","24","51","In 2018 , a report by the civil liberties and rights campaigning organisation Big Brother Watch revealed that two United Kingdom police forces , <E1:UDBKL> South Wales Police </E1:UDBKL> and the Metropolitan Police , were using live facial recognition at public events and in public spaces , in September 2019 , <E2:UDBKL> South Wales Police </E2:UDBKL> use of facial recognition was ruled lawful ."
"role","31","19","In 2018 , a report by the civil liberties and rights campaigning organisation Big Brother Watch revealed that two <E2:UDBKL> United Kingdom </E2:UDBKL> police forces , South Wales Police and the <E1:UDBKL> Metropolitan Police </E1:UDBKL> , were using live facial recognition at public events and in public spaces , in September 2019 , South Wales Police use of facial recognition was ruled lawful ."
"named","29","37","In 2018 , a report by the civil liberties and rights campaigning organisation Big Brother Watch revealed that two United Kingdom police forces , South Wales Police and the <E1:UDBKL> Metropolitan Police </E1:UDBKL> , were using live <E2:UDBKL> facial recognition </E2:UDBKL> at public events and in public spaces , in September 2019 , South Wales Police use of facial recognition was ruled lawful ."
"named","49","56","In 2018 , a report by the civil liberties and rights campaigning organisation Big Brother Watch revealed that two United Kingdom police forces , South Wales Police and the Metropolitan Police , were using live facial recognition at public events and in public spaces , in September 2019 , <E1:UDBKL> South Wales Police </E1:UDBKL> use of <E2:UDBKL> facial recognition </E2:UDBKL> was ruled lawful ."
"related-to","0","7","<E1:proteins> ANIMAL </E1:proteins> has been ported to <E2:proteins> R </E2:proteins> , a freely available language and environment for statistical computing and graphics ."
"part-of","0","16","<E1:proteins> ANIMAL </E1:proteins> has been ported to R , a freely available language and environment for <E2:UDBKL> statistical computing </E2:UDBKL> and graphics ."
"role","0","19","<E1:proteins> ANIMAL </E1:proteins> has been ported to R , a freely available language and environment for statistical computing and <E2:UDBKL> graphics </E2:UDBKL> ."
"related-to","0","13","<E1:proteins> Time-inhomogeneous hidden Bernoulli model </E1:proteins> ( TI-HBM ) is an alternative to <E2:proteins> hidden Markov model </E2:proteins> ( HMM ) for automatic speech recognition ."
"named","7","0","<E2:proteins> Time-inhomogeneous hidden Bernoulli model </E2:proteins> ( <E1:proteins> TI-HBM </E1:proteins> ) is an alternative to hidden Markov model ( HMM ) for automatic speech recognition ."
"named","17","11","Time-inhomogeneous hidden Bernoulli model ( TI-HBM ) is an alternative to <E2:proteins> hidden Markov model </E2:proteins> ( <E1:proteins> HMM </E1:proteins> ) for automatic speech recognition ."
"named","20","0","<E2:proteins> Time-inhomogeneous hidden Bernoulli model </E2:proteins> ( TI-HBM ) is an alternative to hidden Markov model ( HMM ) for <E1:UDBKL> automatic speech recognition </E1:UDBKL> ."
"named","20","11","Time-inhomogeneous hidden Bernoulli model ( TI-HBM ) is an alternative to <E2:proteins> hidden Markov model </E2:proteins> ( HMM ) for <E1:UDBKL> automatic speech recognition </E1:UDBKL> ."
"role","4","9","In July 2016 , <E1:UDBKL> Nvidia </E1:UDBKL> demonstrated during <E2:UDBKL> SIGGRAPH </E2:UDBKL> a new method of foveated rendering claimed to be invisible to users ."
"artifact","3","10","Both rely on <E1:proteins> speech act theory </E1:proteins> developed by <E2:author> John Searle </E2:author> in the 1960s and enhanced by Terry Winograd and Flores in the 1970s ."
"artifact","3","18","Both rely on <E1:proteins> speech act theory </E1:proteins> developed by John Searle in the 1960s and enhanced by <E2:author> Terry Winograd </E2:author> and Flores in the 1970s ."
"artifact","3","21","Both rely on <E1:proteins> speech act theory </E1:proteins> developed by John Searle in the 1960s and enhanced by Terry Winograd and <E2:author> Flores </E2:author> in the 1970s ."
"artifact","0","23","<E1:proteins> Neural network models </E1:proteins> of concept formation and the structure of knowledge have opened powerful hierarchical models of knowledge organization such as <E2:author> George Miller </E2:author> ' s Wordnet ."
"artifact","27","21","Neural network models of concept formation and the structure of knowledge have opened powerful hierarchical models of knowledge organization such as <E2:author> George Miller </E2:author> ' s <E1:proteins> Wordnet </E1:proteins> ."
"named","0","14","<E1:proteins> Template matching </E1:proteins> has various applications and is used in such fields as <E2:UDBKL> face recognition </E2:UDBKL> ( see facial recognition system ) and medical image processing ."
"related-to","0","23","<E1:proteins> Template matching </E1:proteins> has various applications and is used in such fields as face recognition ( see facial recognition system ) and <E2:UDBKL> medical image processing </E2:UDBKL> ."
"named","18","12","Template matching has various applications and is used in such fields as <E2:UDBKL> face recognition </E2:UDBKL> ( see <E1:proteins> facial recognition system </E1:proteins> ) and medical image processing ."
"role","9","20","However , usage only became widespread in 2005 when <E1:author> Navneet Dalal </E1:author> and Bill Triggs , researchers for the <E2:UDBKL> French National Institute for Research in Computer Science and Automation </E2:UDBKL> ( INRIA ) , presented their supplementary work on HOG descriptors at the Conference on Computer Vision and Pattern Recognition ( CVPR ) ."
"role","9","43","However , usage only became widespread in 2005 when <E1:author> Navneet Dalal </E1:author> and Bill Triggs , researchers for the French National Institute for Research in Computer Science and Automation ( INRIA ) , presented their supplementary work on HOG descriptors at the <E2:UDBKL> Conference on Computer Vision and Pattern Recognition </E2:UDBKL> ( CVPR ) ."
"role","9","51","However , usage only became widespread in 2005 when <E1:author> Navneet Dalal </E1:author> and Bill Triggs , researchers for the French National Institute for Research in Computer Science and Automation ( INRIA ) , presented their supplementary work on HOG descriptors at the Conference on Computer Vision and Pattern Recognition ( <E2:UDBKL> CVPR </E2:UDBKL> ) ."
"role","12","20","However , usage only became widespread in 2005 when Navneet Dalal and <E1:author> Bill Triggs </E1:author> , researchers for the <E2:UDBKL> French National Institute for Research in Computer Science and Automation </E2:UDBKL> ( INRIA ) , presented their supplementary work on HOG descriptors at the Conference on Computer Vision and Pattern Recognition ( CVPR ) ."
"role","12","43","However , usage only became widespread in 2005 when Navneet Dalal and <E1:author> Bill Triggs </E1:author> , researchers for the French National Institute for Research in Computer Science and Automation ( INRIA ) , presented their supplementary work on HOG descriptors at the <E2:UDBKL> Conference on Computer Vision and Pattern Recognition </E2:UDBKL> ( CVPR ) ."
"named","31","18","However , usage only became widespread in 2005 when Navneet Dalal and Bill Triggs , researchers for the <E2:UDBKL> French National Institute for Research in Computer Science and Automation </E2:UDBKL> ( <E1:UDBKL> INRIA </E1:UDBKL> ) , presented their supplementary work on HOG descriptors at the Conference on Computer Vision and Pattern Recognition ( CVPR ) ."
"part-of","43","37","However , usage only became widespread in 2005 when Navneet Dalal and Bill Triggs , researchers for the French National Institute for Research in Computer Science and Automation ( INRIA ) , presented their supplementary work on <E2:proteins> HOG descriptors </E2:proteins> at the <E1:UDBKL> Conference on Computer Vision and Pattern Recognition </E1:UDBKL> ( CVPR ) ."
"named","51","41","However , usage only became widespread in 2005 when Navneet Dalal and Bill Triggs , researchers for the French National Institute for Research in Computer Science and Automation ( INRIA ) , presented their supplementary work on HOG descriptors at the <E2:UDBKL> Conference on Computer Vision and Pattern Recognition </E2:UDBKL> ( <E1:UDBKL> CVPR </E1:UDBKL> ) ."
"role","22","32","Prior to joining the Penn faculty in 2002 , he spent a decade ( 1991-2001 ) in AT & T Labs and <E1:UDBKL> Bell Labs </E1:UDBKL> , including as head of the <E2:UDBKL> AI </E2:UDBKL> department with colleagues including Michael L. Littman , David A. McAllester , and Richard S. Sutton ; Secure Systems Research department ; and Machine Learning department with members such as Michael Collins and the leader ) ."
"physical","37","22","Prior to joining the Penn faculty in 2002 , he spent a decade ( 1991-2001 ) in AT & T Labs and <E2:UDBKL> Bell Labs </E2:UDBKL> , including as head of the AI department with colleagues including <E1:author> Michael L. Littman </E1:author> , David A. McAllester , and Richard S. Sutton ; Secure Systems Research department ; and Machine Learning department with members such as Michael Collins and the leader ) ."
"physical","41","22","Prior to joining the Penn faculty in 2002 , he spent a decade ( 1991-2001 ) in AT & T Labs and <E2:UDBKL> Bell Labs </E2:UDBKL> , including as head of the AI department with colleagues including Michael L. Littman , <E1:author> David A. McAllester </E1:author> , and Richard S. Sutton ; Secure Systems Research department ; and Machine Learning department with members such as Michael Collins and the leader ) ."
"physical","46","22","Prior to joining the Penn faculty in 2002 , he spent a decade ( 1991-2001 ) in AT & T Labs and <E2:UDBKL> Bell Labs </E2:UDBKL> , including as head of the AI department with colleagues including Michael L. Littman , David A. McAllester , and <E1:author> Richard S. Sutton </E1:author> ; Secure Systems Research department ; and Machine Learning department with members such as Michael Collins and the leader ) ."
"role","63","54","Prior to joining the Penn faculty in 2002 , he spent a decade ( 1991-2001 ) in AT & T Labs and Bell Labs , including as head of the AI department with colleagues including Michael L. Littman , David A. McAllester , and Richard S. Sutton ; Secure Systems Research department ; and <E2:UDBKL> Machine Learning department </E2:UDBKL> with members such as <E1:author> Michael Collins </E1:author> and the leader ) ."
"role","5","15","When data are unlabelled , <E1:UDBKL> supervised learning </E1:UDBKL> is not possible , and an <E2:UDBKL> unsupervised learning </E2:UDBKL> approach is required which attempts to find natural Cluster analysis to groups , and then map new data to these formed groups ."
"origin","25","13","When data are unlabelled , supervised learning is not possible , and an <E2:UDBKL> unsupervised learning </E2:UDBKL> approach is required which attempts to find natural <E1:UDBKL> Cluster analysis </E1:UDBKL> to groups , and then map new data to these formed groups ."
"physical","3","17","This field of <E1:UDBKL> computer science </E1:UDBKL> developed in the 1950s at academic institutions such as the <E2:UDBKL> MIT A.I. Lab </E2:UDBKL> , originally as a branch of artificial intelligence and robotics ."
"part-of","3","26","This field of <E1:UDBKL> computer science </E1:UDBKL> developed in the 1950s at academic institutions such as the MIT A.I. Lab , originally as a branch of <E2:UDBKL> artificial intelligence </E2:UDBKL> and robotics ."
"role","3","29","This field of <E1:UDBKL> computer science </E1:UDBKL> developed in the 1950s at academic institutions such as the MIT A.I. Lab , originally as a branch of artificial intelligence and <E2:UDBKL> robotics </E2:UDBKL> ."
"role","1","38","The <E1:UDBKL> Shirley Ryan AbilityLab </E1:UDBKL> ( formerly the Rehabilitation Institute of Chicago ) , University of California at Berkeley , MIT , Stanford University , and University of Twente in the Netherlands are the researching leaders in <E2:UDBKL> biomechatronics </E2:UDBKL> ."
"origin","9","1","The <E2:UDBKL> Shirley Ryan AbilityLab </E2:UDBKL> ( formerly the <E1:UDBKL> Rehabilitation Institute of Chicago </E1:UDBKL> ) , University of California at Berkeley , MIT , Stanford University , and University of Twente in the Netherlands are the researching leaders in biomechatronics ."
"part-of","7","38","The Shirley Ryan AbilityLab ( formerly the <E1:UDBKL> Rehabilitation Institute of Chicago </E1:UDBKL> ) , University of California at Berkeley , MIT , Stanford University , and University of Twente in the Netherlands are the researching leaders in <E2:UDBKL> biomechatronics </E2:UDBKL> ."
"part-of","13","38","The Shirley Ryan AbilityLab ( formerly the Rehabilitation Institute of Chicago ) , <E1:UDBKL> University of California at Berkeley </E1:UDBKL> , MIT , Stanford University , and University of Twente in the Netherlands are the researching leaders in <E2:UDBKL> biomechatronics </E2:UDBKL> ."
"part-of","19","38","The Shirley Ryan AbilityLab ( formerly the Rehabilitation Institute of Chicago ) , University of California at Berkeley , <E1:UDBKL> MIT </E1:UDBKL> , Stanford University , and University of Twente in the Netherlands are the researching leaders in <E2:UDBKL> biomechatronics </E2:UDBKL> ."
"part-of","21","38","The Shirley Ryan AbilityLab ( formerly the Rehabilitation Institute of Chicago ) , University of California at Berkeley , MIT , <E1:UDBKL> Stanford University </E1:UDBKL> , and University of Twente in the Netherlands are the researching leaders in <E2:UDBKL> biomechatronics </E2:UDBKL> ."
"physical","25","32","The Shirley Ryan AbilityLab ( formerly the Rehabilitation Institute of Chicago ) , University of California at Berkeley , MIT , Stanford University , and <E1:UDBKL> University of Twente </E1:UDBKL> in the <E2:UDBKL> Netherlands </E2:UDBKL> are the researching leaders in biomechatronics ."
"part-of","25","38","The Shirley Ryan AbilityLab ( formerly the Rehabilitation Institute of Chicago ) , University of California at Berkeley , MIT , Stanford University , and <E1:UDBKL> University of Twente </E1:UDBKL> in the Netherlands are the researching leaders in <E2:UDBKL> biomechatronics </E2:UDBKL> ."
"role","5","17","The first alpha version of <E1:proteins> OpenCV </E1:proteins> was released to the public at the Conference on <E2:UDBKL> Computer Vision and Pattern Recognition </E2:UDBKL> in 2000 , and five betas were released between 2001 and 2005 ."
"related-to","4","20","An early version of <E1:UDBKL> VMAF </E1:UDBKL> has been shown to outperform other image and video quality metrics such as <E2:UDBKL> SSIM </E2:UDBKL> , PSNR -HVS and VQM-VFD on three of four datasets in terms of prediction accuracy , when compared to subjective ratings ."
"related-to","4","22","An early version of <E1:UDBKL> VMAF </E1:UDBKL> has been shown to outperform other image and video quality metrics such as SSIM , <E2:UDBKL> PSNR -HVS </E2:UDBKL> and VQM-VFD on three of four datasets in terms of prediction accuracy , when compared to subjective ratings ."
"related-to","4","25","An early version of <E1:UDBKL> VMAF </E1:UDBKL> has been shown to outperform other image and video quality metrics such as SSIM , PSNR -HVS and <E2:UDBKL> VQM-VFD </E2:UDBKL> on three of four datasets in terms of prediction accuracy , when compared to subjective ratings ."
"related-to","18","27","For example , the ambiguity of ' mouse ' ( animal or device ) is not relevant in <E1:UDBKL> machine translation </E1:UDBKL> , but is relevant in <E2:UDBKL> information retrieval </E2:UDBKL> ."
"part-of","8","0","<E2:proteins> Geometric hashing </E2:proteins> was originally suggested in <E1:UDBKL> computer vision </E1:UDBKL> for object recognition in 2D and 3D ,"
"named","11","6","Geometric hashing was originally suggested in <E2:UDBKL> computer vision </E2:UDBKL> for <E1:UDBKL> object recognition </E1:UDBKL> in 2D and 3D ,"
"part-of","16","9","It forms one of the three main categories of <E2:UDBKL> machine learning </E2:UDBKL> , along with <E1:UDBKL> supervised learning </E1:UDBKL> and reinforcement learning ."
"part-of","19","9","It forms one of the three main categories of <E2:UDBKL> machine learning </E2:UDBKL> , along with supervised learning and <E1:UDBKL> reinforcement learning </E1:UDBKL> ."
"part-of","0","19","<E1:UDBKL> Reinforcement learning </E1:UDBKL> , due to its generality , is studied in many other disciplines , such as <E2:UDBKL> game </E2:UDBKL> , control theory , operations research , information theory , simulation-based optimization , multi-agent systems , swarm intelligence , statistics and genetic algorithm s ."
"related-to","0","21","<E1:UDBKL> Reinforcement learning </E1:UDBKL> , due to its generality , is studied in many other disciplines , such as game , <E2:UDBKL> control theory </E2:UDBKL> , operations research , information theory , simulation-based optimization , multi-agent systems , swarm intelligence , statistics and genetic algorithm s ."
"related-to","0","24","<E1:UDBKL> Reinforcement learning </E1:UDBKL> , due to its generality , is studied in many other disciplines , such as game , control theory , <E2:UDBKL> operations research </E2:UDBKL> , information theory , simulation-based optimization , multi-agent systems , swarm intelligence , statistics and genetic algorithm s ."
"related-to","0","27","<E1:UDBKL> Reinforcement learning </E1:UDBKL> , due to its generality , is studied in many other disciplines , such as game , control theory , operations research , <E2:UDBKL> information theory </E2:UDBKL> , simulation-based optimization , multi-agent systems , swarm intelligence , statistics and genetic algorithm s ."
"role","0","30","<E1:UDBKL> Reinforcement learning </E1:UDBKL> , due to its generality , is studied in many other disciplines , such as game , control theory , operations research , information theory , <E2:UDBKL> simulation-based optimization </E2:UDBKL> , multi-agent systems , swarm intelligence , statistics and genetic algorithm s ."
"related-to","0","33","<E1:UDBKL> Reinforcement learning </E1:UDBKL> , due to its generality , is studied in many other disciplines , such as game , control theory , operations research , information theory , simulation-based optimization , <E2:UDBKL> multi-agent systems </E2:UDBKL> , swarm intelligence , statistics and genetic algorithm s ."
"related-to","0","36","<E1:UDBKL> Reinforcement learning </E1:UDBKL> , due to its generality , is studied in many other disciplines , such as game , control theory , operations research , information theory , simulation-based optimization , multi-agent systems , <E2:UDBKL> swarm intelligence </E2:UDBKL> , statistics and genetic algorithm s ."
"related-to","0","39","<E1:UDBKL> Reinforcement learning </E1:UDBKL> , due to its generality , is studied in many other disciplines , such as game , control theory , operations research , information theory , simulation-based optimization , multi-agent systems , swarm intelligence , <E2:UDBKL> statistics </E2:UDBKL> and genetic algorithm s ."
"related-to","0","41","<E1:UDBKL> Reinforcement learning </E1:UDBKL> , due to its generality , is studied in many other disciplines , such as game , control theory , operations research , information theory , simulation-based optimization , multi-agent systems , swarm intelligence , statistics and <E2:proteins> genetic algorithm </E2:proteins> s ."
"related-to","0","8","<E1:UDBKL> Pattern recognition </E1:UDBKL> is closely related to <E2:UDBKL> artificial intelligence </E2:UDBKL> and machine learning ,"
"related-to","0","11","<E1:UDBKL> Pattern recognition </E1:UDBKL> is closely related to artificial intelligence and <E2:UDBKL> machine learning </E2:UDBKL> ,"
"named","10","15","The software is used to design , train and deploy <E1:proteins> neural network </E1:proteins> ( <E2:UDBKL> supervised learning </E2:UDBKL> and unsupervised learning ) models to perform a wide variety of tasks such as data mining , classification , function approximation , multivariate regression and time-series prediction ."
"part-of","10","18","The software is used to design , train and deploy <E1:proteins> neural network </E1:proteins> ( supervised learning and <E2:UDBKL> unsupervised learning </E2:UDBKL> ) models to perform a wide variety of tasks such as data mining , classification , function approximation , multivariate regression and time-series prediction ."
"part-of","31","10","The software is used to design , train and deploy <E2:proteins> neural network </E2:proteins> ( supervised learning and unsupervised learning ) models to perform a wide variety of tasks such as <E1:UDBKL> data mining </E1:UDBKL> , classification , function approximation , multivariate regression and time-series prediction ."
"part-of","34","10","The software is used to design , train and deploy <E2:proteins> neural network </E2:proteins> ( supervised learning and unsupervised learning ) models to perform a wide variety of tasks such as data mining , <E1:UDBKL> classification </E1:UDBKL> , function approximation , multivariate regression and time-series prediction ."
"part-of","36","10","The software is used to design , train and deploy <E2:proteins> neural network </E2:proteins> ( supervised learning and unsupervised learning ) models to perform a wide variety of tasks such as data mining , classification , <E1:UDBKL> function approximation </E1:UDBKL> , multivariate regression and time-series prediction ."
"part-of","39","10","The software is used to design , train and deploy <E2:proteins> neural network </E2:proteins> ( supervised learning and unsupervised learning ) models to perform a wide variety of tasks such as data mining , classification , function approximation , <E1:proteins> multivariate regression </E1:proteins> and time-series prediction ."
"part-of","42","10","The software is used to design , train and deploy <E2:proteins> neural network </E2:proteins> ( supervised learning and unsupervised learning ) models to perform a wide variety of tasks such as data mining , classification , function approximation , multivariate regression and <E1:UDBKL> time-series prediction </E1:UDBKL> ."
"part-of","10","3","During the 1973 <E2:proteins> Yom Kippur War </E2:proteins> , Soviet-supplied <E1:proteins> surface-to-air missile </E1:proteins> batteries in Egypt and Syria caused heavy damage Israeli fighter jet s ."
"physical","8","14","During the 1973 Yom Kippur War , Soviet-supplied <E1:proteins> surface-to-air missile </E1:proteins> batteries in <E2:UDBKL> Egypt </E2:UDBKL> and Syria caused heavy damage Israeli fighter jet s ."
"physical","8","16","During the 1973 Yom Kippur War , Soviet-supplied <E1:proteins> surface-to-air missile </E1:proteins> batteries in Egypt and <E2:UDBKL> Syria </E2:UDBKL> caused heavy damage Israeli fighter jet s ."
"related-to","8","20","During the 1973 Yom Kippur War , Soviet-supplied <E1:proteins> surface-to-air missile </E1:proteins> batteries in Egypt and Syria caused heavy damage <E2:proteins> Israeli fighter jet </E2:proteins> s ."
"named","17","9","Another resource ( free but copyrighted ) is the <E2:proteins> HTK book </E2:proteins> ( and the accompanying <E1:proteins> HTK toolkit </E1:proteins> ) ."
"temporal","1","12","The <E1:proteins> 1997 RoboCup 2D Soccer Simulation League </E1:proteins> was the first <E2:proteins> RoboCup </E2:proteins> competition promoted in conjunction with International Joint Conference on Artificial Intelligence held in Nagoya , Japan , from 23 to 29 August 1997 ."
"physical","16","26","The 1997 RoboCup 2D Soccer Simulation League was the first RoboCup competition promoted in conjunction with <E1:UDBKL> International Joint Conference on Artificial Intelligence </E1:UDBKL> held in <E2:UDBKL> Nagoya </E2:UDBKL> , Japan , from 23 to 29 August 1997 ."
"physical","24","28","The 1997 RoboCup 2D Soccer Simulation League was the first RoboCup competition promoted in conjunction with International Joint Conference on Artificial Intelligence held in <E1:UDBKL> Nagoya </E1:UDBKL> , <E2:UDBKL> Japan </E2:UDBKL> , from 23 to 29 August 1997 ."
"physical","15","10","From Bonn he has contributed fundamentally to artificial intelligence and <E2:UDBKL> robotics </E2:UDBKL> ( with <E1:author> Wolfram Burgard </E1:author> , Dieter Fox , Sebastian Thrun among his students ) , and to the development of software engineering , particularly in civil engineering , and information systems , particularly in the geosciences. won the AAAI Classic Paper award of 2016.2014 ."
"physical","18","10","From Bonn he has contributed fundamentally to artificial intelligence and <E2:UDBKL> robotics </E2:UDBKL> ( with Wolfram Burgard , <E1:author> Dieter Fox </E1:author> , Sebastian Thrun among his students ) , and to the development of software engineering , particularly in civil engineering , and information systems , particularly in the geosciences. won the AAAI Classic Paper award of 2016.2014 ."
"physical","21","10","From Bonn he has contributed fundamentally to artificial intelligence and <E2:UDBKL> robotics </E2:UDBKL> ( with Wolfram Burgard , Dieter Fox , <E1:author> Sebastian Thrun </E1:author> among his students ) , and to the development of software engineering , particularly in civil engineering , and information systems , particularly in the geosciences. won the AAAI Classic Paper award of 2016.2014 ."
"physical","42","36","From Bonn he has contributed fundamentally to artificial intelligence and robotics ( with Wolfram Burgard , Dieter Fox , Sebastian Thrun among his students ) , and to the development of software engineering , particularly in <E2:UDBKL> civil engineering </E2:UDBKL> , and <E1:UDBKL> information systems </E1:UDBKL> , particularly in the geosciences. won the AAAI Classic Paper award of 2016.2014 ."
"part-of","48","40","From Bonn he has contributed fundamentally to artificial intelligence and robotics ( with Wolfram Burgard , Dieter Fox , Sebastian Thrun among his students ) , and to the development of software engineering , particularly in civil engineering , and <E2:UDBKL> information systems </E2:UDBKL> , particularly in the <E1:UDBKL> geosciences. </E1:UDBKL> won the AAAI Classic Paper award of 2016.2014 ."
"physical","2","19","The first <E1:UDBKL> USA edition of Campus Party </E1:UDBKL> will take place from 20 to 22 of August at <E2:UDBKL> TCF Center </E2:UDBKL> in Detroit , Michigan ."
"physical","17","22","The first USA edition of Campus Party will take place from 20 to 22 of August at <E1:UDBKL> TCF Center </E1:UDBKL> in <E2:UDBKL> Detroit </E2:UDBKL> , Michigan ."
"physical","20","24","The first USA edition of Campus Party will take place from 20 to 22 of August at TCF Center in <E1:UDBKL> Detroit </E1:UDBKL> , <E2:UDBKL> Michigan </E2:UDBKL> ."
"role","2","15","Together with <E1:author> Yann LeCun </E1:author> , and Yoshua Bengio , Hinton won the 2018 <E2:proteins> Turing Award </E2:proteins> for conceptual and engineering breakthroughs that have made deep neural networks a critical component of computing ."
"role","6","15","Together with Yann LeCun , and <E1:author> Yoshua Bengio </E1:author> , Hinton won the 2018 <E2:proteins> Turing Award </E2:proteins> for conceptual and engineering breakthroughs that have made deep neural networks a critical component of computing ."
"role","9","15","Together with Yann LeCun , and Yoshua Bengio , <E1:author> Hinton </E1:author> won the 2018 <E2:proteins> Turing Award </E2:proteins> for conceptual and engineering breakthroughs that have made deep neural networks a critical component of computing ."
"related-to","13","25","Together with Yann LeCun , and Yoshua Bengio , Hinton won the 2018 <E1:proteins> Turing Award </E1:proteins> for conceptual and engineering breakthroughs that have made <E2:proteins> deep neural networks </E2:proteins> a critical component of computing ."
"related-to","0","11","<E1:proteins> Euler Math Toolbox </E1:proteins> uses a matrix language similar to <E2:proteins> MATLAB </E2:proteins> , a system that had been under development since the 1970s ."
"artifact","6","10","In 1969 a famous book entitled <E1:proteins> Perceptrons </E1:proteins> by <E2:author> Marvin Minsky </E2:author> and Seymour Papert showed that it was impossible for these classes of network to learn an XOR function ."
"artifact","6","13","In 1969 a famous book entitled <E1:proteins> Perceptrons </E1:proteins> by Marvin Minsky and <E2:author> Seymour Papert </E2:author> showed that it was impossible for these classes of network to learn an XOR function ."
"related-to","6","28","In 1969 a famous book entitled <E1:proteins> Perceptrons </E1:proteins> by Marvin Minsky and Seymour Papert showed that it was impossible for these classes of network to learn an <E2:proteins> XOR function </E2:proteins> ."
"part-of","19","11","Large numbers of Russian scientific and technical documents were translated using <E2:proteins> SYSTRAN </E2:proteins> under the auspices of the <E1:UDBKL> USAF Foreign Technology Division </E1:UDBKL> ( later the National Air and Space Intelligence Center ) at Wright-Patterson Air Force Base , Ohio ."
"physical","17","34","Large numbers of Russian scientific and technical documents were translated using SYSTRAN under the auspices of the <E1:UDBKL> USAF Foreign Technology Division </E1:UDBKL> ( later the National Air and Space Intelligence Center ) at <E2:UDBKL> Wright-Patterson Air Force Base </E2:UDBKL> , Ohio ."
"named","26","17","Large numbers of Russian scientific and technical documents were translated using SYSTRAN under the auspices of the <E2:UDBKL> USAF Foreign Technology Division </E2:UDBKL> ( later the <E1:UDBKL> National Air and Space Intelligence Center </E1:UDBKL> ) at Wright-Patterson Air Force Base , Ohio ."
"physical","32","39","Large numbers of Russian scientific and technical documents were translated using SYSTRAN under the auspices of the USAF Foreign Technology Division ( later the National Air and Space Intelligence Center ) at <E1:UDBKL> Wright-Patterson Air Force Base </E1:UDBKL> , <E2:UDBKL> Ohio </E2:UDBKL> ."
"related-to","1","10","An <E1:proteins> n -gram model </E1:proteins> is a type of <E2:proteins> probabilistic language model </E2:proteins> for predicting the next item in such a sequence in the form of a ( n − 1 ) -order Markov model .efficiently ."
"related-to","1","7","The <E1:UDBKL> Cleveland Clinic </E1:UDBKL> has used <E2:proteins> Cyc </E2:proteins> to develop a natural language query interface of biomedical information , spanning decades of information on cardiothoracic surgeries ."
"physical","11","1","The <E2:UDBKL> Cleveland Clinic </E2:UDBKL> has used Cyc to develop a <E1:proteins> natural language query interface of biomedical information </E1:proteins> , spanning decades of information on cardiothoracic surgeries ."
"physical","6","11","The incident strained relations between the <E1:UDBKL> United States </E1:UDBKL> and <E2:UDBKL> Japan </E2:UDBKL> , and resulted in the arrest and prosecution two senior executives , as well as the imposition of sanctions on the company by both countries ."
"role","7","14","If the modeling is done by an <E1:proteins> artificial neural network </E1:proteins> or other <E2:UDBKL> machine learning </E2:UDBKL> , the optimization of parameters is called training , while the optimization of model hyperparameters is called tuning and often uses cross-validation .."
"named","23","12","If the modeling is done by an artificial neural network or other <E2:UDBKL> machine learning </E2:UDBKL> , the optimization of parameters is called <E1:proteins> training </E1:proteins> , while the optimization of model hyperparameters is called tuning and often uses cross-validation .."
"named","33","12","If the modeling is done by an artificial neural network or other <E2:UDBKL> machine learning </E2:UDBKL> , the optimization of parameters is called training , while the optimization of model hyperparameters is called <E1:proteins> tuning </E1:proteins> and often uses cross-validation .."
"named","37","12","If the modeling is done by an artificial neural network or other <E2:UDBKL> machine learning </E2:UDBKL> , the optimization of parameters is called training , while the optimization of model hyperparameters is called tuning and often uses <E1:proteins> cross-validation </E1:proteins> .."
"role","21","26","Localized versions of the site available in the United Kingdom , India , and Australia were discontinued following the acquisition of <E1:UDBKL> Rotten Tomatoes </E1:UDBKL> by <E2:UDBKL> Fandango </E2:UDBKL> ."
"related-to","1","15","The <E1:UDBKL> NER </E1:UDBKL> model is one of a number of methods for determining the <E2:UDBKL> accuracy </E2:UDBKL> of live subtitles in television broadcasts and events that are produced using speech recognition ."
"related-to","13","28","The NER model is one of a number of methods for determining the <E1:UDBKL> accuracy </E1:UDBKL> of live subtitles in television broadcasts and events that are produced using <E2:UDBKL> speech recognition </E2:UDBKL> ."
"physical","0","6","<E1:author> Atran </E1:author> has taught at <E2:UDBKL> Cambridge University </E2:UDBKL> , Hebrew University in Jerusalem , the École pratique des hautes études and École Polytechnique in Paris , and John Jay College of Criminal Justice in New York City ."
"physical","0","9","<E1:author> Atran </E1:author> has taught at Cambridge University , <E2:UDBKL> Hebrew University </E2:UDBKL> in Jerusalem , the École pratique des hautes études and École Polytechnique in Paris , and John Jay College of Criminal Justice in New York City ."
"role","0","15","<E1:author> Atran </E1:author> has taught at Cambridge University , Hebrew University in Jerusalem , the <E2:UDBKL> École pratique des hautes études </E2:UDBKL> and École Polytechnique in Paris , and John Jay College of Criminal Justice in New York City ."
"physical","0","21","<E1:author> Atran </E1:author> has taught at Cambridge University , Hebrew University in Jerusalem , the École pratique des hautes études and <E2:UDBKL> École Polytechnique </E2:UDBKL> in Paris , and John Jay College of Criminal Justice in New York City ."
"physical","0","27","<E1:author> Atran </E1:author> has taught at Cambridge University , Hebrew University in Jerusalem , the École pratique des hautes études and École Polytechnique in Paris , and <E2:UDBKL> John Jay College of Criminal Justice </E2:UDBKL> in New York City ."
"physical","7","12","Atran has taught at Cambridge University , <E1:UDBKL> Hebrew University </E1:UDBKL> in <E2:UDBKL> Jerusalem </E2:UDBKL> , the École pratique des hautes études and École Polytechnique in Paris , and John Jay College of Criminal Justice in New York City ."
"physical","13","24","Atran has taught at Cambridge University , Hebrew University in Jerusalem , the <E1:UDBKL> École pratique des hautes études </E1:UDBKL> and École Polytechnique in <E2:UDBKL> Paris </E2:UDBKL> , and John Jay College of Criminal Justice in New York City ."
"physical","19","24","Atran has taught at Cambridge University , Hebrew University in Jerusalem , the École pratique des hautes études and <E1:UDBKL> École Polytechnique </E1:UDBKL> in <E2:UDBKL> Paris </E2:UDBKL> , and John Jay College of Criminal Justice in New York City ."
"physical","25","34","Atran has taught at Cambridge University , Hebrew University in Jerusalem , the École pratique des hautes études and École Polytechnique in Paris , and <E1:UDBKL> John Jay College of Criminal Justice </E1:UDBKL> in <E2:UDBKL> New York City </E2:UDBKL> ."
"named","0","6","<E1:proteins> SHRDLU </E1:proteins> was an early <E2:UDBKL> natural language understanding </E2:UDBKL> computer program , developed by Terry Winograd at MIT in 1968-1970"
"physical","4","17","SHRDLU was an early <E1:UDBKL> natural language understanding </E1:UDBKL> computer program , developed by Terry Winograd at <E2:UDBKL> MIT </E2:UDBKL> in 1968-1970"
"named","3","7","He received a <E1:proteins> B.E. </E1:proteins> in <E2:UDBKL> electronics engineering </E2:UDBKL> from B.M.S. College of Engineering in Bangalore , India in 1982 , when it was affiliated with Bangalore University , an M.S. in electrical and computer engineering in 1984 from Drexel University , and an M.S. in computer science in 1989 , and a Ph.D. in 1990 , respectively , from the University of Wisconsin-Madison , where he studied Artificial Intelligence and worked with Leonard Uhr ."
"physical","3","10","He received a <E1:proteins> B.E. </E1:proteins> in electronics engineering from <E2:UDBKL> B.M.S. College of Engineering </E2:UDBKL> in Bangalore , India in 1982 , when it was affiliated with Bangalore University , an M.S. in electrical and computer engineering in 1984 from Drexel University , and an M.S. in computer science in 1989 , and a Ph.D. in 1990 , respectively , from the University of Wisconsin-Madison , where he studied Artificial Intelligence and worked with Leonard Uhr ."
"physical","8","15","He received a B.E. in electronics engineering from <E1:UDBKL> B.M.S. College of Engineering </E1:UDBKL> in <E2:UDBKL> Bangalore </E2:UDBKL> , India in 1982 , when it was affiliated with Bangalore University , an M.S. in electrical and computer engineering in 1984 from Drexel University , and an M.S. in computer science in 1989 , and a Ph.D. in 1990 , respectively , from the University of Wisconsin-Madison , where he studied Artificial Intelligence and worked with Leonard Uhr ."
"physical","8","26","He received a B.E. in electronics engineering from <E1:UDBKL> B.M.S. College of Engineering </E1:UDBKL> in Bangalore , India in 1982 , when it was affiliated with <E2:UDBKL> Bangalore University </E2:UDBKL> , an M.S. in electrical and computer engineering in 1984 from Drexel University , and an M.S. in computer science in 1989 , and a Ph.D. in 1990 , respectively , from the University of Wisconsin-Madison , where he studied Artificial Intelligence and worked with Leonard Uhr ."
"physical","13","17","He received a B.E. in electronics engineering from B.M.S. College of Engineering in <E1:UDBKL> Bangalore </E1:UDBKL> , <E2:UDBKL> India </E2:UDBKL> in 1982 , when it was affiliated with Bangalore University , an M.S. in electrical and computer engineering in 1984 from Drexel University , and an M.S. in computer science in 1989 , and a Ph.D. in 1990 , respectively , from the University of Wisconsin-Madison , where he studied Artificial Intelligence and worked with Leonard Uhr ."
"physical","28","32","He received a B.E. in electronics engineering from B.M.S. College of Engineering in Bangalore , India in 1982 , when it was affiliated with Bangalore University , an <E1:proteins> M.S. </E1:proteins> in <E2:UDBKL> electrical and computer engineering </E2:UDBKL> in 1984 from Drexel University , and an M.S. in computer science in 1989 , and a Ph.D. in 1990 , respectively , from the University of Wisconsin-Madison , where he studied Artificial Intelligence and worked with Leonard Uhr ."
"physical","28","39","He received a B.E. in electronics engineering from B.M.S. College of Engineering in Bangalore , India in 1982 , when it was affiliated with Bangalore University , an <E1:proteins> M.S. </E1:proteins> in electrical and computer engineering in 1984 from <E2:UDBKL> Drexel University </E2:UDBKL> , and an M.S. in computer science in 1989 , and a Ph.D. in 1990 , respectively , from the University of Wisconsin-Madison , where he studied Artificial Intelligence and worked with Leonard Uhr ."
"physical","42","46","He received a B.E. in electronics engineering from B.M.S. College of Engineering in Bangalore , India in 1982 , when it was affiliated with Bangalore University , an M.S. in electrical and computer engineering in 1984 from Drexel University , and an <E1:proteins> M.S. </E1:proteins> in <E2:UDBKL> computer science </E2:UDBKL> in 1989 , and a Ph.D. in 1990 , respectively , from the University of Wisconsin-Madison , where he studied Artificial Intelligence and worked with Leonard Uhr ."
"physical","51","61","He received a B.E. in electronics engineering from B.M.S. College of Engineering in Bangalore , India in 1982 , when it was affiliated with Bangalore University , an M.S. in electrical and computer engineering in 1984 from Drexel University , and an M.S. in computer science in 1989 , and a <E1:proteins> Ph.D. </E1:proteins> in 1990 , respectively , from the <E2:UDBKL> University of Wisconsin-Madison </E2:UDBKL> , where he studied Artificial Intelligence and worked with Leonard Uhr ."
"temporal","51","68","He received a B.E. in electronics engineering from B.M.S. College of Engineering in Bangalore , India in 1982 , when it was affiliated with Bangalore University , an M.S. in electrical and computer engineering in 1984 from Drexel University , and an M.S. in computer science in 1989 , and a <E1:proteins> Ph.D. </E1:proteins> in 1990 , respectively , from the University of Wisconsin-Madison , where he studied <E2:UDBKL> Artificial Intelligence </E2:UDBKL> and worked with Leonard Uhr ."
"physical","73","59","He received a B.E. in electronics engineering from B.M.S. College of Engineering in Bangalore , India in 1982 , when it was affiliated with Bangalore University , an M.S. in electrical and computer engineering in 1984 from Drexel University , and an M.S. in computer science in 1989 , and a Ph.D. in 1990 , respectively , from the <E2:UDBKL> University of Wisconsin-Madison </E2:UDBKL> , where he studied Artificial Intelligence and worked with <E1:author> Leonard Uhr </E1:author> ."
"named","11","5","Accuracy is usually rated with <E2:UDBKL> word error rate </E2:UDBKL> ( <E1:UDBKL> WER </E1:UDBKL> ) , whereas speed is measured with the real time factor ."
"role","2","9","In 1971 <E1:author> Terry Winograd </E1:author> developed an early <E2:UDBKL> natural language processing </E2:UDBKL> engine capable of interpreting naturally written commands within a simple rule-governed environment ."
"role","1","6","In <E1:UDBKL> artificial intelligence </E1:UDBKL> , <E2:author> Marvin Minsky </E2:author> , Herbert A. Simon , and Allen Newell are prominent ."
"role","1","9","In <E1:UDBKL> artificial intelligence </E1:UDBKL> , Marvin Minsky , <E2:author> Herbert A. Simon </E2:author> , and Allen Newell are prominent ."
"role","1","14","In <E1:UDBKL> artificial intelligence </E1:UDBKL> , Marvin Minsky , Herbert A. Simon , and <E2:author> Allen Newell </E2:author> are prominent ."
"role","32","9","In the latter half of the 20th century , <E2:UDBKL> electrical engineering </E2:UDBKL> itself separated into several disciplines , specialising in the design and analysis of systems that manipulate physical signals ; <E1:UDBKL> electronic engineering </E1:UDBKL> and computer engineering as examples ; while design engineering developed to deal with functional design of user-machine interfaces ."
"role","30","41","In the latter half of the 20th century , electrical engineering itself separated into several disciplines , specialising in the design and analysis of systems that manipulate physical signals ; <E1:UDBKL> electronic engineering </E1:UDBKL> and computer engineering as examples ; while <E2:UDBKL> design engineering </E2:UDBKL> developed to deal with functional design of user-machine interfaces ."
"role","35","9","In the latter half of the 20th century , <E2:UDBKL> electrical engineering </E2:UDBKL> itself separated into several disciplines , specialising in the design and analysis of systems that manipulate physical signals ; electronic engineering and <E1:UDBKL> computer engineering </E1:UDBKL> as examples ; while design engineering developed to deal with functional design of user-machine interfaces ."
"role","33","41","In the latter half of the 20th century , electrical engineering itself separated into several disciplines , specialising in the design and analysis of systems that manipulate physical signals ; electronic engineering and <E1:UDBKL> computer engineering </E1:UDBKL> as examples ; while <E2:UDBKL> design engineering </E2:UDBKL> developed to deal with functional design of user-machine interfaces ."
"general-affiliation","41","9","In the latter half of the 20th century , <E2:UDBKL> electrical engineering </E2:UDBKL> itself separated into several disciplines , specialising in the design and analysis of systems that manipulate physical signals ; electronic engineering and computer engineering as examples ; while <E1:UDBKL> design engineering </E1:UDBKL> developed to deal with functional design of user-machine interfaces ."
"related-to","39","50","In the latter half of the 20th century , electrical engineering itself separated into several disciplines , specialising in the design and analysis of systems that manipulate physical signals ; electronic engineering and computer engineering as examples ; while <E1:UDBKL> design engineering </E1:UDBKL> developed to deal with functional design of <E2:proteins> user-machine interfaces </E2:proteins> ."
"named","12","7","Perhaps the simplest statistic is accuracy or <E2:UDBKL> Fraction Correct </E2:UDBKL> ( <E1:UDBKL> FC </E1:UDBKL> ) , which measures the fraction of all instances that are correctly categorized ; it is the ratio of the number of correct classifications to the total number of correct or incorrect classifications : ( TP + TN ) / Total Population = ( TP + TN ) / ( TP + TN + FP + FN ) ."
"named","46","57","Perhaps the simplest statistic is accuracy or Fraction Correct ( FC ) , which measures the fraction of all instances that are correctly categorized ; it is the ratio of the number of correct classifications to the total number of correct or incorrect classifications : ( <E1:UDBKL> TP + TN </E1:UDBKL> ) / Total Population = ( <E2:UDBKL> TP + TN </E2:UDBKL> ) / ( TP + TN + FP + FN ) ."
"named","55","63","Perhaps the simplest statistic is accuracy or Fraction Correct ( FC ) , which measures the fraction of all instances that are correctly categorized ; it is the ratio of the number of correct classifications to the total number of correct or incorrect classifications : ( TP + TN ) / Total Population = ( <E1:UDBKL> TP + TN </E1:UDBKL> ) / ( <E2:UDBKL> TP + TN + FP + FN </E2:UDBKL> ) ."
"physical","15","31","In the academic community , the major forums for research started in 1995 when the <E1:UDBKL> First International Conference Data Mining and Knowledge Discovery </E1:UDBKL> ( KDD-95 ) was started in <E2:UDBKL> Montreal </E2:UDBKL> under AAAI sponsorship ."
"named","26","15","In the academic community , the major forums for research started in 1995 when the <E2:UDBKL> First International Conference Data Mining and Knowledge Discovery </E2:UDBKL> ( <E1:UDBKL> KDD-95 </E1:UDBKL> ) was started in Montreal under AAAI sponsorship ."
"origin","33","15","In the academic community , the major forums for research started in 1995 when the <E2:UDBKL> First International Conference Data Mining and Knowledge Discovery </E2:UDBKL> ( KDD-95 ) was started in Montreal under <E1:UDBKL> AAAI </E1:UDBKL> sponsorship ."
"related-to","11","18","In light of the above discussion , we see that the <E1:proteins> SVM </E1:proteins> technique is equivalent to <E2:proteins> empirical risk </E2:proteins> with Tikhonov regularization , where in this case the loss function is the hinge loss"
"related-to","16","21","In light of the above discussion , we see that the SVM technique is equivalent to <E1:proteins> empirical risk </E1:proteins> with <E2:proteins> Tikhonov regularization </E2:proteins> , where in this case the loss function is the hinge loss"
"named","19","33","In light of the above discussion , we see that the SVM technique is equivalent to empirical risk with <E1:proteins> Tikhonov regularization </E1:proteins> , where in this case the loss function is the <E2:UDBKL> hinge loss </E2:UDBKL>"
"part-of","33","27","In light of the above discussion , we see that the SVM technique is equivalent to empirical risk with Tikhonov regularization , where in this case the <E2:proteins> loss function </E2:proteins> is the <E1:UDBKL> hinge loss </E1:UDBKL>"
"physical","18","14","The 2015 edition was hosted by Molly McGrath , with Chris Rose and former <E2:UDBKL> UFC </E2:UDBKL> fighter <E1:UDBKL> Kenny Florian </E1:UDBKL> as commentators ."
"artifact","3","9","A subset called <E1:proteins> Micro-Planner </E1:proteins> was implemented by <E2:author> Gerald Jay Sussman </E2:author> , Eugene Charniak and Terry Winograd Sussman , , and Winograd 1971 and was used in Winograd 's natural-language understanding program SHRDLU , Eugene Charniak 's story understanding work , Thorne McCarty 's work on legal reasoning , and some other projects ."
"artifact","3","13","A subset called <E1:proteins> Micro-Planner </E1:proteins> was implemented by Gerald Jay Sussman , <E2:author> Eugene Charniak </E2:author> and Terry Winograd Sussman , , and Winograd 1971 and was used in Winograd 's natural-language understanding program SHRDLU , Eugene Charniak 's story understanding work , Thorne McCarty 's work on legal reasoning , and some other projects ."
"artifact","3","16","A subset called <E1:proteins> Micro-Planner </E1:proteins> was implemented by Gerald Jay Sussman , Eugene Charniak and <E2:author> Terry Winograd </E2:author> Sussman , , and Winograd 1971 and was used in Winograd 's natural-language understanding program SHRDLU , Eugene Charniak 's story understanding work , Thorne McCarty 's work on legal reasoning , and some other projects ."
"artifact","3","18","A subset called <E1:proteins> Micro-Planner </E1:proteins> was implemented by Gerald Jay Sussman , Eugene Charniak and Terry Winograd <E2:author> Sussman </E2:author> , , and Winograd 1971 and was used in Winograd 's natural-language understanding program SHRDLU , Eugene Charniak 's story understanding work , Thorne McCarty 's work on legal reasoning , and some other projects ."
"named","11","35","A subset called Micro-Planner was implemented by Gerald Jay Sussman , <E1:author> Eugene Charniak </E1:author> and Terry Winograd Sussman , , and Winograd 1971 and was used in Winograd 's natural-language understanding program SHRDLU , <E2:author> Eugene Charniak </E2:author> 's story understanding work , Thorne McCarty 's work on legal reasoning , and some other projects ."
"named","14","22","A subset called Micro-Planner was implemented by Gerald Jay Sussman , Eugene Charniak and <E1:author> Terry Winograd </E1:author> Sussman , , and <E2:author> Winograd </E2:author> 1971 and was used in Winograd 's natural-language understanding program SHRDLU , Eugene Charniak 's story understanding work , Thorne McCarty 's work on legal reasoning , and some other projects ."
"named","14","28","A subset called Micro-Planner was implemented by Gerald Jay Sussman , Eugene Charniak and <E1:author> Terry Winograd </E1:author> Sussman , , and Winograd 1971 and was used in <E2:author> Winograd </E2:author> 's natural-language understanding program SHRDLU , Eugene Charniak 's story understanding work , Thorne McCarty 's work on legal reasoning , and some other projects ."
"related-to","28","33","A subset called Micro-Planner was implemented by Gerald Jay Sussman , Eugene Charniak and Terry Winograd Sussman , , and Winograd 1971 and was used in Winograd 's <E1:UDBKL> natural-language understanding </E1:UDBKL> program <E2:proteins> SHRDLU </E2:proteins> , Eugene Charniak 's story understanding work , Thorne McCarty 's work on legal reasoning , and some other projects ."
"artifact","33","26","A subset called Micro-Planner was implemented by Gerald Jay Sussman , Eugene Charniak and Terry Winograd Sussman , , and Winograd 1971 and was used in <E2:author> Winograd </E2:author> 's natural-language understanding program <E1:proteins> SHRDLU </E1:proteins> , Eugene Charniak 's story understanding work , Thorne McCarty 's work on legal reasoning , and some other projects ."
"part-of","12","0","<E2:proteins> WordNet </E2:proteins> has been used for a number of purposes in <E1:proteins> information systems </E1:proteins> , including word-sense disambiguation , information retrieval , automatic text classification , Automatic summarization , machine translation and even automatic crossword puzzle generation ."
"part-of","16","10","WordNet has been used for a number of purposes in <E2:proteins> information systems </E2:proteins> , including <E1:UDBKL> word-sense disambiguation </E1:UDBKL> , information retrieval , automatic text classification , Automatic summarization , machine translation and even automatic crossword puzzle generation ."
"part-of","19","10","WordNet has been used for a number of purposes in <E2:proteins> information systems </E2:proteins> , including word-sense disambiguation , <E1:UDBKL> information retrieval </E1:UDBKL> , automatic text classification , Automatic summarization , machine translation and even automatic crossword puzzle generation ."
"general-affiliation","22","10","WordNet has been used for a number of purposes in <E2:proteins> information systems </E2:proteins> , including word-sense disambiguation , information retrieval , <E1:UDBKL> automatic text classification </E1:UDBKL> , Automatic summarization , machine translation and even automatic crossword puzzle generation ."
"general-affiliation","26","10","WordNet has been used for a number of purposes in <E2:proteins> information systems </E2:proteins> , including word-sense disambiguation , information retrieval , automatic text classification , <E1:UDBKL> Automatic summarization </E1:UDBKL> , machine translation and even automatic crossword puzzle generation ."
"general-affiliation","29","10","WordNet has been used for a number of purposes in <E2:proteins> information systems </E2:proteins> , including word-sense disambiguation , information retrieval , automatic text classification , Automatic summarization , <E1:UDBKL> machine translation </E1:UDBKL> and even automatic crossword puzzle generation ."
"general-affiliation","33","10","WordNet has been used for a number of purposes in <E2:proteins> information systems </E2:proteins> , including word-sense disambiguation , information retrieval , automatic text classification , Automatic summarization , machine translation and even <E1:UDBKL> automatic crossword puzzle generation </E1:UDBKL> ."
"role","0","9","<E1:author> Keutzer </E1:author> was named a Fellow of the <E2:UDBKL> IEEE </E2:UDBKL> in 1996 ."
"part-of","70","57","A widely used type of composition is the nonlinear weighted sum , where math \ textstyle f ( x ) = K \ left ( \ sum _ i w _ i g _ i ( x ) \ right ) / math , where math \ textstyle K / math ( commonly referred to as the <E2:proteins> activation function </E2:proteins> ) is some predefined function , such as the <E1:proteins> hyperbolic tangent </E1:proteins> , sigmoid function , softmax function , or rectifier function ."
"part-of","73","57","A widely used type of composition is the nonlinear weighted sum , where math \ textstyle f ( x ) = K \ left ( \ sum _ i w _ i g _ i ( x ) \ right ) / math , where math \ textstyle K / math ( commonly referred to as the <E2:proteins> activation function </E2:proteins> ) is some predefined function , such as the hyperbolic tangent , <E1:proteins> sigmoid function </E1:proteins> , softmax function , or rectifier function ."
"part-of","76","57","A widely used type of composition is the nonlinear weighted sum , where math \ textstyle f ( x ) = K \ left ( \ sum _ i w _ i g _ i ( x ) \ right ) / math , where math \ textstyle K / math ( commonly referred to as the <E2:proteins> activation function </E2:proteins> ) is some predefined function , such as the hyperbolic tangent , sigmoid function , <E1:proteins> softmax function </E1:proteins> , or rectifier function ."
"part-of","80","57","A widely used type of composition is the nonlinear weighted sum , where math \ textstyle f ( x ) = K \ left ( \ sum _ i w _ i g _ i ( x ) \ right ) / math , where math \ textstyle K / math ( commonly referred to as the <E2:proteins> activation function </E2:proteins> ) is some predefined function , such as the hyperbolic tangent , sigmoid function , softmax function , or <E1:proteins> rectifier function </E1:proteins> ."
"role","6","24","Typically , the process starts by <E1:UDBKL> terminology extraction </E1:UDBKL> and concepts or noun phrase s from plain text using linguistic processors such as <E2:UDBKL> part-of-speech tagging </E2:UDBKL> and phrase chunking ."
"part-of","20","13","They demonstrated its performance on a number of problems of interest to the <E2:UDBKL> machine learning </E2:UDBKL> community , including <E1:UDBKL> handwriting recognition </E1:UDBKL> ."
"physical","7","3","While studying at <E2:UDBKL> Stanford </E2:UDBKL> , <E1:author> Scheinman </E1:author> was awarded a fellowship sponsored by George Devol , the inventor of the Unimate , the first industrial robot ."
"artifact","21","12","While studying at Stanford , Scheinman was awarded a fellowship sponsored by <E2:author> George Devol </E2:author> , the inventor of the <E1:proteins> Unimate </E1:proteins> , the first industrial robot ."
"general-affiliation","19","25","While studying at Stanford , Scheinman was awarded a fellowship sponsored by George Devol , the inventor of the <E1:proteins> Unimate </E1:proteins> , the first <E2:proteins> industrial robot </E2:proteins> ."
"related-to","5","10","While originally used to evaluate <E1:UDBKL> machine translations </E1:UDBKL> , <E2:UDBKL> bilingual evaluation understudy </E2:UDBKL> ( BLEU ) has been used successfully to evaluate paraphrase generation models as well ."
"named","14","8","While originally used to evaluate machine translations , <E2:UDBKL> bilingual evaluation understudy </E2:UDBKL> ( <E1:UDBKL> BLEU </E1:UDBKL> ) has been used successfully to evaluate paraphrase generation models as well ."
"named","22","8","While originally used to evaluate machine translations , <E2:UDBKL> bilingual evaluation understudy </E2:UDBKL> ( BLEU ) has been used successfully to evaluate <E1:proteins> paraphrase generation models </E1:proteins> as well ."
"role","0","8","<E1:UDBKL> Unimation </E1:UDBKL> later licensed their technology to <E2:UDBKL> Kawasaki Heavy Industries </E2:UDBKL> and GKN , manufacturing Unimate s in Japan and England respectively ."
"role","0","12","<E1:UDBKL> Unimation </E1:UDBKL> later licensed their technology to Kawasaki Heavy Industries and <E2:UDBKL> GKN </E2:UDBKL> , manufacturing Unimate s in Japan and England respectively ."
"physical","6","18","Unimation later licensed their technology to <E1:UDBKL> Kawasaki Heavy Industries </E1:UDBKL> and GKN , manufacturing Unimate s in <E2:UDBKL> Japan </E2:UDBKL> and England respectively ."
"physical","10","20","Unimation later licensed their technology to Kawasaki Heavy Industries and <E1:UDBKL> GKN </E1:UDBKL> , manufacturing Unimate s in Japan and <E2:UDBKL> England </E2:UDBKL> respectively ."
"role","15","6","Unimation later licensed their technology to <E2:UDBKL> Kawasaki Heavy Industries </E2:UDBKL> and GKN , manufacturing <E1:proteins> Unimate </E1:proteins> s in Japan and England respectively ."
"role","15","10","Unimation later licensed their technology to Kawasaki Heavy Industries and <E2:UDBKL> GKN </E2:UDBKL> , manufacturing <E1:proteins> Unimate </E1:proteins> s in Japan and England respectively ."
"related-to","37","58","Much of the confusion between these two research communities ( which do often have separate conferences and separate journals , ECML PKDD being a major exception ) comes from the basic assumptions they work with : in <E1:UDBKL> machine learning </E1:UDBKL> , performance is usually evaluated with respect to the ability to reproduce known knowledge , while in <E2:UDBKL> knowledge discovery and data mining </E2:UDBKL> ( KDD ) the key task is the discovery of previously unknown knowledge ."
"named","64","56","Much of the confusion between these two research communities ( which do often have separate conferences and separate journals , ECML PKDD being a major exception ) comes from the basic assumptions they work with : in machine learning , performance is usually evaluated with respect to the ability to reproduce known knowledge , while in <E2:UDBKL> knowledge discovery and data mining </E2:UDBKL> ( <E1:UDBKL> KDD </E1:UDBKL> ) the key task is the discovery of previously unknown knowledge ."
"related-to","0","12","<E1:proteins> Hidden Markov model </E1:proteins> s are the basis for most modern <E2:proteins> automatic speech recognition systems </E2:proteins> ."
"physical","4","8",", a company in <E1:UDBKL> Bangalore </E1:UDBKL> , <E2:UDBKL> India </E2:UDBKL> specializing in online handwriting recognition software ."
"named","47","51","Do repeated translations converge on a single expression in both languages ? I.e. does the translation method show stationarity or produce a canonical form ? Does the translation become stationary without losing the original meaning ? This metric has been criticized as not being well correlated with <E1:UDBKL> BLEU </E1:UDBKL> ( <E2:UDBKL> BiLingual Evaluation Understudy </E2:UDBKL> ) scores ."
"physical","12","23","He holds fellowships in the American Association for Artificial Intelligence , the <E1:UDBKL> Center for Advanced Study in the Behavioral Sciences </E1:UDBKL> at <E2:UDBKL> Stanford University </E2:UDBKL> , the MIT Center for Cognitive Science , the Canadian Institute for Advanced Research , the Canadian Psychological Association , and was elected Fellow of the Royal Society of Canada in 1998 ."
"role","25","30","He holds fellowships in the American Association for Artificial Intelligence , the Center for Advanced Study in the Behavioral Sciences at Stanford University , the <E1:UDBKL> MIT </E1:UDBKL> Center for <E2:UDBKL> Cognitive Science </E2:UDBKL> , the Canadian Institute for Advanced Research , the Canadian Psychological Association , and was elected Fellow of the Royal Society of Canada in 1998 ."
"related-to","0","19","<E1:author> Hinton </E1:author> - together with Yoshua Bengio and Yann LeCun - are referred to by some as the <E2:proteins> Godfathers of AI </E2:proteins> and Godfathers of Deep Learning ."
"related-to","0","23","<E1:author> Hinton </E1:author> - together with Yoshua Bengio and Yann LeCun - are referred to by some as the Godfathers of AI and <E2:proteins> Godfathers of Deep Learning </E2:proteins> ."
"related-to","4","19","Hinton - together with <E1:author> Yoshua Bengio </E1:author> and Yann LeCun - are referred to by some as the <E2:proteins> Godfathers of AI </E2:proteins> and Godfathers of Deep Learning ."
"named","4","23","Hinton - together with <E1:author> Yoshua Bengio </E1:author> and Yann LeCun - are referred to by some as the Godfathers of AI and <E2:proteins> Godfathers of Deep Learning </E2:proteins> ."
"general-affiliation","7","19","Hinton - together with Yoshua Bengio and <E1:author> Yann LeCun </E1:author> - are referred to by some as the <E2:proteins> Godfathers of AI </E2:proteins> and Godfathers of Deep Learning ."
"role","7","23","Hinton - together with Yoshua Bengio and <E1:author> Yann LeCun </E1:author> - are referred to by some as the Godfathers of AI and <E2:proteins> Godfathers of Deep Learning </E2:proteins> ."
"related-to","5","20","The lightweight open-source speech project <E1:proteins> eSpeak </E1:proteins> , which has its own approach to synthesis , has experimented with <E2:proteins> Mandarin </E2:proteins> and Cantonese. eSpeak was used by Google Translate from May 20102010 ."
"related-to","5","22","The lightweight open-source speech project <E1:proteins> eSpeak </E1:proteins> , which has its own approach to synthesis , has experimented with Mandarin and <E2:proteins> Cantonese. </E2:proteins> eSpeak was used by Google Translate from May 20102010 ."
"part-of","18","23","The lightweight open-source speech project eSpeak , which has its own approach to synthesis , has experimented with <E1:proteins> Mandarin </E1:proteins> and Cantonese. <E2:proteins> eSpeak </E2:proteins> was used by Google Translate from May 20102010 ."
"named","27","21","The lightweight open-source speech project eSpeak , which has its own approach to synthesis , has experimented with Mandarin and Cantonese. <E2:proteins> eSpeak </E2:proteins> was used by <E1:proteins> Google Translate </E1:proteins> from May 20102010 ."
"related-to","5","16","Also released in 1982 , <E1:proteins> Software Automatic Mouth </E1:proteins> was the first commercial all-software voice <E2:proteins> synthesis program </E2:proteins> ."
"named","10","4","The column ratios are <E2:UDBKL> TRUE Positive Rate </E2:UDBKL> ( <E1:UDBKL> TPR </E1:UDBKL> , aka Sensitivity or recall ) ( TP / ( TP + FN ) ) , with complement the FALSE Negative Rate ( FNR ) ( FN / ( TP + FN ) ) ; and TRUE Negative Rate ( TNR , aka Specificity , SPC ) ( TN / ( TN + FP ) ) , with complement FALSE Positive Rate ( FPR ) ( FP / ( TN + FP ) ) ."
"named","13","4","The column ratios are <E2:UDBKL> TRUE Positive Rate </E2:UDBKL> ( TPR , aka <E1:UDBKL> Sensitivity </E1:UDBKL> or recall ) ( TP / ( TP + FN ) ) , with complement the FALSE Negative Rate ( FNR ) ( FN / ( TP + FN ) ) ; and TRUE Negative Rate ( TNR , aka Specificity , SPC ) ( TN / ( TN + FP ) ) , with complement FALSE Positive Rate ( FPR ) ( FP / ( TN + FP ) ) ."
"named","15","4","The column ratios are <E2:UDBKL> TRUE Positive Rate </E2:UDBKL> ( TPR , aka Sensitivity or <E1:UDBKL> recall </E1:UDBKL> ) ( TP / ( TP + FN ) ) , with complement the FALSE Negative Rate ( FNR ) ( FN / ( TP + FN ) ) ; and TRUE Negative Rate ( TNR , aka Specificity , SPC ) ( TN / ( TN + FP ) ) , with complement FALSE Positive Rate ( FPR ) ( FP / ( TN + FP ) ) ."
"named","18","4","The column ratios are <E2:UDBKL> TRUE Positive Rate </E2:UDBKL> ( TPR , aka Sensitivity or recall ) ( <E1:UDBKL> TP / ( TP + FN ) </E1:UDBKL> ) , with complement the FALSE Negative Rate ( FNR ) ( FN / ( TP + FN ) ) ; and TRUE Negative Rate ( TNR , aka Specificity , SPC ) ( TN / ( TN + FP ) ) , with complement FALSE Positive Rate ( FPR ) ( FP / ( TN + FP ) ) ."
"named","34","28","The column ratios are TRUE Positive Rate ( TPR , aka Sensitivity or recall ) ( TP / ( TP + FN ) ) , with complement the <E2:UDBKL> FALSE Negative Rate </E2:UDBKL> ( <E1:UDBKL> FNR </E1:UDBKL> ) ( FN / ( TP + FN ) ) ; and TRUE Negative Rate ( TNR , aka Specificity , SPC ) ( TN / ( TN + FP ) ) , with complement FALSE Positive Rate ( FPR ) ( FP / ( TN + FP ) ) ."
"named","37","28","The column ratios are TRUE Positive Rate ( TPR , aka Sensitivity or recall ) ( TP / ( TP + FN ) ) , with complement the <E2:UDBKL> FALSE Negative Rate </E2:UDBKL> ( FNR ) ( <E1:UDBKL> FN / ( TP + FN ) </E1:UDBKL> ) ; and TRUE Negative Rate ( TNR , aka Specificity , SPC ) ( TN / ( TN + FP ) ) , with complement FALSE Positive Rate ( FPR ) ( FP / ( TN + FP ) ) ."
"named","51","45","The column ratios are TRUE Positive Rate ( TPR , aka Sensitivity or recall ) ( TP / ( TP + FN ) ) , with complement the FALSE Negative Rate ( FNR ) ( FN / ( TP + FN ) ) ; and <E2:UDBKL> TRUE Negative Rate </E2:UDBKL> ( <E1:UDBKL> TNR </E1:UDBKL> , aka Specificity , SPC ) ( TN / ( TN + FP ) ) , with complement FALSE Positive Rate ( FPR ) ( FP / ( TN + FP ) ) ."
"named","54","45","The column ratios are TRUE Positive Rate ( TPR , aka Sensitivity or recall ) ( TP / ( TP + FN ) ) , with complement the FALSE Negative Rate ( FNR ) ( FN / ( TP + FN ) ) ; and <E2:UDBKL> TRUE Negative Rate </E2:UDBKL> ( TNR , aka <E1:UDBKL> Specificity </E1:UDBKL> , SPC ) ( TN / ( TN + FP ) ) , with complement FALSE Positive Rate ( FPR ) ( FP / ( TN + FP ) ) ."
"named","56","45","The column ratios are TRUE Positive Rate ( TPR , aka Sensitivity or recall ) ( TP / ( TP + FN ) ) , with complement the FALSE Negative Rate ( FNR ) ( FN / ( TP + FN ) ) ; and <E2:UDBKL> TRUE Negative Rate </E2:UDBKL> ( TNR , aka Specificity , <E1:UDBKL> SPC </E1:UDBKL> ) ( TN / ( TN + FP ) ) , with complement FALSE Positive Rate ( FPR ) ( FP / ( TN + FP ) ) ."
"named","59","45","The column ratios are TRUE Positive Rate ( TPR , aka Sensitivity or recall ) ( TP / ( TP + FN ) ) , with complement the FALSE Negative Rate ( FNR ) ( FN / ( TP + FN ) ) ; and <E2:UDBKL> TRUE Negative Rate </E2:UDBKL> ( TNR , aka Specificity , SPC ) ( <E1:UDBKL> TN / ( TN + FP ) </E1:UDBKL> ) , with complement FALSE Positive Rate ( FPR ) ( FP / ( TN + FP ) ) ."
"named","74","68","The column ratios are TRUE Positive Rate ( TPR , aka Sensitivity or recall ) ( TP / ( TP + FN ) ) , with complement the FALSE Negative Rate ( FNR ) ( FN / ( TP + FN ) ) ; and TRUE Negative Rate ( TNR , aka Specificity , SPC ) ( TN / ( TN + FP ) ) , with complement <E2:UDBKL> FALSE Positive Rate </E2:UDBKL> ( <E1:UDBKL> FPR </E1:UDBKL> ) ( FP / ( TN + FP ) ) ."
"named","77","68","The column ratios are TRUE Positive Rate ( TPR , aka Sensitivity or recall ) ( TP / ( TP + FN ) ) , with complement the FALSE Negative Rate ( FNR ) ( FN / ( TP + FN ) ) ; and TRUE Negative Rate ( TNR , aka Specificity , SPC ) ( TN / ( TN + FP ) ) , with complement <E2:UDBKL> FALSE Positive Rate </E2:UDBKL> ( FPR ) ( <E1:UDBKL> FP / ( TN + FP ) </E1:UDBKL> ) ."
"role","0","19","<E1:UDBKL> Edsinger </E1:UDBKL> and Weber collaborated on many other robots as well , and their experience working with the <E2:proteins> Kismet </E2:proteins>"
"role","2","19","Edsinger and <E1:UDBKL> Weber </E1:UDBKL> collaborated on many other robots as well , and their experience working with the <E2:proteins> Kismet </E2:proteins>"
"related-to","0","12","<E1:proteins> R </E1:proteins> functionality is accessible from several scripting languages such as <E2:proteins> Python </E2:proteins> , are available as well ."
"artifact","14","0","<E2:proteins> VAL </E2:proteins> was one of the first robot languages and was used in <E1:proteins> Unimate robots </E1:proteins> ."
"physical","13","27","They presented their database for the first time as a poster at the <E1:UDBKL> 2009 Conference on Computer Vision and Pattern Recognition </E1:UDBKL> ( CVPR ) in <E2:UDBKL> Florida </E2:UDBKL> ."
"temporal","24","13","They presented their database for the first time as a poster at the <E2:UDBKL> 2009 Conference on Computer Vision and Pattern Recognition </E2:UDBKL> ( <E1:UDBKL> CVPR </E1:UDBKL> ) in Florida ."
"related-to","14","0","<E2:proteins> Categorization tasks </E2:proteins> in which no labels are supplied are referred to as <E1:UDBKL> unsupervised classification </E1:UDBKL> , unsupervised learning , Cluster analysis ."
"named","17","0","<E2:proteins> Categorization tasks </E2:proteins> in which no labels are supplied are referred to as unsupervised classification , <E1:UDBKL> unsupervised learning </E1:UDBKL> , Cluster analysis ."
"related-to","20","0","<E2:proteins> Categorization tasks </E2:proteins> in which no labels are supplied are referred to as unsupervised classification , unsupervised learning , <E1:UDBKL> Cluster analysis </E1:UDBKL> ."
"named","8","15","Also known as parallel robots , or generalized <E1:proteins> Stewart platforms </E1:proteins> ( in the <E2:proteins> Stewart platform </E2:proteins> , the actuators are paired together on both the basis and the platform ) , these systems are articulated robot s that use similar mechanisms for the movement of either the robot on its base , or one or more manipulator arms ."
"related-to","8","35","Also known as parallel robots , or generalized <E1:proteins> Stewart platforms </E1:proteins> ( in the Stewart platform , the actuators are paired together on both the basis and the platform ) , these systems are <E2:proteins> articulated robot </E2:proteins> s that use similar mechanisms for the movement of either the robot on its base , or one or more manipulator arms ."
"role","0","6","<E1:UDBKL> Machine vision </E1:UDBKL> as a <E2:UDBKL> systems engineering </E2:UDBKL> discipline can be considered distinct from computer vision , a form of computer science ."
"named","0","14","<E1:UDBKL> Machine vision </E1:UDBKL> as a systems engineering discipline can be considered distinct from <E2:UDBKL> computer vision </E2:UDBKL> , a form of computer science ."
"part-of","12","20","Machine vision as a systems engineering discipline can be considered distinct from <E1:UDBKL> computer vision </E1:UDBKL> , a form of <E2:UDBKL> computer science </E2:UDBKL> ."
"related-to","5","12","The activation function of the <E1:proteins> LSTM gates </E1:proteins> is often the <E2:proteins> logistic sigmoid function </E2:proteins> ."
"related-to","5","22","In other words , the <E1:UDBKL> sample mean </E1:UDBKL> is the ( necessarily unique ) efficient estimator , and thus also the <E2:UDBKL> minimum variance unbiased estimator </E2:UDBKL> ( MVUE ) , in addition to being the maximum likelihood estimator ."
"related-to","5","35","In other words , the <E1:UDBKL> sample mean </E1:UDBKL> is the ( necessarily unique ) efficient estimator , and thus also the minimum variance unbiased estimator ( MVUE ) , in addition to being the <E2:UDBKL> maximum likelihood estimator </E2:UDBKL> ."
"named","27","20","In other words , the sample mean is the ( necessarily unique ) efficient estimator , and thus also the <E2:UDBKL> minimum variance unbiased estimator </E2:UDBKL> ( <E1:UDBKL> MVUE </E1:UDBKL> ) , in addition to being the maximum likelihood estimator ."
"role","11","0","<E2:proteins> Blade Runner </E2:proteins> used a number of then-lesser-known actors : <E1:UDBKL> Sean Young </E1:UDBKL> portrays Rachael , an experimental replicant implanted with the memories of Tyrell 's niece , causing her to believe she is human ; Sammon , pp. 92-93 Nina Axelrod auditioned for the role ."
"origin","14","9","Blade Runner used a number of then-lesser-known actors : <E2:UDBKL> Sean Young </E2:UDBKL> portrays <E1:UDBKL> Rachael </E1:UDBKL> , an experimental replicant implanted with the memories of Tyrell 's niece , causing her to believe she is human ; Sammon , pp. 92-93 Nina Axelrod auditioned for the role ."
"origin","24","12","Blade Runner used a number of then-lesser-known actors : Sean Young portrays <E2:UDBKL> Rachael </E2:UDBKL> , an experimental replicant implanted with the memories of <E1:UDBKL> Tyrell </E1:UDBKL> 's niece , causing her to believe she is human ; Sammon , pp. 92-93 Nina Axelrod auditioned for the role ."
"origin","40","12","Blade Runner used a number of then-lesser-known actors : Sean Young portrays <E2:UDBKL> Rachael </E2:UDBKL> , an experimental replicant implanted with the memories of Tyrell 's niece , causing her to believe she is human ; Sammon , pp. 92-93 <E1:UDBKL> Nina Axelrod </E1:UDBKL> auditioned for the role ."
"physical","0","15","<E1:author> Gerry Sussman </E1:author> , Eugene Charniak , Seymour Papert and Terry Winograd visited the <E2:UDBKL> University of Edinburgh </E2:UDBKL> in 1971 spreading the news about Micro-Planner and SHRDLU and casting doubt on the resolution uniform proof procedure approach that had been the mainstay of the Edinburgh Logicists ."
"physical","3","15","Gerry Sussman , <E1:author> Eugene Charniak </E1:author> , Seymour Papert and Terry Winograd visited the <E2:UDBKL> University of Edinburgh </E2:UDBKL> in 1971 spreading the news about Micro-Planner and SHRDLU and casting doubt on the resolution uniform proof procedure approach that had been the mainstay of the Edinburgh Logicists ."
"physical","6","15","Gerry Sussman , Eugene Charniak , <E1:author> Seymour Papert </E1:author> and Terry Winograd visited the <E2:UDBKL> University of Edinburgh </E2:UDBKL> in 1971 spreading the news about Micro-Planner and SHRDLU and casting doubt on the resolution uniform proof procedure approach that had been the mainstay of the Edinburgh Logicists ."
"physical","9","15","Gerry Sussman , Eugene Charniak , Seymour Papert and <E1:author> Terry Winograd </E1:author> visited the <E2:UDBKL> University of Edinburgh </E2:UDBKL> in 1971 spreading the news about Micro-Planner and SHRDLU and casting doubt on the resolution uniform proof procedure approach that had been the mainstay of the Edinburgh Logicists ."
"physical","13","44","Gerry Sussman , Eugene Charniak , Seymour Papert and Terry Winograd visited the <E1:UDBKL> University of Edinburgh </E1:UDBKL> in 1971 spreading the news about Micro-Planner and SHRDLU and casting doubt on the resolution uniform proof procedure approach that had been the mainstay of the <E2:UDBKL> Edinburgh </E2:UDBKL> Logicists ."
"physical","24","13","Gerry Sussman , Eugene Charniak , Seymour Papert and Terry Winograd visited the <E2:UDBKL> University of Edinburgh </E2:UDBKL> in 1971 spreading the news about <E1:proteins> Micro-Planner </E1:proteins> and SHRDLU and casting doubt on the resolution uniform proof procedure approach that had been the mainstay of the Edinburgh Logicists ."
"physical","26","13","Gerry Sussman , Eugene Charniak , Seymour Papert and Terry Winograd visited the <E2:UDBKL> University of Edinburgh </E2:UDBKL> in 1971 spreading the news about Micro-Planner and <E1:proteins> SHRDLU </E1:proteins> and casting doubt on the resolution uniform proof procedure approach that had been the mainstay of the Edinburgh Logicists ."
"role","0","13","<E1:author> Walter </E1:author> 's work inspired subsequent generations of robotics researchers such as <E2:author> Rodney Brooks </E2:author> , Hans Moravec and Mark Tilden ."
"role","0","16","<E1:author> Walter </E1:author> 's work inspired subsequent generations of robotics researchers such as Rodney Brooks , <E2:author> Hans Moravec </E2:author> and Mark Tilden ."
"role","0","19","<E1:author> Walter </E1:author> 's work inspired subsequent generations of robotics researchers such as Rodney Brooks , Hans Moravec and <E2:author> Mark Tilden </E2:author> ."
"artifact","5","9","Subsequently , a similar GPU-based <E1:proteins> CNN </E1:proteins> by <E2:author> Alex Krizhevsky </E2:author> et al. won the ImageNet Large Scale Visual Recognition Challenge 2012 ."
"role","5","15","Subsequently , a similar GPU-based <E1:proteins> CNN </E1:proteins> by Alex Krizhevsky et al. won the <E2:UDBKL> ImageNet Large Scale Visual Recognition Challenge 2012 </E2:UDBKL> ."
"part-of","10","2","Commonly used <E2:proteins> loss functions </E2:proteins> for probabilistic classification include <E1:UDBKL> log loss </E1:UDBKL> and the Brier score between the predicted and the TRUE probability distributions ."
"part-of","14","2","Commonly used <E2:proteins> loss functions </E2:proteins> for probabilistic classification include log loss and the <E1:UDBKL> Brier score </E1:UDBKL> between the predicted and the TRUE probability distributions ."
"related-to","12","21","Commonly used loss functions for probabilistic classification include log loss and the <E1:UDBKL> Brier score </E1:UDBKL> between the predicted and the <E2:proteins> TRUE probability </E2:proteins> distributions ."
"related-to","4","14","In May 2016 , <E1:UDBKL> NtechLab </E1:UDBKL> was admitted to the official testing of <E2:UDBKL> biometrics </E2:UDBKL> technology by NIST among the three Russian companies ."
"role","4","21","In May 2016 , <E1:UDBKL> NtechLab </E1:UDBKL> was admitted to the official testing of biometrics technology by NIST among the three <E2:proteins> Russian companies </E2:proteins> ."
"role","17","4","In May 2016 , <E2:UDBKL> NtechLab </E2:UDBKL> was admitted to the official testing of biometrics technology by <E1:UDBKL> NIST </E1:UDBKL> among the three Russian companies ."
"role","5","14","During 2015 , many of <E1:UDBKL> SenseTime </E1:UDBKL> 's papers were accepted into the <E2:UDBKL> Conference on Computer Vision and Pattern Recognition </E2:UDBKL> ( CVPR ) ."
"named","22","12","During 2015 , many of SenseTime 's papers were accepted into the <E2:UDBKL> Conference on Computer Vision and Pattern Recognition </E2:UDBKL> ( <E1:UDBKL> CVPR </E1:UDBKL> ) ."
"part-of","5","23","He co-developed optimal algorithms for <E1:UDBKL> Structure From Motion </E1:UDBKL> ( SFM , or Visual SLAM , simultaneous localization and mapping , in <E2:UDBKL> Robotics </E2:UDBKL> ; Best Paper Award at Conference on Computer Vision and Pattern Recognition 1998 ) , characterized its ambiguities ( David Marr Prize at ICCV 1999 ) , also characterized the identifiability and observability of visual-inertial sensor fusion ( Best Paper Award at Robotics 2015 ) ."
"named","11","5","He co-developed optimal algorithms for <E2:UDBKL> Structure From Motion </E2:UDBKL> ( <E1:UDBKL> SFM </E1:UDBKL> , or Visual SLAM , simultaneous localization and mapping , in Robotics ; Best Paper Award at Conference on Computer Vision and Pattern Recognition 1998 ) , characterized its ambiguities ( David Marr Prize at ICCV 1999 ) , also characterized the identifiability and observability of visual-inertial sensor fusion ( Best Paper Award at Robotics 2015 ) ."
"physical","12","23","He co-developed optimal algorithms for Structure From Motion ( SFM , or <E1:UDBKL> Visual SLAM </E1:UDBKL> , simultaneous localization and mapping , in <E2:UDBKL> Robotics </E2:UDBKL> ; Best Paper Award at Conference on Computer Vision and Pattern Recognition 1998 ) , characterized its ambiguities ( David Marr Prize at ICCV 1999 ) , also characterized the identifiability and observability of visual-inertial sensor fusion ( Best Paper Award at Robotics 2015 ) ."
"named","17","12","He co-developed optimal algorithms for Structure From Motion ( SFM , or <E2:UDBKL> Visual SLAM </E2:UDBKL> , <E1:UDBKL> simultaneous localization and mapping </E1:UDBKL> , in Robotics ; Best Paper Award at Conference on Computer Vision and Pattern Recognition 1998 ) , characterized its ambiguities ( David Marr Prize at ICCV 1999 ) , also characterized the identifiability and observability of visual-inertial sensor fusion ( Best Paper Award at Robotics 2015 ) ."
"win-defeat","23","29","He co-developed optimal algorithms for Structure From Motion ( SFM , or Visual SLAM , simultaneous localization and mapping , in Robotics ; <E1:proteins> Best Paper Award </E1:proteins> at <E2:UDBKL> Conference on Computer Vision and Pattern Recognition </E2:UDBKL> 1998 ) , characterized its ambiguities ( David Marr Prize at ICCV 1999 ) , also characterized the identifiability and observability of visual-inertial sensor fusion ( Best Paper Award at Robotics 2015 ) ."
"origin","41","47","He co-developed optimal algorithms for Structure From Motion ( SFM , or Visual SLAM , simultaneous localization and mapping , in Robotics ; Best Paper Award at Conference on Computer Vision and Pattern Recognition 1998 ) , characterized its ambiguities ( <E1:proteins> David Marr Prize </E1:proteins> at <E2:UDBKL> ICCV 1999 </E2:UDBKL> ) , also characterized the identifiability and observability of visual-inertial sensor fusion ( Best Paper Award at Robotics 2015 ) ."
"origin","60","66","He co-developed optimal algorithms for Structure From Motion ( SFM , or Visual SLAM , simultaneous localization and mapping , in Robotics ; Best Paper Award at Conference on Computer Vision and Pattern Recognition 1998 ) , characterized its ambiguities ( David Marr Prize at ICCV 1999 ) , also characterized the identifiability and observability of visual-inertial sensor fusion ( <E1:proteins> Best Paper Award </E1:proteins> at <E2:UDBKL> Robotics </E2:UDBKL> 2015 ) ."
"part-of","0","9","<E1:UDBKL> Edge detection </E1:UDBKL> is a fundamental tool in <E2:UDBKL> image processing </E2:UDBKL> , machine vision and computer vision , particularly in the areas of feature detection and feature extraction ."
"related-to","0","12","<E1:UDBKL> Edge detection </E1:UDBKL> is a fundamental tool in image processing , <E2:UDBKL> machine vision </E2:UDBKL> and computer vision , particularly in the areas of feature detection and feature extraction ."
"role","0","15","<E1:UDBKL> Edge detection </E1:UDBKL> is a fundamental tool in image processing , machine vision and <E2:UDBKL> computer vision </E2:UDBKL> , particularly in the areas of feature detection and feature extraction ."
"part-of","0","23","<E1:UDBKL> Edge detection </E1:UDBKL> is a fundamental tool in image processing , machine vision and computer vision , particularly in the areas of <E2:UDBKL> feature detection </E2:UDBKL> and feature extraction ."
"related-to","0","26","<E1:UDBKL> Edge detection </E1:UDBKL> is a fundamental tool in image processing , machine vision and computer vision , particularly in the areas of feature detection and <E2:UDBKL> feature extraction </E2:UDBKL> ."
"role","32","24","The returning judges are Fon Davis , Jessica Chobot , and Leland Melvin , as well as celebrity guest judges actor Clark Gregg , <E2:proteins> MythBusters </E2:proteins> host and former Battlebots builder <E1:UDBKL> Adam Savage </E1:UDBKL> , NFL tightend Vernon Davis , and YouTube star Michael Stevens a.k.a. Vsauce ."
"general-affiliation","32","28","The returning judges are Fon Davis , Jessica Chobot , and Leland Melvin , as well as celebrity guest judges actor Clark Gregg , MythBusters host and former <E2:proteins> Battlebots </E2:proteins> builder <E1:UDBKL> Adam Savage </E1:UDBKL> , NFL tightend Vernon Davis , and YouTube star Michael Stevens a.k.a. Vsauce ."
"named","37","33","The returning judges are Fon Davis , Jessica Chobot , and Leland Melvin , as well as celebrity guest judges actor Clark Gregg , MythBusters host and former Battlebots builder Adam Savage , <E2:UDBKL> NFL </E2:UDBKL> tightend <E1:UDBKL> Vernon Davis </E1:UDBKL> , and YouTube star Michael Stevens a.k.a. Vsauce ."
"named","43","39","The returning judges are Fon Davis , Jessica Chobot , and Leland Melvin , as well as celebrity guest judges actor Clark Gregg , MythBusters host and former Battlebots builder Adam Savage , NFL tightend Vernon Davis , and <E2:UDBKL> YouTube </E2:UDBKL> star <E1:UDBKL> Michael Stevens </E1:UDBKL> a.k.a. Vsauce ."
"origin","46","41","The returning judges are Fon Davis , Jessica Chobot , and Leland Melvin , as well as celebrity guest judges actor Clark Gregg , MythBusters host and former Battlebots builder Adam Savage , NFL tightend Vernon Davis , and YouTube star <E2:UDBKL> Michael Stevens </E2:UDBKL> a.k.a. <E1:UDBKL> Vsauce </E1:UDBKL> ."
"named","9","19","But these methods never won over the non-uniform internal-handcrafting <E1:proteins> Gaussian mixture model </E1:proteins> / Hidden Markov model ( <E2:proteins> GMM-HMM </E2:proteins> ) technology based on generative models of speech trained discriminatively ."
"named","13","19","But these methods never won over the non-uniform internal-handcrafting Gaussian mixture model / <E1:proteins> Hidden Markov model </E1:proteins> ( <E2:proteins> GMM-HMM </E2:proteins> ) technology based on generative models of speech trained discriminatively ."
"named","0","10","<E1:proteins> Linear predictive coding </E1:proteins> ( LPC ) , a <E2:UDBKL> speech processing </E2:UDBKL> algorithm , was first proposed by Fumitada Itakura of Nagoya University and Shuzo Saito of Nippon Telegraph and Telephone ( NTT ) in 1966 ."
"artifact","0","18","<E1:proteins> Linear predictive coding </E1:proteins> ( LPC ) , a speech processing algorithm , was first proposed by <E2:author> Fumitada Itakura </E2:author> of Nagoya University and Shuzo Saito of Nippon Telegraph and Telephone ( NTT ) in 1966 ."
"artifact","0","24","<E1:proteins> Linear predictive coding </E1:proteins> ( LPC ) , a speech processing algorithm , was first proposed by Fumitada Itakura of Nagoya University and <E2:author> Shuzo Saito </E2:author> of Nippon Telegraph and Telephone ( NTT ) in 1966 ."
"named","6","0","<E2:proteins> Linear predictive coding </E2:proteins> ( <E1:proteins> LPC </E1:proteins> ) , a speech processing algorithm , was first proposed by Fumitada Itakura of Nagoya University and Shuzo Saito of Nippon Telegraph and Telephone ( NTT ) in 1966 ."
"physical","16","21","Linear predictive coding ( LPC ) , a speech processing algorithm , was first proposed by <E1:author> Fumitada Itakura </E1:author> of <E2:UDBKL> Nagoya University </E2:UDBKL> and Shuzo Saito of Nippon Telegraph and Telephone ( NTT ) in 1966 ."
"physical","22","27","Linear predictive coding ( LPC ) , a speech processing algorithm , was first proposed by Fumitada Itakura of Nagoya University and <E1:author> Shuzo Saito </E1:author> of <E2:UDBKL> Nippon Telegraph and Telephone </E2:UDBKL> ( NTT ) in 1966 ."
"named","32","25","Linear predictive coding ( LPC ) , a speech processing algorithm , was first proposed by Fumitada Itakura of Nagoya University and Shuzo Saito of <E2:UDBKL> Nippon Telegraph and Telephone </E2:UDBKL> ( <E1:UDBKL> NTT </E1:UDBKL> ) in 1966 ."
"named","28","17","In 2006 , for the 25th anniversary of the algorithm , a workshop was organized at the <E2:UDBKL> International Conference on Computer Vision and Pattern Recognition </E2:UDBKL> ( <E1:UDBKL> CVPR </E1:UDBKL> ) to summarize the most recent contributions and variations to the original algorithm , mostly meant to improve the speed of the algorithm , the robustness and accuracy of the estimated solution and to decrease the dependency from user defined constants ."
"related-to","2","19","To extend <E1:proteins> SVM </E1:proteins> to cases in which the data are not linearly separable , we introduce the <E2:proteins> loss function </E2:proteins> ,"
"artifact","0","13","<E1:proteins> Logo </E1:proteins> is an educational programming language , designed in 1967 by <E2:author> Wally Feurzeig </E2:author> , Seymour Papert , and Cynthia Solomon ."
"artifact","0","16","<E1:proteins> Logo </E1:proteins> is an educational programming language , designed in 1967 by Wally Feurzeig , <E2:author> Seymour Papert </E2:author> , and Cynthia Solomon ."
"artifact","0","20","<E1:proteins> Logo </E1:proteins> is an educational programming language , designed in 1967 by Wally Feurzeig , Seymour Papert , and <E2:author> Cynthia Solomon </E2:author> ."
"role","0","9","<E1:UDBKL> Eyring Research Institute </E1:UDBKL> was instrumental to the <E2:UDBKL> U.S. Air Force Missile Directorate </E2:UDBKL> at Hill Air Force Base near Ogden , Utah to produce in top military secrecy , the Intelligent Systems Technology Software that was foundational to the later named Reagan Star Wars program ."
"physical","7","15","Eyring Research Institute was instrumental to the <E1:UDBKL> U.S. Air Force Missile Directorate </E1:UDBKL> at <E2:UDBKL> Hill Air Force Base </E2:UDBKL> near Ogden , Utah to produce in top military secrecy , the Intelligent Systems Technology Software that was foundational to the later named Reagan Star Wars program ."
"physical","13","20","Eyring Research Institute was instrumental to the U.S. Air Force Missile Directorate at <E1:UDBKL> Hill Air Force Base </E1:UDBKL> near <E2:UDBKL> Ogden </E2:UDBKL> , Utah to produce in top military secrecy , the Intelligent Systems Technology Software that was foundational to the later named Reagan Star Wars program ."
"physical","18","22","Eyring Research Institute was instrumental to the U.S. Air Force Missile Directorate at Hill Air Force Base near <E1:UDBKL> Ogden </E1:UDBKL> , <E2:UDBKL> Utah </E2:UDBKL> to produce in top military secrecy , the Intelligent Systems Technology Software that was foundational to the later named Reagan Star Wars program ."
"artifact","31","0","<E2:UDBKL> Eyring Research Institute </E2:UDBKL> was instrumental to the U.S. Air Force Missile Directorate at Hill Air Force Base near Ogden , Utah to produce in top military secrecy , the <E1:proteins> Intelligent Systems Technology Software </E1:proteins> that was foundational to the later named Reagan Star Wars program ."
"part-of","42","29","Eyring Research Institute was instrumental to the U.S. Air Force Missile Directorate at Hill Air Force Base near Ogden , Utah to produce in top military secrecy , the <E2:proteins> Intelligent Systems Technology Software </E2:proteins> that was foundational to the later named <E1:proteins> Reagan Star Wars program </E1:proteins> ."
"named","9","1","The <E2:proteins> Sobel operator </E2:proteins> , sometimes called the <E1:proteins> Sobel-Feldman operator </E1:proteins> or Sobel filter , is used in image processing and computer vision , particularly within edge detection algorithms where it creates an image emphasising edges ."
"named","12","1","The <E2:proteins> Sobel operator </E2:proteins> , sometimes called the Sobel-Feldman operator or <E1:proteins> Sobel filter </E1:proteins> , is used in image processing and computer vision , particularly within edge detection algorithms where it creates an image emphasising edges ."
"part-of","18","1","The <E2:proteins> Sobel operator </E2:proteins> , sometimes called the Sobel-Feldman operator or Sobel filter , is used in <E1:UDBKL> image processing </E1:UDBKL> and computer vision , particularly within edge detection algorithms where it creates an image emphasising edges ."
"part-of","21","1","The <E2:proteins> Sobel operator </E2:proteins> , sometimes called the Sobel-Feldman operator or Sobel filter , is used in image processing and <E1:UDBKL> computer vision </E1:UDBKL> , particularly within edge detection algorithms where it creates an image emphasising edges ."
"part-of","26","1","The <E2:proteins> Sobel operator </E2:proteins> , sometimes called the Sobel-Feldman operator or Sobel filter , is used in image processing and computer vision , particularly within <E1:proteins> edge detection algorithms </E1:proteins> where it creates an image emphasising edges ."
"related-to","0","5","<E1:proteins> LDA </E1:proteins> is a <E2:UDBKL> supervised learning </E2:UDBKL> algorithm that utilizes the labels of the data , while PCA is an learning algorithm that ignores the labels ."
"related-to","0","17","<E1:proteins> LDA </E1:proteins> is a supervised learning algorithm that utilizes the labels of the data , while <E2:proteins> PCA </E2:proteins> is an learning algorithm that ignores the labels ."
"related-to","0","6","<E1:proteins> VTK </E1:proteins> consists of a <E2:proteins> C + + </E2:proteins> class library and several interpreted interface layers including Tcl / Tk , Java , and Python ."
"related-to","0","17","<E1:proteins> VTK </E1:proteins> consists of a C + + class library and several interpreted interface layers including <E2:proteins> Tcl / Tk </E2:proteins> , Java , and Python ."
"related-to","0","21","<E1:proteins> VTK </E1:proteins> consists of a C + + class library and several interpreted interface layers including Tcl / Tk , <E2:proteins> Java </E2:proteins> , and Python ."
"related-to","0","24","<E1:proteins> VTK </E1:proteins> consists of a C + + class library and several interpreted interface layers including Tcl / Tk , Java , and <E2:proteins> Python </E2:proteins> ."
"related-to","0","11","<E1:author> Miller </E1:author> wrote several books and directed the development of <E2:proteins> WordNet </E2:proteins> , an online word-linkage database usable by computer programs ."
"physical","8","15","Contemporary automata are represented by the works of <E1:UDBKL> Cabaret Mechanical Theatre </E1:UDBKL> in the <E2:UDBKL> United Kingdom </E2:UDBKL> , Dug North and Chomick + Meder , Arthur Ganson , Joe Jones in the United States , Le Défenseur du Temps by French artist Jacques Monestier , and François Junod in Switzerland ."
"physical","16","32","Contemporary automata are represented by the works of Cabaret Mechanical Theatre in the United Kingdom , <E1:UDBKL> Dug North </E1:UDBKL> and Chomick + Meder , Arthur Ganson , Joe Jones in the <E2:UDBKL> United States </E2:UDBKL> , Le Défenseur du Temps by French artist Jacques Monestier , and François Junod in Switzerland ."
"physical","19","32","Contemporary automata are represented by the works of Cabaret Mechanical Theatre in the United Kingdom , Dug North and <E1:UDBKL> Chomick + Meder </E1:UDBKL> , Arthur Ganson , Joe Jones in the <E2:UDBKL> United States </E2:UDBKL> , Le Défenseur du Temps by French artist Jacques Monestier , and François Junod in Switzerland ."
"physical","23","32","Contemporary automata are represented by the works of Cabaret Mechanical Theatre in the United Kingdom , Dug North and Chomick + Meder , <E1:UDBKL> Arthur Ganson </E1:UDBKL> , Joe Jones in the <E2:UDBKL> United States </E2:UDBKL> , Le Défenseur du Temps by French artist Jacques Monestier , and François Junod in Switzerland ."
"physical","26","32","Contemporary automata are represented by the works of Cabaret Mechanical Theatre in the United Kingdom , Dug North and Chomick + Meder , Arthur Ganson , <E1:UDBKL> Joe Jones </E1:UDBKL> in the <E2:UDBKL> United States </E2:UDBKL> , Le Défenseur du Temps by French artist Jacques Monestier , and François Junod in Switzerland ."
"physical","35","1","Contemporary <E2:UDBKL> automata </E2:UDBKL> are represented by the works of Cabaret Mechanical Theatre in the United Kingdom , Dug North and Chomick + Meder , Arthur Ganson , Joe Jones in the United States , <E1:UDBKL> Le Défenseur du Temps </E1:UDBKL> by French artist Jacques Monestier , and François Junod in Switzerland ."
"role","33","42","Contemporary automata are represented by the works of Cabaret Mechanical Theatre in the United Kingdom , Dug North and Chomick + Meder , Arthur Ganson , Joe Jones in the United States , <E1:UDBKL> Le Défenseur du Temps </E1:UDBKL> by French artist <E2:UDBKL> Jacques Monestier </E2:UDBKL> , and François Junod in Switzerland ."
"named","38","42","Contemporary automata are represented by the works of Cabaret Mechanical Theatre in the United Kingdom , Dug North and Chomick + Meder , Arthur Ganson , Joe Jones in the United States , Le Défenseur du Temps by <E1:proteins> French artist </E1:proteins> <E2:UDBKL> Jacques Monestier </E2:UDBKL> , and François Junod in Switzerland ."
"physical","44","49","Contemporary automata are represented by the works of Cabaret Mechanical Theatre in the United Kingdom , Dug North and Chomick + Meder , Arthur Ganson , Joe Jones in the United States , Le Défenseur du Temps by French artist Jacques Monestier , and <E1:UDBKL> François Junod </E1:UDBKL> in <E2:UDBKL> Switzerland </E2:UDBKL> ."
"related-to","0","24","<E1:proteins> MATLAB </E1:proteins> does include standard codefor / code and codewhile / code loops , but ( as in other similar applications such as <E2:proteins> R </E2:proteins> ) , using the vectorized notation is encouraged and is often faster to execute ."
"role","0","21","<E1:author> Pausch </E1:author> received two awards from Association for Computing Machinery in 2007 for his achievements in computing education : the <E2:proteins> Karl V. Karlstrom Outstanding Educator Award </E2:proteins> and the ACM SIGCSE Award for Outstanding Contributions to Computer Science Education ."
"role","0","29","<E1:author> Pausch </E1:author> received two awards from Association for Computing Machinery in 2007 for his achievements in computing education : the Karl V. Karlstrom Outstanding Educator Award and the <E2:proteins> ACM SIGCSE Award for Outstanding Contributions to Computer Science Education </E2:proteins> ."
"role","21","5","Pausch received two awards from <E2:UDBKL> Association for Computing Machinery </E2:UDBKL> in 2007 for his achievements in computing education : the <E1:proteins> Karl V. Karlstrom Outstanding Educator Award </E1:proteins> and the ACM SIGCSE Award for Outstanding Contributions to Computer Science Education ."
"win-defeat","21","15","Pausch received two awards from Association for Computing Machinery in 2007 for his achievements in <E2:UDBKL> computing education </E2:UDBKL> : the <E1:proteins> Karl V. Karlstrom Outstanding Educator Award </E1:proteins> and the ACM SIGCSE Award for Outstanding Contributions to Computer Science Education ."
"role","29","5","Pausch received two awards from <E2:UDBKL> Association for Computing Machinery </E2:UDBKL> in 2007 for his achievements in computing education : the Karl V. Karlstrom Outstanding Educator Award and the <E1:proteins> ACM SIGCSE Award for Outstanding Contributions to Computer Science Education </E1:proteins> ."
"win-defeat","29","15","Pausch received two awards from Association for Computing Machinery in 2007 for his achievements in <E2:UDBKL> computing education </E2:UDBKL> : the Karl V. Karlstrom Outstanding Educator Award and the <E1:proteins> ACM SIGCSE Award for Outstanding Contributions to Computer Science Education </E1:proteins> ."
"related-to","3","10","In 1960 , <E1:UDBKL> Devol </E1:UDBKL> personally sold the first <E2:proteins> Unimate </E2:proteins> robot , which was shipped in 1961 to General Motors ."
"named","8","11","In 1960 , Devol personally sold the first <E1:proteins> Unimate </E1:proteins> <E2:proteins> robot </E2:proteins> , which was shipped in 1961 to General Motors ."
"role","8","19","In 1960 , Devol personally sold the first <E1:proteins> Unimate </E1:proteins> robot , which was shipped in 1961 to <E2:UDBKL> General Motors </E2:UDBKL> ."
"part-of","13","0","<E2:proteins> Semantic networks </E2:proteins> are used in natural language processing applications such as <E1:UDBKL> semantic parsing </E1:UDBKL> ."
"part-of","13","5","Semantic networks are used in <E2:UDBKL> natural language processing </E2:UDBKL> applications such as <E1:UDBKL> semantic parsing </E1:UDBKL> ."
"named","9","4","Some successful applications of <E2:UDBKL> deep learning </E2:UDBKL> are <E1:UDBKL> computer vision </E1:UDBKL> and speech recognition . Honglak Lee , Roger Grosse , Rajesh Ranganath , Andrew Y. Ng ."
"related-to","12","4","Some successful applications of <E2:UDBKL> deep learning </E2:UDBKL> are computer vision and <E1:UDBKL> speech recognition </E1:UDBKL> . Honglak Lee , Roger Grosse , Rajesh Ranganath , Andrew Y. Ng ."
"physical","5","16","In addition to maintaining the <E1:proteins> Discovery One spacecraft systems </E1:proteins> during the interplanetary mission to <E2:proteins> Jupiter </E2:proteins> ( or Saturn in the novel ) , HAL is capable of speech synthesis , speech recognition , facial recognition , natural language processing , lip reading , art appreciation , Affective computing , automated reasoning , spacecraft piloting and playing chess ."
"part-of","5","19","In addition to maintaining the <E1:proteins> Discovery One spacecraft systems </E1:proteins> during the interplanetary mission to Jupiter ( or <E2:proteins> Saturn </E2:proteins> in the novel ) , HAL is capable of speech synthesis , speech recognition , facial recognition , natural language processing , lip reading , art appreciation , Affective computing , automated reasoning , spacecraft piloting and playing chess ."
"part-of","25","5","In addition to maintaining the <E2:proteins> Discovery One spacecraft systems </E2:proteins> during the interplanetary mission to Jupiter ( or Saturn in the novel ) , <E1:proteins> HAL </E1:proteins> is capable of speech synthesis , speech recognition , facial recognition , natural language processing , lip reading , art appreciation , Affective computing , automated reasoning , spacecraft piloting and playing chess ."
"related-to","23","29","In addition to maintaining the Discovery One spacecraft systems during the interplanetary mission to Jupiter ( or Saturn in the novel ) , <E1:proteins> HAL </E1:proteins> is capable of <E2:UDBKL> speech synthesis </E2:UDBKL> , speech recognition , facial recognition , natural language processing , lip reading , art appreciation , Affective computing , automated reasoning , spacecraft piloting and playing chess ."
"related-to","23","32","In addition to maintaining the Discovery One spacecraft systems during the interplanetary mission to Jupiter ( or Saturn in the novel ) , <E1:proteins> HAL </E1:proteins> is capable of speech synthesis , <E2:UDBKL> speech recognition </E2:UDBKL> , facial recognition , natural language processing , lip reading , art appreciation , Affective computing , automated reasoning , spacecraft piloting and playing chess ."
"related-to","23","35","In addition to maintaining the Discovery One spacecraft systems during the interplanetary mission to Jupiter ( or Saturn in the novel ) , <E1:proteins> HAL </E1:proteins> is capable of speech synthesis , speech recognition , <E2:UDBKL> facial recognition </E2:UDBKL> , natural language processing , lip reading , art appreciation , Affective computing , automated reasoning , spacecraft piloting and playing chess ."
"related-to","23","38","In addition to maintaining the Discovery One spacecraft systems during the interplanetary mission to Jupiter ( or Saturn in the novel ) , <E1:proteins> HAL </E1:proteins> is capable of speech synthesis , speech recognition , facial recognition , <E2:UDBKL> natural language processing </E2:UDBKL> , lip reading , art appreciation , Affective computing , automated reasoning , spacecraft piloting and playing chess ."
"named","23","42","In addition to maintaining the Discovery One spacecraft systems during the interplanetary mission to Jupiter ( or Saturn in the novel ) , <E1:proteins> HAL </E1:proteins> is capable of speech synthesis , speech recognition , facial recognition , natural language processing , <E2:UDBKL> lip reading </E2:UDBKL> , art appreciation , Affective computing , automated reasoning , spacecraft piloting and playing chess ."
"named","23","45","In addition to maintaining the Discovery One spacecraft systems during the interplanetary mission to Jupiter ( or Saturn in the novel ) , <E1:proteins> HAL </E1:proteins> is capable of speech synthesis , speech recognition , facial recognition , natural language processing , lip reading , <E2:UDBKL> art appreciation </E2:UDBKL> , Affective computing , automated reasoning , spacecraft piloting and playing chess ."
"related-to","23","48","In addition to maintaining the Discovery One spacecraft systems during the interplanetary mission to Jupiter ( or Saturn in the novel ) , <E1:proteins> HAL </E1:proteins> is capable of speech synthesis , speech recognition , facial recognition , natural language processing , lip reading , art appreciation , <E2:UDBKL> Affective computing </E2:UDBKL> , automated reasoning , spacecraft piloting and playing chess ."
"related-to","23","51","In addition to maintaining the Discovery One spacecraft systems during the interplanetary mission to Jupiter ( or Saturn in the novel ) , <E1:proteins> HAL </E1:proteins> is capable of speech synthesis , speech recognition , facial recognition , natural language processing , lip reading , art appreciation , Affective computing , <E2:UDBKL> automated reasoning </E2:UDBKL> , spacecraft piloting and playing chess ."
"physical","23","54","In addition to maintaining the Discovery One spacecraft systems during the interplanetary mission to Jupiter ( or Saturn in the novel ) , <E1:proteins> HAL </E1:proteins> is capable of speech synthesis , speech recognition , facial recognition , natural language processing , lip reading , art appreciation , Affective computing , automated reasoning , <E2:UDBKL> spacecraft piloting </E2:UDBKL> and playing chess ."
"artifact","23","57","In addition to maintaining the Discovery One spacecraft systems during the interplanetary mission to Jupiter ( or Saturn in the novel ) , <E1:proteins> HAL </E1:proteins> is capable of speech synthesis , speech recognition , facial recognition , natural language processing , lip reading , art appreciation , Affective computing , automated reasoning , spacecraft piloting and <E2:UDBKL> playing chess </E2:UDBKL> ."
"physical","0","6","<E1:author> Dr. Julesz </E1:author> emigrated from <E2:UDBKL> Hungary </E2:UDBKL> to the United States following the 1956 Soviet invasion ."
"physical","0","8","<E1:author> Dr. Julesz </E1:author> emigrated from Hungary to <E2:UDBKL> the United States </E2:UDBKL> following the 1956 Soviet invasion ."
"role","0","14","<E1:author> Dr. Julesz </E1:author> emigrated from Hungary to the United States following the 1956 <E2:UDBKL> Soviet </E2:UDBKL> invasion ."
"named","12","7","Some popular fitness functions based on the <E2:UDBKL> confusion matrix </E2:UDBKL> include <E1:UDBKL> sensitivity / specificity </E1:UDBKL> , recall / precision , F-measure , Jaccard similarity , Matthews correlation coefficient , and cost / gain matrix which combines the costs and gains assigned to the 4 different types of classifications ."
"named","16","7","Some popular fitness functions based on the <E2:UDBKL> confusion matrix </E2:UDBKL> include sensitivity / specificity , <E1:UDBKL> recall / precision </E1:UDBKL> , F-measure , Jaccard similarity , Matthews correlation coefficient , and cost / gain matrix which combines the costs and gains assigned to the 4 different types of classifications ."
"named","20","7","Some popular fitness functions based on the <E2:UDBKL> confusion matrix </E2:UDBKL> include sensitivity / specificity , recall / precision , <E1:UDBKL> F-measure </E1:UDBKL> , Jaccard similarity , Matthews correlation coefficient , and cost / gain matrix which combines the costs and gains assigned to the 4 different types of classifications ."
"named","22","7","Some popular fitness functions based on the <E2:UDBKL> confusion matrix </E2:UDBKL> include sensitivity / specificity , recall / precision , F-measure , <E1:UDBKL> Jaccard similarity </E1:UDBKL> , Matthews correlation coefficient , and cost / gain matrix which combines the costs and gains assigned to the 4 different types of classifications ."
"named","25","7","Some popular fitness functions based on the <E2:UDBKL> confusion matrix </E2:UDBKL> include sensitivity / specificity , recall / precision , F-measure , Jaccard similarity , <E1:UDBKL> Matthews correlation coefficient </E1:UDBKL> , and cost / gain matrix which combines the costs and gains assigned to the 4 different types of classifications ."
"named","30","7","Some popular fitness functions based on the <E2:UDBKL> confusion matrix </E2:UDBKL> include sensitivity / specificity , recall / precision , F-measure , Jaccard similarity , Matthews correlation coefficient , and <E1:UDBKL> cost / gain matrix </E1:UDBKL> which combines the costs and gains assigned to the 4 different types of classifications ."
"named","29","6","Common numerical programming environments such as <E2:proteins> MATLAB </E2:proteins> , SciLab , NumPy , Sklearn and the R language provide some of the simpler feature extraction techniques ( e.g. <E1:proteins> principal component analysis </E1:proteins> ) via built-in commands ."
"named","29","8","Common numerical programming environments such as MATLAB , <E2:proteins> SciLab </E2:proteins> , NumPy , Sklearn and the R language provide some of the simpler feature extraction techniques ( e.g. <E1:proteins> principal component analysis </E1:proteins> ) via built-in commands ."
"named","29","10","Common numerical programming environments such as MATLAB , SciLab , <E2:proteins> NumPy </E2:proteins> , Sklearn and the R language provide some of the simpler feature extraction techniques ( e.g. <E1:proteins> principal component analysis </E1:proteins> ) via built-in commands ."
"named","29","12","Common numerical programming environments such as MATLAB , SciLab , NumPy , <E2:proteins> Sklearn </E2:proteins> and the R language provide some of the simpler feature extraction techniques ( e.g. <E1:proteins> principal component analysis </E1:proteins> ) via built-in commands ."
"named","29","15","Common numerical programming environments such as MATLAB , SciLab , NumPy , Sklearn and the <E2:proteins> R language </E2:proteins> provide some of the simpler feature extraction techniques ( e.g. <E1:proteins> principal component analysis </E1:proteins> ) via built-in commands ."
"part-of","6","22","In the first published paper on <E1:UDBKL> CGs </E1:UDBKL> , John F. Sowa applied them to a wide range of topics in <E2:UDBKL> artificial intelligence </E2:UDBKL> , computer science , and cognitive science ."
"role","6","25","In the first published paper on <E1:UDBKL> CGs </E1:UDBKL> , John F. Sowa applied them to a wide range of topics in artificial intelligence , <E2:UDBKL> computer science </E2:UDBKL> , and cognitive science ."
"role","6","29","In the first published paper on <E1:UDBKL> CGs </E1:UDBKL> , John F. Sowa applied them to a wide range of topics in artificial intelligence , computer science , and <E2:UDBKL> cognitive science </E2:UDBKL> ."
"role","10","6","In the first published paper on <E2:UDBKL> CGs </E2:UDBKL> , <E1:author> John F. Sowa </E1:author> applied them to a wide range of topics in artificial intelligence , computer science , and cognitive science ."
"related-to","0","6","<E1:UDBKL> NIST </E1:UDBKL> also differs from <E2:UDBKL> BLEU </E2:UDBKL> in its calculation of the brevity penalty , insofar as small variations in translation length do not impact the overall score as much ."
"role","1","15","The <E1:proteins> IJCAI Award for Research Excellence </E1:proteins> is a biannual award given at the <E2:UDBKL> IJCAI </E2:UDBKL> conference to researcher in artificial intelligence as a recognition of excellence of their career ."
"named","1","20","The <E1:proteins> IJCAI Award for Research Excellence </E1:proteins> is a biannual award given at the IJCAI conference to researcher in <E2:UDBKL> artificial intelligence </E2:UDBKL> as a recognition of excellence of their career ."
"role","0","11","<E1:author> Lenat </E1:author> was one of the original Fellows of the <E2:UDBKL> AAAI </E2:UDBKL> , and is the only individual to have on the Scientific Advisory Boards of both Microsoft and Apple ."
"role","0","22","<E1:author> Lenat </E1:author> was one of the original Fellows of the AAAI , and is the only individual to have on the <E2:UDBKL> Scientific Advisory Boards of both Microsoft and Apple </E2:UDBKL> ."
"related-to","0","7","<E1:proteins> Autoencoders </E1:proteins> are trained to minimise <E2:proteins> reconstruction errors </E2:proteins> ( such as Mean squared error ) , often referred to as the loss :"
"part-of","12","5","Autoencoders are trained to minimise <E2:proteins> reconstruction errors </E2:proteins> ( such as <E1:UDBKL> Mean squared error </E1:UDBKL> ) , often referred to as the loss :"
"part-of","22","5","Autoencoders are trained to minimise <E2:proteins> reconstruction errors </E2:proteins> ( such as Mean squared error ) , often referred to as the <E1:proteins> loss </E1:proteins> :"
"part-of","36","29","An alternative to the use of the definitions is to consider general word-sense relatedness and to compute the similarity of each pair of word senses based on a given <E2:proteins> lexical knowledge base </E2:proteins> such as <E1:proteins> WordNet </E1:proteins> ."
"artifact","0","9","<E1:proteins> TD-Lambda </E1:proteins> is a learning algorithm invented by <E2:author> Richard S. Sutton </E2:author> based on earlier work on temporal difference learning by Arthur Samuel ."
"role","7","21","TD-Lambda is a learning algorithm invented by <E1:author> Richard S. Sutton </E1:author> based on earlier work on temporal difference learning by <E2:author> Arthur Samuel </E2:author> ."
"named","8","1","In <E2:UDBKL> data mining </E2:UDBKL> and statistics , <E1:UDBKL> hierarchical clustering </E1:UDBKL> ( also called hierarchical cluster analysis or HCA ) is a method of cluster analysis which seeks to build a hierarchy of clusters ."
"named","8","4","In data mining and <E2:UDBKL> statistics </E2:UDBKL> , <E1:UDBKL> hierarchical clustering </E1:UDBKL> ( also called hierarchical cluster analysis or HCA ) is a method of cluster analysis which seeks to build a hierarchy of clusters ."
"named","13","6","In data mining and statistics , <E2:UDBKL> hierarchical clustering </E2:UDBKL> ( also called <E1:UDBKL> hierarchical cluster analysis </E1:UDBKL> or HCA ) is a method of cluster analysis which seeks to build a hierarchy of clusters ."
"named","17","6","In data mining and statistics , <E2:UDBKL> hierarchical clustering </E2:UDBKL> ( also called hierarchical cluster analysis or <E1:UDBKL> HCA </E1:UDBKL> ) is a method of cluster analysis which seeks to build a hierarchy of clusters ."
"related-to","3","13","The concept of <E1:proteins> deconvolution </E1:proteins> is widely used in the techniques of <E2:UDBKL> signal processing </E2:UDBKL> and image processing ."
"related-to","0","25","<E1:proteins> Cognitive maps </E1:proteins> serve the construction and accumulation of spatial knowledge , allowing the mind 's eye to visualize images in order to reduce <E2:proteins> cognitive load </E2:proteins> , enhance recall and learning of information ."
"named","1","17","A <E1:proteins> voice-user interface </E1:proteins> ( VUI ) makes spoken human interaction with computers possible , using <E2:UDBKL> speech recognition </E2:UDBKL> to understand spoken commands and Question answering , and typically text to speech to play a reply ."
"related-to","1","24","A <E1:proteins> voice-user interface </E1:proteins> ( VUI ) makes spoken human interaction with computers possible , using speech recognition to understand spoken commands and <E2:UDBKL> Question answering </E2:UDBKL> , and typically text to speech to play a reply ."
"named","1","29","A <E1:proteins> voice-user interface </E1:proteins> ( VUI ) makes spoken human interaction with computers possible , using speech recognition to understand spoken commands and Question answering , and typically <E2:UDBKL> text to speech </E2:UDBKL> to play a reply ."
"named","6","1","A <E2:proteins> voice-user interface </E2:proteins> ( <E1:proteins> VUI </E1:proteins> ) makes spoken human interaction with computers possible , using speech recognition to understand spoken commands and Question answering , and typically text to speech to play a reply ."
"related-to","0","5","<E1:proteins> Jess </E1:proteins> is a <E2:proteins> rule engine </E2:proteins> for the Java platform that was developed by Ernest Friedman-Hill of Sandia National ."
"related-to","0","9","<E1:proteins> Jess </E1:proteins> is a rule engine for the <E2:proteins> Java </E2:proteins> platform that was developed by Ernest Friedman-Hill of Sandia National ."
"artifact","0","15","<E1:proteins> Jess </E1:proteins> is a rule engine for the Java platform that was developed by <E2:author> Ernest Friedman-Hill </E2:author> of Sandia National ."
"physical","13","18","Jess is a rule engine for the Java platform that was developed by <E1:author> Ernest Friedman-Hill </E1:author> of <E2:UDBKL> Sandia National </E2:UDBKL> ."
"related-to","1","18","For <E1:proteins> multilayer perceptron </E1:proteins> s , where a hidden layer exists , more sophisticated algorithms such as <E2:proteins> backpropagation </E2:proteins> must be used ."
"artifact","5","0","<E2:proteins> Google Translate </E2:proteins> 's <E1:proteins> neural machine translation system </E1:proteins> uses a large end-to-end artificial neural network that attempts to perform deep learning , in particular , long short-term memory networks ."
"part-of","3","12","Google Translate 's <E1:proteins> neural machine translation system </E1:proteins> uses a large <E2:proteins> end-to-end artificial neural network </E2:proteins> that attempts to perform deep learning , in particular , long short-term memory networks ."
"part-of","10","20","Google Translate 's neural machine translation system uses a large <E1:proteins> end-to-end artificial neural network </E1:proteins> that attempts to perform <E2:UDBKL> deep learning </E2:UDBKL> , in particular , long short-term memory networks ."
"part-of","26","18","Google Translate 's neural machine translation system uses a large end-to-end artificial neural network that attempts to perform <E2:UDBKL> deep learning </E2:UDBKL> , in particular , <E1:proteins> long short-term memory networks </E1:proteins> ."
"role","1","10","| <E1:UDBKL> Apple </E1:UDBKL> Apple Inc originally licensed software from <E2:UDBKL> Nuance </E2:UDBKL> to provide speech recognition capability to its digital assistant Siri ."
"role","4","1","| <E2:UDBKL> Apple </E2:UDBKL> <E1:UDBKL> Apple Inc </E1:UDBKL> originally licensed software from Nuance to provide speech recognition capability to its digital assistant Siri ."
"named","20","1","| <E2:UDBKL> Apple </E2:UDBKL> Apple Inc originally licensed software from Nuance to provide speech recognition capability to its digital assistant <E1:proteins> Siri </E1:proteins> ."
"part-of","20","11","| Apple Apple Inc originally licensed software from Nuance to provide <E2:UDBKL> speech recognition </E2:UDBKL> capability to its digital assistant <E1:proteins> Siri </E1:proteins> ."
"role","0","5","<E1:UDBKL> Columbia </E1:UDBKL> released several <E2:proteins> 3D westerns </E2:proteins> produced by Sam Katzman and directed by William Castle ."
"role","9","0","<E2:UDBKL> Columbia </E2:UDBKL> released several 3D westerns produced by <E1:UDBKL> Sam Katzman </E1:UDBKL> and directed by William Castle ."
"role","14","0","<E2:UDBKL> Columbia </E2:UDBKL> released several 3D westerns produced by Sam Katzman and directed by <E1:UDBKL> William Castle </E1:UDBKL> ."
"part-of","1","10","The <E1:UDBKL> ROC curve </E1:UDBKL> is created by plotting the <E2:UDBKL> TRUE positive rate </E2:UDBKL> ( TPR ) against the FALSE positive rate ( FPR ) at various threshold settings ."
"part-of","1","18","The <E1:UDBKL> ROC curve </E1:UDBKL> is created by plotting the TRUE positive rate ( TPR ) against the <E2:UDBKL> FALSE positive rate </E2:UDBKL> ( FPR ) at various threshold settings ."
"named","14","8","The ROC curve is created by plotting the <E2:UDBKL> TRUE positive rate </E2:UDBKL> ( <E1:UDBKL> TPR </E1:UDBKL> ) against the FALSE positive rate ( FPR ) at various threshold settings ."
"named","22","16","The ROC curve is created by plotting the TRUE positive rate ( TPR ) against the <E2:UDBKL> FALSE positive rate </E2:UDBKL> ( <E1:UDBKL> FPR </E1:UDBKL> ) at various threshold settings ."
"role","9","3","Research stagnated after <E2:UDBKL> machine learning </E2:UDBKL> research by <E1:author> Marvin Minsky </E1:author> and Seymour Papert ( 1969 ) ,"
"role","12","3","Research stagnated after <E2:UDBKL> machine learning </E2:UDBKL> research by Marvin Minsky and <E1:author> Seymour Papert </E1:author> ( 1969 ) ,"
"related-to","8","13","Other programming environments that are used to build <E1:UDBKL> DAQ </E1:UDBKL> applications include <E2:proteins> ladder logic </E2:proteins> , Visual C + + , Visual Basic , LabVIEW , and MATLAB ."
"related-to","8","16","Other programming environments that are used to build <E1:UDBKL> DAQ </E1:UDBKL> applications include ladder logic , <E2:proteins> Visual C + + </E2:proteins> , Visual Basic , LabVIEW , and MATLAB ."
"related-to","8","21","Other programming environments that are used to build <E1:UDBKL> DAQ </E1:UDBKL> applications include ladder logic , Visual C + + , <E2:proteins> Visual Basic </E2:proteins> , LabVIEW , and MATLAB ."
"part-of","8","24","Other programming environments that are used to build <E1:UDBKL> DAQ </E1:UDBKL> applications include ladder logic , Visual C + + , Visual Basic , <E2:proteins> LabVIEW </E2:proteins> , and MATLAB ."
"related-to","8","27","Other programming environments that are used to build <E1:UDBKL> DAQ </E1:UDBKL> applications include ladder logic , Visual C + + , Visual Basic , LabVIEW , and <E2:proteins> MATLAB </E2:proteins> ."
"related-to","1","15","Mass-produced <E1:proteins> printed circuit board </E1:proteins> s ( PCBs ) are almost exclusively manufactured by <E2:proteins> pick-and-place robots </E2:proteins> , typically with SCARA manipulators , which remove tiny electronic component s from strips or trays , and place them on to PCBs with great accuracy ."
"related-to","1","39","Mass-produced <E1:proteins> printed circuit board </E1:proteins> s ( PCBs ) are almost exclusively manufactured by pick-and-place robots , typically with SCARA manipulators , which remove tiny electronic component s from strips or trays , and place them on to <E2:proteins> PCBs </E2:proteins> with great accuracy ."
"named","8","1","Mass-produced <E2:proteins> printed circuit board </E2:proteins> s ( <E1:proteins> PCBs </E1:proteins> ) are almost exclusively manufactured by pick-and-place robots , typically with SCARA manipulators , which remove tiny electronic component s from strips or trays , and place them on to PCBs with great accuracy ."
"part-of","20","13","Mass-produced printed circuit board s ( PCBs ) are almost exclusively manufactured by <E2:proteins> pick-and-place robots </E2:proteins> , typically with <E1:proteins> SCARA </E1:proteins> manipulators , which remove tiny electronic component s from strips or trays , and place them on to PCBs with great accuracy ."
"named","17","4","In the context of <E2:UDBKL> machine learning </E2:UDBKL> , where it is most widely applied today , <E1:proteins> LDA </E1:proteins> was rediscovered independently by David Blei , Andrew Ng and Michael I. Jordan in 2003 , and presented as a graphical model for topic discovery ."
"artifact","15","22","In the context of machine learning , where it is most widely applied today , <E1:proteins> LDA </E1:proteins> was rediscovered independently by <E2:author> David Blei </E2:author> , Andrew Ng and Michael I. Jordan in 2003 , and presented as a graphical model for topic discovery ."
"artifact","15","25","In the context of machine learning , where it is most widely applied today , <E1:proteins> LDA </E1:proteins> was rediscovered independently by David Blei , <E2:author> Andrew Ng </E2:author> and Michael I. Jordan in 2003 , and presented as a graphical model for topic discovery ."
"artifact","15","28","In the context of machine learning , where it is most widely applied today , <E1:proteins> LDA </E1:proteins> was rediscovered independently by David Blei , Andrew Ng and <E2:author> Michael I. Jordan </E2:author> in 2003 , and presented as a graphical model for topic discovery ."
"related-to","15","38","In the context of machine learning , where it is most widely applied today , <E1:proteins> LDA </E1:proteins> was rediscovered independently by David Blei , Andrew Ng and Michael I. Jordan in 2003 , and presented as a <E2:proteins> graphical model </E2:proteins> for topic discovery ."
"named","36","41","In the context of machine learning , where it is most widely applied today , LDA was rediscovered independently by David Blei , Andrew Ng and Michael I. Jordan in 2003 , and presented as a <E1:proteins> graphical model </E1:proteins> for <E2:UDBKL> topic discovery </E2:UDBKL> ."
"related-to","9","14","The measured performance on test data of eight naive <E1:UDBKL> WSI </E1:UDBKL> across various <E2:proteins> tauopathies </E2:proteins> resulted in the recall , precision , and an F1 score of 0.92 , 0.72 , and 0.81 , respectively ."
"related-to","5","16","With the help of advanced <E1:UDBKL> AR </E1:UDBKL> technologies ( e.g. adding computer vision , incorporating <E2:UDBKL> AR </E2:UDBKL> cameras into smartphone and object recognition ) the information about the surrounding real world of the user becomes interactive and digitally manipulated ."
"role","3","10","In 2014 , <E1:author> Schmidhuber </E1:author> formed a company , <E2:UDBKL> Nnaisense </E2:UDBKL> , to work on commercial applications of artificial intelligence in fields such as finance , heavy industry and self-driving car s ."
"part-of","8","18","In 2014 , Schmidhuber formed a company , <E1:UDBKL> Nnaisense </E1:UDBKL> , to work on commercial applications of <E2:UDBKL> artificial intelligence </E2:UDBKL> in fields such as finance , heavy industry and self-driving car s ."
"related-to","8","29","In 2014 , Schmidhuber formed a company , <E1:UDBKL> Nnaisense </E1:UDBKL> , to work on commercial applications of artificial intelligence in fields such as finance , heavy industry and <E2:proteins> self-driving car </E2:proteins> s ."
"part-of","8","0","<E2:proteins> Bigrams </E2:proteins> are used in most successful <E1:proteins> language model </E1:proteins> s for speech recognition ."
"related-to","6","12","Bigrams are used in most successful <E1:proteins> language model </E1:proteins> s for <E2:UDBKL> speech recognition </E2:UDBKL> ."
"named","10","3","His research in <E2:UDBKL> cognitive psychology </E2:UDBKL> has won the <E1:proteins> Early Career Award </E1:proteins> ( 1984 ) and Boyd McCandless Award 1986 ) from the American Psychological Association , the Troland Research Award ( 1993 ) from the National Academy of Sciences , the Henry Dale Prize ( 2004 ) from the Royal Institution of Great Britain , and the George Miller Prize ( 2010 ) from the Cognitive Neuroscience Society ."
"role","15","24","His research in cognitive psychology has won the Early Career Award ( 1984 ) and <E1:proteins> Boyd McCandless Award </E1:proteins> 1986 ) from the <E2:UDBKL> American Psychological Association </E2:UDBKL> , the Troland Research Award ( 1993 ) from the National Academy of Sciences , the Henry Dale Prize ( 2004 ) from the Royal Institution of Great Britain , and the George Miller Prize ( 2010 ) from the Cognitive Neuroscience Society ."
"origin","27","37","His research in cognitive psychology has won the Early Career Award ( 1984 ) and Boyd McCandless Award 1986 ) from the American Psychological Association , the <E1:proteins> Troland Research Award </E1:proteins> ( 1993 ) from the <E2:UDBKL> National Academy of Sciences </E2:UDBKL> , the Henry Dale Prize ( 2004 ) from the Royal Institution of Great Britain , and the George Miller Prize ( 2010 ) from the Cognitive Neuroscience Society ."
"physical","41","51","His research in cognitive psychology has won the Early Career Award ( 1984 ) and Boyd McCandless Award 1986 ) from the American Psychological Association , the Troland Research Award ( 1993 ) from the National Academy of Sciences , the <E1:proteins> Henry Dale Prize </E1:proteins> ( 2004 ) from the <E2:UDBKL> Royal Institution of Great Britain </E2:UDBKL> , and the George Miller Prize ( 2010 ) from the Cognitive Neuroscience Society ."
"origin","57","67","His research in cognitive psychology has won the Early Career Award ( 1984 ) and Boyd McCandless Award 1986 ) from the American Psychological Association , the Troland Research Award ( 1993 ) from the National Academy of Sciences , the Henry Dale Prize ( 2004 ) from the Royal Institution of Great Britain , and the <E1:proteins> George Miller Prize </E1:proteins> ( 2010 ) from the <E2:UDBKL> Cognitive Neuroscience Society </E2:UDBKL> ."
"named","1","9","An <E1:proteins> eigenface </E1:proteins> ( The approach of using <E2:proteins> eigenfaces </E2:proteins> for Facial recognition system was developed by Sirovich and Kirby ( 1987 ) and used by Matthew Turk and Alex Pentland in face classification . Turk , Matthew A and Pentland , Alex P. Face recognition using eigenfaces ."
"named","1","47","An <E1:proteins> eigenface </E1:proteins> ( The approach of using eigenfaces for Facial recognition system was developed by Sirovich and Kirby ( 1987 ) and used by Matthew Turk and Alex Pentland in face classification . Turk , Matthew A and Pentland , Alex P. Face recognition using <E2:proteins> eigenfaces </E2:proteins> ."
"artifact","7","17","An eigenface ( The approach of using <E1:proteins> eigenfaces </E1:proteins> for Facial recognition system was developed by <E2:author> Sirovich </E2:author> and Kirby ( 1987 ) and used by Matthew Turk and Alex Pentland in face classification . Turk , Matthew A and Pentland , Alex P. Face recognition using eigenfaces ."
"artifact","7","19","An eigenface ( The approach of using <E1:proteins> eigenfaces </E1:proteins> for Facial recognition system was developed by Sirovich and <E2:author> Kirby </E2:author> ( 1987 ) and used by Matthew Turk and Alex Pentland in face classification . Turk , Matthew A and Pentland , Alex P. Face recognition using eigenfaces ."
"part-of","7","32","An eigenface ( The approach of using <E1:proteins> eigenfaces </E1:proteins> for Facial recognition system was developed by Sirovich and Kirby ( 1987 ) and used by Matthew Turk and Alex Pentland in <E2:UDBKL> face classification </E2:UDBKL> . Turk , Matthew A and Pentland , Alex P. Face recognition using eigenfaces ."
"part-of","11","7","An eigenface ( The approach of using <E2:proteins> eigenfaces </E2:proteins> for <E1:proteins> Facial recognition system </E1:proteins> was developed by Sirovich and Kirby ( 1987 ) and used by Matthew Turk and Alex Pentland in face classification . Turk , Matthew A and Pentland , Alex P. Face recognition using eigenfaces ."
"related-to","9","44","An eigenface ( The approach of using eigenfaces for <E1:proteins> Facial recognition system </E1:proteins> was developed by Sirovich and Kirby ( 1987 ) and used by Matthew Turk and Alex Pentland in face classification . Turk , Matthew A and Pentland , Alex P. <E2:UDBKL> Face recognition </E2:UDBKL> using eigenfaces ."
"role","26","7","An eigenface ( The approach of using <E2:proteins> eigenfaces </E2:proteins> for Facial recognition system was developed by Sirovich and Kirby ( 1987 ) and used by <E1:author> Matthew Turk </E1:author> and Alex Pentland in face classification . Turk , Matthew A and Pentland , Alex P. Face recognition using eigenfaces ."
"named","24","35","An eigenface ( The approach of using eigenfaces for Facial recognition system was developed by Sirovich and Kirby ( 1987 ) and used by <E1:author> Matthew Turk </E1:author> and Alex Pentland in face classification . <E2:author> Turk , Matthew A </E2:author> and Pentland , Alex P. Face recognition using eigenfaces ."
"role","29","7","An eigenface ( The approach of using <E2:proteins> eigenfaces </E2:proteins> for Facial recognition system was developed by Sirovich and Kirby ( 1987 ) and used by Matthew Turk and <E1:author> Alex Pentland </E1:author> in face classification . Turk , Matthew A and Pentland , Alex P. Face recognition using eigenfaces ."
"named","27","40","An eigenface ( The approach of using eigenfaces for Facial recognition system was developed by Sirovich and Kirby ( 1987 ) and used by Matthew Turk and <E1:author> Alex Pentland </E1:author> in face classification . Turk , Matthew A and <E2:author> Pentland , Alex P. </E2:author> Face recognition using eigenfaces ."
"related-to","42","47","An eigenface ( The approach of using eigenfaces for Facial recognition system was developed by Sirovich and Kirby ( 1987 ) and used by Matthew Turk and Alex Pentland in face classification . Turk , Matthew A and Pentland , Alex P. <E1:UDBKL> Face recognition </E1:UDBKL> using <E2:proteins> eigenfaces </E2:proteins> ."
"related-to","0","10","<E1:proteins> Hyponymy </E1:proteins> is the most frequently encoded relation among <E2:proteins> synsets </E2:proteins> used in lexical databases such as WordNet ."
"related-to","8","17","Hyponymy is the most frequently encoded relation among <E1:proteins> synsets </E1:proteins> used in lexical databases such as <E2:proteins> WordNet </E2:proteins> ."
"related-to","0","7","<E1:UDBKL> OPeNDAP </E1:UDBKL> offers open-source libraries in <E2:proteins> C + + </E2:proteins> and Java , but many clients rely on community developed libraries such as libraries include embedded capabilities for retrieving ( array-style ) data from DAP servers ."
"role","0","11","<E1:UDBKL> OPeNDAP </E1:UDBKL> offers open-source libraries in C + + and <E2:proteins> Java </E2:proteins> , but many clients rely on community developed libraries such as libraries include embedded capabilities for retrieving ( array-style ) data from DAP servers ."
"physical","4","15","In that page , <E1:proteins> Samurai Damashii </E1:proteins> exaggerated the Senkousha as the crystallization of <E2:UDBKL> China </E2:UDBKL> 's four thousand years of scientific knowledge , commented on the crude design ( e.g. the Chinese Cannon on its crotch ) , and put its image among images of Honda ' s ASIMO and Sony ' s QRIO SDR-3X for juxtaposition ."
"physical","8","15","In that page , Samurai Damashii exaggerated the <E1:proteins> Senkousha </E1:proteins> as the crystallization of <E2:UDBKL> China </E2:UDBKL> 's four thousand years of scientific knowledge , commented on the crude design ( e.g. the Chinese Cannon on its crotch ) , and put its image among images of Honda ' s ASIMO and Sony ' s QRIO SDR-3X for juxtaposition ."
"named","32","8","In that page , Samurai Damashii exaggerated the <E2:proteins> Senkousha </E2:proteins> as the crystallization of China 's four thousand years of scientific knowledge , commented on the crude design ( e.g. the <E1:proteins> Chinese Cannon </E1:proteins> on its crotch ) , and put its image among images of Honda ' s ASIMO and Sony ' s QRIO SDR-3X for juxtaposition ."
"named","49","44","In that page , Samurai Damashii exaggerated the Senkousha as the crystallization of China 's four thousand years of scientific knowledge , commented on the crude design ( e.g. the Chinese Cannon on its crotch ) , and put its image among images of <E2:UDBKL> Honda </E2:UDBKL> ' s <E1:proteins> ASIMO </E1:proteins> and Sony ' s QRIO SDR-3X for juxtaposition ."
"named","54","49","In that page , Samurai Damashii exaggerated the Senkousha as the crystallization of China 's four thousand years of scientific knowledge , commented on the crude design ( e.g. the Chinese Cannon on its crotch ) , and put its image among images of Honda ' s ASIMO and <E2:UDBKL> Sony </E2:UDBKL> ' s <E1:proteins> QRIO SDR-3X </E1:proteins> for juxtaposition ."
"part-of","8","24","There are also many programming libraries that contain <E1:proteins> neural network </E1:proteins> functionality and that can be used in custom implementations ( such as <E2:proteins> TensorFlow </E2:proteins> , Theano , etc ."
"part-of","8","26","There are also many programming libraries that contain <E1:proteins> neural network </E1:proteins> functionality and that can be used in custom implementations ( such as TensorFlow , <E2:proteins> Theano </E2:proteins> , etc ."
"related-to","3","9","A trial by <E1:UDBKL> RET </E1:UDBKL> in 2011 with <E2:proteins> Facial recognition system </E2:proteins> cameras mounted on trams made sure that people were banned from the city trams did not sneak on anyway ."
"physical","7","11","The film , adapted from the popular <E1:UDBKL> Cole Porter </E1:UDBKL> <E2:UDBKL> Broadway </E2:UDBKL> musical , starred the MGM songbird team of Howard Keel and Kathryn Grayson as the leads , supported by Ann Miller , Keenan Wynn , Bobby Van , James Whitmore , Kurt Kasznar and Tommy Rall ."
"physical","20","9","The film , adapted from the popular Cole Porter <E2:UDBKL> Broadway </E2:UDBKL> musical , starred the MGM songbird team of <E1:UDBKL> Howard Keel </E1:UDBKL> and Kathryn Grayson as the leads , supported by Ann Miller , Keenan Wynn , Bobby Van , James Whitmore , Kurt Kasznar and Tommy Rall ."
"physical","23","9","The film , adapted from the popular Cole Porter <E2:UDBKL> Broadway </E2:UDBKL> musical , starred the MGM songbird team of Howard Keel and <E1:UDBKL> Kathryn Grayson </E1:UDBKL> as the leads , supported by Ann Miller , Keenan Wynn , Bobby Van , James Whitmore , Kurt Kasznar and Tommy Rall ."
"physical","31","9","The film , adapted from the popular Cole Porter <E2:UDBKL> Broadway </E2:UDBKL> musical , starred the MGM songbird team of Howard Keel and Kathryn Grayson as the leads , supported by <E1:UDBKL> Ann Miller </E1:UDBKL> , Keenan Wynn , Bobby Van , James Whitmore , Kurt Kasznar and Tommy Rall ."
"physical","34","9","The film , adapted from the popular Cole Porter <E2:UDBKL> Broadway </E2:UDBKL> musical , starred the MGM songbird team of Howard Keel and Kathryn Grayson as the leads , supported by Ann Miller , <E1:UDBKL> Keenan Wynn </E1:UDBKL> , Bobby Van , James Whitmore , Kurt Kasznar and Tommy Rall ."
"physical","37","9","The film , adapted from the popular Cole Porter <E2:UDBKL> Broadway </E2:UDBKL> musical , starred the MGM songbird team of Howard Keel and Kathryn Grayson as the leads , supported by Ann Miller , Keenan Wynn , <E1:UDBKL> Bobby Van </E1:UDBKL> , James Whitmore , Kurt Kasznar and Tommy Rall ."
"physical","40","9","The film , adapted from the popular Cole Porter <E2:UDBKL> Broadway </E2:UDBKL> musical , starred the MGM songbird team of Howard Keel and Kathryn Grayson as the leads , supported by Ann Miller , Keenan Wynn , Bobby Van , <E1:UDBKL> James Whitmore </E1:UDBKL> , Kurt Kasznar and Tommy Rall ."
"physical","43","9","The film , adapted from the popular Cole Porter <E2:UDBKL> Broadway </E2:UDBKL> musical , starred the MGM songbird team of Howard Keel and Kathryn Grayson as the leads , supported by Ann Miller , Keenan Wynn , Bobby Van , James Whitmore , <E1:UDBKL> Kurt Kasznar </E1:UDBKL> and Tommy Rall ."
"physical","46","9","The film , adapted from the popular Cole Porter <E2:UDBKL> Broadway </E2:UDBKL> musical , starred the MGM songbird team of Howard Keel and Kathryn Grayson as the leads , supported by Ann Miller , Keenan Wynn , Bobby Van , James Whitmore , Kurt Kasznar and <E1:UDBKL> Tommy Rall </E1:UDBKL> ."
"named","10","4","As such , traditional <E2:proteins> gradient descent </E2:proteins> ( or <E1:proteins> Stochastic gradient descent </E1:proteins> ) methods can be adapted , where of taking a step in the direction of the function 's gradient , a step is taken in the direction of a vector selected from the function 's sub-gradient ."
"related-to","0","6","<E1:proteins> MLPs </E1:proteins> were a popular <E2:UDBKL> machine learning </E2:UDBKL> solution in the 1980s , finding applications in diverse fields such as speech recognition , image recognition , and machine translation software , Neural networks ."
"related-to","20","0","<E2:proteins> MLPs </E2:proteins> were a popular machine learning solution in the 1980s , finding applications in diverse fields such as <E1:UDBKL> speech recognition </E1:UDBKL> , image recognition , and machine translation software , Neural networks ."
"related-to","23","0","<E2:proteins> MLPs </E2:proteins> were a popular machine learning solution in the 1980s , finding applications in diverse fields such as speech recognition , <E1:UDBKL> image recognition </E1:UDBKL> , and machine translation software , Neural networks ."
"related-to","27","0","<E2:proteins> MLPs </E2:proteins> were a popular machine learning solution in the 1980s , finding applications in diverse fields such as speech recognition , image recognition , and <E1:UDBKL> machine translation </E1:UDBKL> software , Neural networks ."
"part-of","31","0","<E2:proteins> MLPs </E2:proteins> were a popular machine learning solution in the 1980s , finding applications in diverse fields such as speech recognition , image recognition , and machine translation software , <E1:proteins> Neural networks </E1:proteins> ."
"physical","0","8","<E1:author> Allen </E1:author> received his Ph.D. from the <E2:UDBKL> University of Toronto </E2:UDBKL> in 1979 , under the supervision of C. Raymond Perrault ,"
"origin","5","0","<E2:author> Allen </E2:author> received his <E1:proteins> Ph.D. </E1:proteins> from the University of Toronto in 1979 , under the supervision of C. Raymond Perrault ,"
"role","18","0","<E2:author> Allen </E2:author> received his Ph.D. from the University of Toronto in 1979 , under the supervision of <E1:author> C. Raymond Perrault </E1:author> ,"
"role","0","7","<E1:proteins> OpenCV </E1:proteins> supports some models from <E2:UDBKL> deep learning frameworks </E2:UDBKL> like TensorFlow , Torch , PyTorch ( after converting to an ONNX model ) and Caffe according to a defined list of supported layers ."
"artifact","11","5","OpenCV supports some models from <E2:UDBKL> deep learning frameworks </E2:UDBKL> like <E1:proteins> TensorFlow </E1:proteins> , Torch , PyTorch ( after converting to an ONNX model ) and Caffe according to a defined list of supported layers ."
"artifact","13","5","OpenCV supports some models from <E2:UDBKL> deep learning frameworks </E2:UDBKL> like TensorFlow , <E1:proteins> Torch </E1:proteins> , PyTorch ( after converting to an ONNX model ) and Caffe according to a defined list of supported layers ."
"artifact","15","5","OpenCV supports some models from <E2:UDBKL> deep learning frameworks </E2:UDBKL> like TensorFlow , Torch , <E1:proteins> PyTorch </E1:proteins> ( after converting to an ONNX model ) and Caffe according to a defined list of supported layers ."
"part-of","13","21","OpenCV supports some models from deep learning frameworks like TensorFlow , Torch , <E1:proteins> PyTorch </E1:proteins> ( after converting to an <E2:proteins> ONNX </E2:proteins> model ) and Caffe according to a defined list of supported layers ."
"part-of","25","5","OpenCV supports some models from <E2:UDBKL> deep learning frameworks </E2:UDBKL> like TensorFlow , Torch , PyTorch ( after converting to an ONNX model ) and <E1:proteins> Caffe </E1:proteins> according to a defined list of supported layers ."
"role","2","10","Previously , <E1:author> Christensen </E1:author> was the Founding Chairman of <E2:UDBKL> European Robotics Research Network </E2:UDBKL> ( EURON ) and an IEEE Robotics and Automation Society Distinguished Lecturer in Robotics ."
"role","2","19","Previously , <E1:author> Christensen </E1:author> was the Founding Chairman of European Robotics Research Network ( EURON ) and an <E2:UDBKL> IEEE Robotics and Automation Society </E2:UDBKL> Distinguished Lecturer in Robotics ."
"role","2","27","Previously , <E1:author> Christensen </E1:author> was the Founding Chairman of European Robotics Research Network ( EURON ) and an IEEE Robotics and Automation Society Distinguished Lecturer in <E2:UDBKL> Robotics </E2:UDBKL> ."
"named","15","8","Previously , Christensen was the Founding Chairman of <E2:UDBKL> European Robotics Research Network </E2:UDBKL> ( <E1:UDBKL> EURON </E1:UDBKL> ) and an IEEE Robotics and Automation Society Distinguished Lecturer in Robotics ."
"physical","10","16","He received his master 's degree in mathematics from the <E1:UDBKL> Samarkand State University </E1:UDBKL> , <E2:UDBKL> Samarkand </E2:UDBKL> , Uzbek Soviet Socialist Republic in 1958 and Ph.D in statistics at the Institute of Control Sciences , Moscow in 1964 ."
"physical","14","18","He received his master 's degree in mathematics from the Samarkand State University , <E1:UDBKL> Samarkand </E1:UDBKL> , <E2:UDBKL> Uzbek Soviet Socialist Republic </E2:UDBKL> in 1958 and Ph.D in statistics at the Institute of Control Sciences , Moscow in 1964 ."
"named","23","27","He received his master 's degree in mathematics from the Samarkand State University , Samarkand , Uzbek Soviet Socialist Republic in 1958 and <E1:proteins> Ph.D </E1:proteins> in <E2:UDBKL> statistics </E2:UDBKL> at the Institute of Control Sciences , Moscow in 1964 ."
"physical","28","35","He received his master 's degree in mathematics from the Samarkand State University , Samarkand , Uzbek Soviet Socialist Republic in 1958 and Ph.D in statistics at the <E1:UDBKL> Institute of Control Sciences </E1:UDBKL> , <E2:UDBKL> Moscow </E2:UDBKL> in 1964 ."
"related-to","6","35","Increasingly , however , work at <E1:UDBKL> Cycorp </E1:UDBKL> involves giving the Cyc system the ability to communicate with end users in natural language , and to assist with the ongoing knowledge formation process via <E2:UDBKL> machine learning </E2:UDBKL> and natural language understanding ."
"related-to","6","38","Increasingly , however , work at <E1:UDBKL> Cycorp </E1:UDBKL> involves giving the Cyc system the ability to communicate with end users in natural language , and to assist with the ongoing knowledge formation process via machine learning and <E2:UDBKL> natural language understanding </E2:UDBKL> ."
"named","12","6","Increasingly , however , work at <E2:UDBKL> Cycorp </E2:UDBKL> involves giving the <E1:proteins> Cyc system </E1:proteins> the ability to communicate with end users in natural language , and to assist with the ongoing knowledge formation process via machine learning and natural language understanding ."
"part-of","11","3","In 1979 a <E2:proteins> Micromouse competition </E2:proteins> was organized by the <E1:UDBKL> IEEE </E1:UDBKL> as shown in the Spectrum magazine ."
"part-of","16","3","In 1979 a <E2:proteins> Micromouse competition </E2:proteins> was organized by the IEEE as shown in the <E1:proteins> Spectrum </E1:proteins> magazine ."
"related-to","1","9","The <E1:proteins> Gabor space </E1:proteins> is very useful in <E2:UDBKL> image processing </E2:UDBKL> applications such as optical character recognition , iris recognition and fingerprint recognition ."
"part-of","14","7","The Gabor space is very useful in <E2:UDBKL> image processing </E2:UDBKL> applications such as <E1:UDBKL> optical character recognition </E1:UDBKL> , iris recognition and fingerprint recognition ."
"part-of","18","7","The Gabor space is very useful in <E2:UDBKL> image processing </E2:UDBKL> applications such as optical character recognition , <E1:UDBKL> iris recognition </E1:UDBKL> and fingerprint recognition ."
"part-of","21","7","The Gabor space is very useful in <E2:UDBKL> image processing </E2:UDBKL> applications such as optical character recognition , iris recognition and <E1:UDBKL> fingerprint recognition </E1:UDBKL> ."
"part-of","8","19","In recent research , kernel-based methods such as <E1:proteins> support vector machine </E1:proteins> s have shown superior performance in <E2:UDBKL> supervised </E2:UDBKL> ."
"related-to","22","34","To illustrate the basic principles of bagging , below is an analysis on the relationship between ozone and temperature ( data from <E1:author> Rousseeuw </E1:author> and Leroy ( 1986 ) , analysis done in <E2:proteins> R </E2:proteins> ) ."
"related-to","24","34","To illustrate the basic principles of bagging , below is an analysis on the relationship between ozone and temperature ( data from Rousseeuw and <E1:author> Leroy </E1:author> ( 1986 ) , analysis done in <E2:proteins> R </E2:proteins> ) ."
"named","13","0","<E2:UDBKL> Denso Wave </E2:UDBKL> is a subsidiary that produces automatic identification products ( <E1:proteins> bar-code reader </E1:proteins> s and related products ) , industrial robot s and programmable logic controller s ."
"named","21","0","<E2:UDBKL> Denso Wave </E2:UDBKL> is a subsidiary that produces automatic identification products ( bar-code reader s and related products ) , <E1:proteins> industrial robot </E1:proteins> s and programmable logic controller s ."
"named","25","0","<E2:UDBKL> Denso Wave </E2:UDBKL> is a subsidiary that produces automatic identification products ( bar-code reader s and related products ) , industrial robot s and <E1:proteins> programmable logic controller </E1:proteins> s ."
"role","1","17","Where <E1:UDBKL> Bilingual evaluation understudy </E1:UDBKL> simply calculates n-gram precision adding equal weight to each one , <E2:UDBKL> NIST </E2:UDBKL> also calculates how informative a particular n-gram is ."
"named","8","1","Where <E2:UDBKL> Bilingual evaluation understudy </E2:UDBKL> simply calculates <E1:UDBKL> n-gram precision </E1:UDBKL> adding equal weight to each one , NIST also calculates how informative a particular n-gram is ."
"part-of","24","15","Where Bilingual evaluation understudy simply calculates n-gram precision adding equal weight to each one , <E2:UDBKL> NIST </E2:UDBKL> also calculates how informative a particular <E1:proteins> n-gram </E1:proteins> is ."
"named","24","19","The Audio Engineering Society recommends 48 kHz sampling rate for most applications but gives recognition to 44.1 kHz for <E2:proteins> Compact Disc </E2:proteins> ( <E1:proteins> CD </E1:proteins> ) and other consumer uses , 32 kHz for transmission-related applications , and 96 kHz for higher bandwidth or relaxed anti-aliasing filter ing ."
"role","27","38","In red-green anaglyph , the audience was presented three reels of tests , which included rural scenes , test shots of Marie Doro , a segment of <E1:UDBKL> John B. Mason </E1:UDBKL> playing a number of passages from <E2:UDBKL> Jim the Penman </E2:UDBKL> ( a film released by Famous Players-Lasky that year , but not in 3D ) , Oriental dancers , and a reel of footage of Niagara Falls ."
"origin","46","36","In red-green anaglyph , the audience was presented three reels of tests , which included rural scenes , test shots of Marie Doro , a segment of John B. Mason playing a number of passages from <E2:UDBKL> Jim the Penman </E2:UDBKL> ( a film released by <E1:UDBKL> Famous Players-Lasky </E1:UDBKL> that year , but not in 3D ) , Oriental dancers , and a reel of footage of Niagara Falls ."
"related-to","10","4","Other typical applications of <E2:UDBKL> pattern recognition </E2:UDBKL> techniques are <E1:UDBKL> automatic speech recognition </E1:UDBKL> , classification of text into several categories ( e.g. , spam / non-spam email messages ) , the handwriting recognition on postal envelopes , automatic recognition of images of human faces , or handwriting image extraction from medical forms ."
"related-to","14","4","Other typical applications of <E2:UDBKL> pattern recognition </E2:UDBKL> techniques are automatic speech recognition , <E1:UDBKL> classification of text into several categories </E1:UDBKL> ( e.g. , spam / non-spam email messages ) , the handwriting recognition on postal envelopes , automatic recognition of images of human faces , or handwriting image extraction from medical forms ."
"named","31","4","Other typical applications of <E2:UDBKL> pattern recognition </E2:UDBKL> techniques are automatic speech recognition , classification of text into several categories ( e.g. , spam / non-spam email messages ) , the <E1:UDBKL> handwriting recognition on postal envelopes </E1:UDBKL> , automatic recognition of images of human faces , or handwriting image extraction from medical forms ."
"related-to","37","4","Other typical applications of <E2:UDBKL> pattern recognition </E2:UDBKL> techniques are automatic speech recognition , classification of text into several categories ( e.g. , spam / non-spam email messages ) , the handwriting recognition on postal envelopes , <E1:UDBKL> automatic recognition of images of human faces </E1:UDBKL> , or handwriting image extraction from medical forms ."
"named","46","4","Other typical applications of <E2:UDBKL> pattern recognition </E2:UDBKL> techniques are automatic speech recognition , classification of text into several categories ( e.g. , spam / non-spam email messages ) , the handwriting recognition on postal envelopes , automatic recognition of images of human faces , or <E1:UDBKL> handwriting image extraction from medical forms </E1:UDBKL> ."
"related-to","15","0","<E2:proteins> Artificial neural networks </E2:proteins> have been used on a variety of tasks , including <E1:UDBKL> computer vision </E1:UDBKL> , speech recognition , machine translation , social network filtering , playing board and video games and medical diagnosis ."
"related-to","18","0","<E2:proteins> Artificial neural networks </E2:proteins> have been used on a variety of tasks , including computer vision , <E1:UDBKL> speech recognition </E1:UDBKL> , machine translation , social network filtering , playing board and video games and medical diagnosis ."
"related-to","21","0","<E2:proteins> Artificial neural networks </E2:proteins> have been used on a variety of tasks , including computer vision , speech recognition , <E1:UDBKL> machine translation </E1:UDBKL> , social network filtering , playing board and video games and medical diagnosis ."
"related-to","24","0","<E2:proteins> Artificial neural networks </E2:proteins> have been used on a variety of tasks , including computer vision , speech recognition , machine translation , <E1:UDBKL> social network filtering </E1:UDBKL> , playing board and video games and medical diagnosis ."
"related-to","28","0","<E2:proteins> Artificial neural networks </E2:proteins> have been used on a variety of tasks , including computer vision , speech recognition , machine translation , social network filtering , <E1:UDBKL> playing board and video games </E1:UDBKL> and medical diagnosis ."
"related-to","34","0","<E2:proteins> Artificial neural networks </E2:proteins> have been used on a variety of tasks , including computer vision , speech recognition , machine translation , social network filtering , playing board and video games and <E1:UDBKL> medical diagnosis </E1:UDBKL> ."
"artifact","6","2","Examples include <E2:UDBKL> Salford Systems </E2:UDBKL> <E1:proteins> CART </E1:proteins> ( which licensed the proprietary code of the original CART authors ) , IBM SPSS Modeler , RapidMiner , SAS Enterprise Miner , Matlab , R ( an open-source software environment for statistical computing , which includes several CART implementations such as rpart , party and randomForest packages ) , Weka ( a free and open-source data-mining suite , contains many decision tree algorithms ) , Orange , KNIME , Microsoft SQL Server programming language ) ."
"named","4","16","Examples include Salford Systems <E1:proteins> CART </E1:proteins> ( which licensed the proprietary code of the original <E2:proteins> CART </E2:proteins> authors ) , IBM SPSS Modeler , RapidMiner , SAS Enterprise Miner , Matlab , R ( an open-source software environment for statistical computing , which includes several CART implementations such as rpart , party and randomForest packages ) , Weka ( a free and open-source data-mining suite , contains many decision tree algorithms ) , Orange , KNIME , Microsoft SQL Server programming language ) ."
"related-to","4","45","Examples include Salford Systems <E1:proteins> CART </E1:proteins> ( which licensed the proprietary code of the original CART authors ) , IBM SPSS Modeler , RapidMiner , SAS Enterprise Miner , Matlab , R ( an open-source software environment for statistical computing , which includes several <E2:proteins> CART </E2:proteins> implementations such as rpart , party and randomForest packages ) , Weka ( a free and open-source data-mining suite , contains many decision tree algorithms ) , Orange , KNIME , Microsoft SQL Server programming language ) ."
"part-of","30","39","Examples include Salford Systems CART ( which licensed the proprietary code of the original CART authors ) , IBM SPSS Modeler , RapidMiner , SAS Enterprise Miner , Matlab , <E1:proteins> R </E1:proteins> ( an open-source software environment for <E2:UDBKL> statistical computing </E2:UDBKL> , which includes several CART implementations such as rpart , party and randomForest packages ) , Weka ( a free and open-source data-mining suite , contains many decision tree algorithms ) , Orange , KNIME , Microsoft SQL Server programming language ) ."
"part-of","49","30","Examples include Salford Systems CART ( which licensed the proprietary code of the original CART authors ) , IBM SPSS Modeler , RapidMiner , SAS Enterprise Miner , Matlab , <E2:proteins> R </E2:proteins> ( an open-source software environment for statistical computing , which includes several CART implementations such as <E1:proteins> rpart </E1:proteins> , party and randomForest packages ) , Weka ( a free and open-source data-mining suite , contains many decision tree algorithms ) , Orange , KNIME , Microsoft SQL Server programming language ) ."
"part-of","49","43","Examples include Salford Systems CART ( which licensed the proprietary code of the original CART authors ) , IBM SPSS Modeler , RapidMiner , SAS Enterprise Miner , Matlab , R ( an open-source software environment for statistical computing , which includes several <E2:proteins> CART </E2:proteins> implementations such as <E1:proteins> rpart </E1:proteins> , party and randomForest packages ) , Weka ( a free and open-source data-mining suite , contains many decision tree algorithms ) , Orange , KNIME , Microsoft SQL Server programming language ) ."
"part-of","51","30","Examples include Salford Systems CART ( which licensed the proprietary code of the original CART authors ) , IBM SPSS Modeler , RapidMiner , SAS Enterprise Miner , Matlab , <E2:proteins> R </E2:proteins> ( an open-source software environment for statistical computing , which includes several CART implementations such as rpart , <E1:proteins> party </E1:proteins> and randomForest packages ) , Weka ( a free and open-source data-mining suite , contains many decision tree algorithms ) , Orange , KNIME , Microsoft SQL Server programming language ) ."
"part-of","51","43","Examples include Salford Systems CART ( which licensed the proprietary code of the original CART authors ) , IBM SPSS Modeler , RapidMiner , SAS Enterprise Miner , Matlab , R ( an open-source software environment for statistical computing , which includes several <E2:proteins> CART </E2:proteins> implementations such as rpart , <E1:proteins> party </E1:proteins> and randomForest packages ) , Weka ( a free and open-source data-mining suite , contains many decision tree algorithms ) , Orange , KNIME , Microsoft SQL Server programming language ) ."
"part-of","53","30","Examples include Salford Systems CART ( which licensed the proprietary code of the original CART authors ) , IBM SPSS Modeler , RapidMiner , SAS Enterprise Miner , Matlab , <E2:proteins> R </E2:proteins> ( an open-source software environment for statistical computing , which includes several CART implementations such as rpart , party and <E1:proteins> randomForest </E1:proteins> packages ) , Weka ( a free and open-source data-mining suite , contains many decision tree algorithms ) , Orange , KNIME , Microsoft SQL Server programming language ) ."
"part-of","53","43","Examples include Salford Systems CART ( which licensed the proprietary code of the original CART authors ) , IBM SPSS Modeler , RapidMiner , SAS Enterprise Miner , Matlab , R ( an open-source software environment for statistical computing , which includes several <E2:proteins> CART </E2:proteins> implementations such as rpart , party and <E1:proteins> randomForest </E1:proteins> packages ) , Weka ( a free and open-source data-mining suite , contains many decision tree algorithms ) , Orange , KNIME , Microsoft SQL Server programming language ) ."
"named","55","63","Examples include Salford Systems CART ( which licensed the proprietary code of the original CART authors ) , IBM SPSS Modeler , RapidMiner , SAS Enterprise Miner , Matlab , R ( an open-source software environment for statistical computing , which includes several CART implementations such as rpart , party and randomForest packages ) , <E1:proteins> Weka </E1:proteins> ( a free and open-source <E2:UDBKL> data-mining </E2:UDBKL> suite , contains many decision tree algorithms ) , Orange , KNIME , Microsoft SQL Server programming language ) ."
"part-of","68","55","Examples include Salford Systems CART ( which licensed the proprietary code of the original CART authors ) , IBM SPSS Modeler , RapidMiner , SAS Enterprise Miner , Matlab , R ( an open-source software environment for statistical computing , which includes several CART implementations such as rpart , party and randomForest packages ) , <E2:proteins> Weka </E2:proteins> ( a free and open-source data-mining suite , contains many <E1:proteins> decision tree </E1:proteins> algorithms ) , Orange , KNIME , Microsoft SQL Server programming language ) ."
"artifact","0","12","<E1:proteins> Linear predictive coding </E1:proteins> ( LPC ) was first developed by <E2:author> Fumitada Itakura </E2:author> of Nagoya University and Shuzo Saito of Nippon Telegraph and Telephone ( NTT ) in 1966 , and then further developed by Bishnu S. Atal and Manfred R. Schroeder at Bell Labs during the early-to-mid-1970s , becoming a basis for the first speech synthesizer DSP chips in the late 1970s ."
"artifact","0","18","<E1:proteins> Linear predictive coding </E1:proteins> ( LPC ) was first developed by Fumitada Itakura of Nagoya University and <E2:author> Shuzo Saito </E2:author> of Nippon Telegraph and Telephone ( NTT ) in 1966 , and then further developed by Bishnu S. Atal and Manfred R. Schroeder at Bell Labs during the early-to-mid-1970s , becoming a basis for the first speech synthesizer DSP chips in the late 1970s ."
"role","0","36","<E1:proteins> Linear predictive coding </E1:proteins> ( LPC ) was first developed by Fumitada Itakura of Nagoya University and Shuzo Saito of Nippon Telegraph and Telephone ( NTT ) in 1966 , and then further developed by <E2:author> Bishnu S. Atal </E2:author> and Manfred R. Schroeder at Bell Labs during the early-to-mid-1970s , becoming a basis for the first speech synthesizer DSP chips in the late 1970s ."
"role","0","40","<E1:proteins> Linear predictive coding </E1:proteins> ( LPC ) was first developed by Fumitada Itakura of Nagoya University and Shuzo Saito of Nippon Telegraph and Telephone ( NTT ) in 1966 , and then further developed by Bishnu S. Atal and <E2:author> Manfred R. Schroeder </E2:author> at Bell Labs during the early-to-mid-1970s , becoming a basis for the first speech synthesizer DSP chips in the late 1970s ."
"named","6","0","<E2:proteins> Linear predictive coding </E2:proteins> ( <E1:proteins> LPC </E1:proteins> ) was first developed by Fumitada Itakura of Nagoya University and Shuzo Saito of Nippon Telegraph and Telephone ( NTT ) in 1966 , and then further developed by Bishnu S. Atal and Manfred R. Schroeder at Bell Labs during the early-to-mid-1970s , becoming a basis for the first speech synthesizer DSP chips in the late 1970s ."
"physical","10","15","Linear predictive coding ( LPC ) was first developed by <E1:author> Fumitada Itakura </E1:author> of <E2:UDBKL> Nagoya University </E2:UDBKL> and Shuzo Saito of Nippon Telegraph and Telephone ( NTT ) in 1966 , and then further developed by Bishnu S. Atal and Manfred R. Schroeder at Bell Labs during the early-to-mid-1970s , becoming a basis for the first speech synthesizer DSP chips in the late 1970s ."
"physical","16","21","Linear predictive coding ( LPC ) was first developed by Fumitada Itakura of Nagoya University and <E1:author> Shuzo Saito </E1:author> of <E2:UDBKL> Nippon Telegraph and Telephone </E2:UDBKL> ( NTT ) in 1966 , and then further developed by Bishnu S. Atal and Manfred R. Schroeder at Bell Labs during the early-to-mid-1970s , becoming a basis for the first speech synthesizer DSP chips in the late 1970s ."
"named","26","19","Linear predictive coding ( LPC ) was first developed by Fumitada Itakura of Nagoya University and Shuzo Saito of <E2:UDBKL> Nippon Telegraph and Telephone </E2:UDBKL> ( <E1:UDBKL> NTT </E1:UDBKL> ) in 1966 , and then further developed by Bishnu S. Atal and Manfred R. Schroeder at Bell Labs during the early-to-mid-1970s , becoming a basis for the first speech synthesizer DSP chips in the late 1970s ."
"physical","34","44","Linear predictive coding ( LPC ) was first developed by Fumitada Itakura of Nagoya University and Shuzo Saito of Nippon Telegraph and Telephone ( NTT ) in 1966 , and then further developed by <E1:author> Bishnu S. Atal </E1:author> and Manfred R. Schroeder at <E2:UDBKL> Bell Labs </E2:UDBKL> during the early-to-mid-1970s , becoming a basis for the first speech synthesizer DSP chips in the late 1970s ."
"physical","38","44","Linear predictive coding ( LPC ) was first developed by Fumitada Itakura of Nagoya University and Shuzo Saito of Nippon Telegraph and Telephone ( NTT ) in 1966 , and then further developed by Bishnu S. Atal and <E1:author> Manfred R. Schroeder </E1:author> at <E2:UDBKL> Bell Labs </E2:UDBKL> during the early-to-mid-1970s , becoming a basis for the first speech synthesizer DSP chips in the late 1970s ."
"part-of","56","0","<E2:proteins> Linear predictive coding </E2:proteins> ( LPC ) was first developed by Fumitada Itakura of Nagoya University and Shuzo Saito of Nippon Telegraph and Telephone ( NTT ) in 1966 , and then further developed by Bishnu S. Atal and Manfred R. Schroeder at Bell Labs during the early-to-mid-1970s , becoming a basis for the first <E1:proteins> speech synthesizer DSP chips </E1:proteins> in the late 1970s ."
"named","9","1","An <E2:UDBKL> F-score </E2:UDBKL> is a combination of the <E1:UDBKL> precision </E1:UDBKL> and the recall , providing a single score ."
"named","12","1","An <E2:UDBKL> F-score </E2:UDBKL> is a combination of the precision and the <E1:UDBKL> recall </E1:UDBKL> , providing a single score ."
"related-to","10","0","<E2:UDBKL> Image analysis </E2:UDBKL> tasks can be as simple as <E1:UDBKL> reading bar code d tags </E1:UDBKL> or as sophisticated as facial recognition system ."
"part-of","19","0","<E2:UDBKL> Image analysis </E2:UDBKL> tasks can be as simple as reading bar code d tags or as sophisticated as <E1:proteins> facial recognition system </E1:proteins> ."
"part-of","34","24","The special case of linear support-vector machines can be solved more efficiently by the same kind of algorithms to optimize its close cousin , <E2:proteins> logistic regression </E2:proteins> ; this class of algorithms includes <E1:proteins> Stochastic gradient descent </E1:proteins> ( e.g. , PEGASOS ) ."
"named","40","32","The special case of linear support-vector machines can be solved more efficiently by the same kind of algorithms to optimize its close cousin , logistic regression ; this class of algorithms includes <E2:proteins> Stochastic gradient descent </E2:proteins> ( e.g. , <E1:proteins> PEGASOS </E1:proteins> ) ."
"related-to","1","6","When <E1:proteins> Siri </E1:proteins> on an <E2:proteins> iOS </E2:proteins> device is asked Do you have a pet ? , one the responses is I used to have an AIBO ."
"named","7","1","In <E2:UDBKL> information retrieval </E2:UDBKL> , the <E1:UDBKL> positive predictive value </E1:UDBKL> is called precision , and sensitivity is called recall ."
"named","12","5","In information retrieval , the <E2:UDBKL> positive predictive value </E2:UDBKL> is called <E1:UDBKL> precision </E1:UDBKL> , and sensitivity is called recall ."
"named","15","1","In <E2:UDBKL> information retrieval </E2:UDBKL> , the positive predictive value is called precision , and <E1:UDBKL> sensitivity </E1:UDBKL> is called recall ."
"named","18","13","In information retrieval , the positive predictive value is called precision , and <E2:UDBKL> sensitivity </E2:UDBKL> is called <E1:UDBKL> recall </E1:UDBKL> ."
"named","15","10","In particular , his research focused on areas such as <E2:UDBKL> text mining </E2:UDBKL> ( <E1:UDBKL> extraction </E1:UDBKL> , categorization , novelty detection ) and in new theoretical frameworks such as a unified utility-based theory bridging information retrieval , Automatic summarization , free-text Question Answering and related tasks ."
"named","17","10","In particular , his research focused on areas such as <E2:UDBKL> text mining </E2:UDBKL> ( extraction , <E1:UDBKL> categorization </E1:UDBKL> , novelty detection ) and in new theoretical frameworks such as a unified utility-based theory bridging information retrieval , Automatic summarization , free-text Question Answering and related tasks ."
"named","19","10","In particular , his research focused on areas such as <E2:UDBKL> text mining </E2:UDBKL> ( extraction , categorization , <E1:UDBKL> novelty detection </E1:UDBKL> ) and in new theoretical frameworks such as a unified utility-based theory bridging information retrieval , Automatic summarization , free-text Question Answering and related tasks ."
"part-of","7","0","<E2:proteins> Delta robot </E2:proteins> s have base-mounted <E1:proteins> rotary actuator </E1:proteins> s that move a light , stiff , parallelogram arm ."
"part-of","17","0","<E2:proteins> Delta robot </E2:proteins> s have base-mounted rotary actuator s that move a light , stiff , <E1:proteins> parallelogram arm </E1:proteins> ."
"named","31","2","The actual <E2:UDBKL> data mining </E2:UDBKL> task is the semi-automatic or automatic analysis of large quantities of data to extract unknown , interesting patterns such as groups of data records ( <E1:UDBKL> cluster analysis </E1:UDBKL> ) , unusual records ( anomaly detection ) , and dependencies ( association rule mining , sequential pattern mining ) ."
"named","38","2","The actual <E2:UDBKL> data mining </E2:UDBKL> task is the semi-automatic or automatic analysis of large quantities of data to extract unknown , interesting patterns such as groups of data records ( cluster analysis ) , unusual records ( <E1:UDBKL> anomaly detection </E1:UDBKL> ) , and dependencies ( association rule mining , sequential pattern mining ) ."
"named","45","2","The actual <E2:UDBKL> data mining </E2:UDBKL> task is the semi-automatic or automatic analysis of large quantities of data to extract unknown , interesting patterns such as groups of data records ( cluster analysis ) , unusual records ( anomaly detection ) , and dependencies ( <E1:UDBKL> association rule mining </E1:UDBKL> , sequential pattern mining ) ."
"named","49","2","The actual <E2:UDBKL> data mining </E2:UDBKL> task is the semi-automatic or automatic analysis of large quantities of data to extract unknown , interesting patterns such as groups of data records ( cluster analysis ) , unusual records ( anomaly detection ) , and dependencies ( association rule mining , <E1:UDBKL> sequential pattern mining </E1:UDBKL> ) ."
"named","2","7","For a <E1:proteins> recommender system </E1:proteins> , <E2:UDBKL> sentiment analysis </E2:UDBKL> has been proven to be a valuable technique ."
"related-to","4","14","By chance , the <E1:proteins> Germans </E1:proteins> had chosen the operating frequency of the <E2:proteins> Wotan </E2:proteins> system very badly ; it operated on 45 MHz , which just happened to be the frequency of the powerful-but-dormant BBC television transmitter at Alexandra Palace ."
"physical","33","39","By chance , the Germans had chosen the operating frequency of the Wotan system very badly ; it operated on 45 MHz , which just happened to be the frequency of the powerful-but-dormant <E1:UDBKL> BBC </E1:UDBKL> television transmitter at <E2:UDBKL> Alexandra Palace </E2:UDBKL> ."
"part-of","15","11","In Semantic Web applications , and in relatively popular applications of <E2:proteins> RDF </E2:proteins> like <E1:proteins> RSS </E1:proteins> and FOAF ( Friend a Friend ) , resources tend to be represented by URIs that intentionally denote , and can be used to access , actual data on the World Wide Web ."
"part-of","17","11","In Semantic Web applications , and in relatively popular applications of <E2:proteins> RDF </E2:proteins> like RSS and <E1:proteins> FOAF </E1:proteins> ( Friend a Friend ) , resources tend to be represented by URIs that intentionally denote , and can be used to access , actual data on the World Wide Web ."
"named","19","15","In Semantic Web applications , and in relatively popular applications of RDF like RSS and <E2:proteins> FOAF </E2:proteins> ( <E1:proteins> Friend a Friend </E1:proteins> ) , resources tend to be represented by URIs that intentionally denote , and can be used to access , actual data on the World Wide Web ."
"part-of","30","11","In Semantic Web applications , and in relatively popular applications of <E2:proteins> RDF </E2:proteins> like RSS and FOAF ( Friend a Friend ) , resources tend to be represented by <E1:proteins> URIs </E1:proteins> that intentionally denote , and can be used to access , actual data on the World Wide Web ."
"part-of","20","6","Starting as a curiosity , the <E2:proteins> speech system of Apple Macintosh </E2:proteins> has evolved into a fully supported program <E1:proteins> PlainTalk </E1:proteins> , for people with vision problems ."
"part-of","11","7","Other areas of usage for ontologies within <E2:UDBKL> NLP </E2:UDBKL> include <E1:UDBKL> information retrieval </E1:UDBKL> , information extraction and automatic summarization ."
"part-of","14","7","Other areas of usage for ontologies within <E2:UDBKL> NLP </E2:UDBKL> include information retrieval , <E1:UDBKL> information extraction </E1:UDBKL> and automatic summarization ."
"part-of","17","7","Other areas of usage for ontologies within <E2:UDBKL> NLP </E2:UDBKL> include information retrieval , information extraction and <E1:UDBKL> automatic summarization </E1:UDBKL> ."
"artifact","7","2","Recently , <E2:UDBKL> Google </E2:UDBKL> announced that <E1:proteins> Google Translate </E1:proteins> translates roughly enough text to fill 1 million books in one day ( 2012 ) ."
"temporal","13","4","As part of the <E2:UDBKL> 2006 European Conference on Computer Vision </E2:UDBKL> ( <E1:UDBKL> ECCV </E1:UDBKL> ) , Dalal and Triggs teamed up with Cordelia Schmid to apply HOG detectors to the problem of human detection in films and videos ."
"role","16","4","As part of the <E2:UDBKL> 2006 European Conference on Computer Vision </E2:UDBKL> ( ECCV ) , <E1:author> Dalal </E1:author> and Triggs teamed up with Cordelia Schmid to apply HOG detectors to the problem of human detection in films and videos ."
"role","14","22","As part of the 2006 European Conference on Computer Vision ( ECCV ) , <E1:author> Dalal </E1:author> and Triggs teamed up with <E2:author> Cordelia Schmid </E2:author> to apply HOG detectors to the problem of human detection in films and videos ."
"related-to","14","26","As part of the 2006 European Conference on Computer Vision ( ECCV ) , <E1:author> Dalal </E1:author> and Triggs teamed up with Cordelia Schmid to apply <E2:proteins> HOG detectors </E2:proteins> to the problem of human detection in films and videos ."
"temporal","18","4","As part of the <E2:UDBKL> 2006 European Conference on Computer Vision </E2:UDBKL> ( ECCV ) , Dalal and <E1:author> Triggs </E1:author> teamed up with Cordelia Schmid to apply HOG detectors to the problem of human detection in films and videos ."
"role","16","22","As part of the 2006 European Conference on Computer Vision ( ECCV ) , Dalal and <E1:author> Triggs </E1:author> teamed up with <E2:author> Cordelia Schmid </E2:author> to apply HOG detectors to the problem of human detection in films and videos ."
"related-to","16","26","As part of the 2006 European Conference on Computer Vision ( ECCV ) , Dalal and <E1:author> Triggs </E1:author> teamed up with Cordelia Schmid to apply <E2:proteins> HOG detectors </E2:proteins> to the problem of human detection in films and videos ."
"role","22","4","As part of the <E2:UDBKL> 2006 European Conference on Computer Vision </E2:UDBKL> ( ECCV ) , Dalal and Triggs teamed up with <E1:author> Cordelia Schmid </E1:author> to apply HOG detectors to the problem of human detection in films and videos ."
"related-to","20","26","As part of the 2006 European Conference on Computer Vision ( ECCV ) , Dalal and Triggs teamed up with <E1:author> Cordelia Schmid </E1:author> to apply <E2:proteins> HOG detectors </E2:proteins> to the problem of human detection in films and videos ."
"related-to","24","32","As part of the 2006 European Conference on Computer Vision ( ECCV ) , Dalal and Triggs teamed up with Cordelia Schmid to apply <E1:proteins> HOG detectors </E1:proteins> to the problem of <E2:UDBKL> human detection in films and videos </E2:UDBKL> ."
"related-to","3","13","In addition to <E1:UDBKL> sensitivity </E1:UDBKL> and specificity , the performance of a <E2:UDBKL> binary classification </E2:UDBKL> test can be measured with positive predictive value ( PPV ) , also known as precision , and negative predictive value ( NPV ) ."
"related-to","5","13","In addition to sensitivity and <E1:UDBKL> specificity </E1:UDBKL> , the performance of a <E2:UDBKL> binary classification </E2:UDBKL> test can be measured with positive predictive value ( PPV ) , also known as precision , and negative predictive value ( NPV ) ."
"named","20","11","In addition to sensitivity and specificity , the performance of a <E2:UDBKL> binary classification </E2:UDBKL> test can be measured with <E1:UDBKL> positive predictive value </E1:UDBKL> ( PPV ) , also known as precision , and negative predictive value ( NPV ) ."
"named","24","18","In addition to sensitivity and specificity , the performance of a binary classification test can be measured with <E2:UDBKL> positive predictive value </E2:UDBKL> ( <E1:UDBKL> PPV </E1:UDBKL> ) , also known as precision , and negative predictive value ( NPV ) ."
"named","30","18","In addition to sensitivity and specificity , the performance of a binary classification test can be measured with <E2:UDBKL> positive predictive value </E2:UDBKL> ( PPV ) , also known as <E1:UDBKL> precision </E1:UDBKL> , and negative predictive value ( NPV ) ."
"named","37","31","In addition to sensitivity and specificity , the performance of a binary classification test can be measured with positive predictive value ( PPV ) , also known as precision , and <E2:UDBKL> negative predictive value </E2:UDBKL> ( <E1:UDBKL> NPV </E1:UDBKL> ) ."
"artifact","0","11","<E1:proteins> KRL </E1:proteins> is a knowledge representation language , developed by <E2:author> Daniel G. Bobrow </E2:author> and Terry Winograd while at Xerox PARC and Stanford University , respectively ."
"artifact","0","15","<E1:proteins> KRL </E1:proteins> is a knowledge representation language , developed by Daniel G. Bobrow and <E2:author> Terry Winograd </E2:author> while at Xerox PARC and Stanford University , respectively ."
"physical","9","19","KRL is a knowledge representation language , developed by <E1:author> Daniel G. Bobrow </E1:author> and Terry Winograd while at <E2:UDBKL> Xerox PARC </E2:UDBKL> and Stanford University , respectively ."
"physical","13","22","KRL is a knowledge representation language , developed by Daniel G. Bobrow and <E1:author> Terry Winograd </E1:author> while at Xerox PARC and <E2:UDBKL> Stanford University </E2:UDBKL> , respectively ."
