Saved arguments to data/predictions/almnps_8878/ood_embedding/ood/args.json.
loading projection weights from /home/davidsule/gensim-data/word2vec-google-news-300/word2vec-google-news-300.gz
KeyedVectors lifecycle event {'msg': 'loaded (3000000, 300) matrix of type float32 from /home/davidsule/gensim-data/word2vec-google-news-300/word2vec-google-news-300.gz', 'binary': True, 'encoding': 'utf8', 'datetime': '2023-05-08T02:33:29.850027', 'gensim': '4.3.0', 'python': '3.9.16 | packaged by conda-forge | (main, Feb  1 2023, 21:39:03) \n[GCC 11.3.0]', 'platform': 'Linux-5.15.90.1-microsoft-standard-WSL2-x86_64-with-glibc2.31', 'event': 'load_word2vec_format'}
Saved category mapping to data/predictions/almnps_8878/ood_embedding/ood/mapping.json.
Loaded category mapping: ood_embedding.
Loaded <torch.utils.data.dataloader.DataLoader object at 0x7f46588c3b80> (train).
Loaded <torch.utils.data.dataloader.DataLoader object at 0x7f46588c35b0> (dev).
Starting training on ['literature', 'music', 'news', 'politics', 'science'] data.
Loaded <TransformerEmbeddings: dim=768>.
Using classifier: <LinearClassifier: emb_model = <TransformerEmbeddings: dim=768>>
Using criterion: <LabelLoss: loss=XEnt>.
Optimizing using: AdamW with learning rate 2e-05.
[Epoch 1/50] Train completed with Micro-f1: 0.3770, Macro-f1: 0.1955, Weighted-f1: 0.2973, Loss: 2.0794
[Epoch 1/50] Evaluation completed with Micro-f1: 0.4947, Macro-f1: 0.3112, Weighted-f1: 0.4392, Loss: 1.7955
Saved models from epoch 1 to 'data/predictions/almnps_8878/ood_embedding/ood/ai/newest.pt'.
Saved model with best loss 1.7955 to 'data/predictions/almnps_8878/ood_embedding/ood/ai/best.pt'.
[Epoch 2/50] Train completed with Micro-f1: 0.7121, Macro-f1: 0.5545, Weighted-f1: 0.6784, Loss: 1.1096
[Epoch 2/50] Evaluation completed with Micro-f1: 0.5234, Macro-f1: 0.3452, Weighted-f1: 0.4735, Loss: 1.5765
Saved models from epoch 2 to 'data/predictions/almnps_8878/ood_embedding/ood/ai/newest.pt'.
Saved model with best loss 1.5765 to 'data/predictions/almnps_8878/ood_embedding/ood/ai/best.pt'.
[Epoch 3/50] Train completed with Micro-f1: 0.8171, Macro-f1: 0.6895, Weighted-f1: 0.7976, Loss: 0.6834
[Epoch 3/50] Evaluation completed with Micro-f1: 0.5387, Macro-f1: 0.3633, Weighted-f1: 0.4935, Loss: 1.4832
Saved models from epoch 3 to 'data/predictions/almnps_8878/ood_embedding/ood/ai/newest.pt'.
Saved model with best loss 1.4832 to 'data/predictions/almnps_8878/ood_embedding/ood/ai/best.pt'.
[Epoch 4/50] Train completed with Micro-f1: 0.8970, Macro-f1: 0.8098, Weighted-f1: 0.8847, Loss: 0.4468
[Epoch 4/50] Evaluation completed with Micro-f1: 0.5459, Macro-f1: 0.3716, Weighted-f1: 0.5032, Loss: 1.5148
Saved models from epoch 4 to 'data/predictions/almnps_8878/ood_embedding/ood/ai/newest.pt'.
[Epoch 5/50] Train completed with Micro-f1: 0.9477, Macro-f1: 0.8982, Weighted-f1: 0.9411, Loss: 0.2684
[Epoch 5/50] Evaluation completed with Micro-f1: 0.5532, Macro-f1: 0.3808, Weighted-f1: 0.5134, Loss: 1.4738
Saved models from epoch 5 to 'data/predictions/almnps_8878/ood_embedding/ood/ai/newest.pt'.
Saved model with best loss 1.4738 to 'data/predictions/almnps_8878/ood_embedding/ood/ai/best.pt'.
[Epoch 6/50] Train completed with Micro-f1: 0.9790, Macro-f1: 0.9520, Weighted-f1: 0.9778, Loss: 0.1743
[Epoch 6/50] Evaluation completed with Micro-f1: 0.5589, Macro-f1: 0.3889, Weighted-f1: 0.5208, Loss: 1.5997
Saved models from epoch 6 to 'data/predictions/almnps_8878/ood_embedding/ood/ai/newest.pt'.
[Epoch 7/50] Train completed with Micro-f1: 0.9862, Macro-f1: 0.9633, Weighted-f1: 0.9856, Loss: 0.1140
[Epoch 7/50] Evaluation completed with Micro-f1: 0.5631, Macro-f1: 0.3954, Weighted-f1: 0.5267, Loss: 1.6378
Saved models from epoch 7 to 'data/predictions/almnps_8878/ood_embedding/ood/ai/newest.pt'.
[Epoch 8/50] Train completed with Micro-f1: 0.9954, Macro-f1: 0.9906, Weighted-f1: 0.9950, Loss: 0.0795
[Epoch 8/50] Evaluation completed with Micro-f1: 0.5674, Macro-f1: 0.4014, Weighted-f1: 0.5322, Loss: 1.6327
Saved models from epoch 8 to 'data/predictions/almnps_8878/ood_embedding/ood/ai/newest.pt'.
No improvement since 3 epochs (1.4738 loss). Early stop.
OOD training completed for test topic ai after 8 epochs.
Loaded <torch.utils.data.dataloader.DataLoader object at 0x7f45f02465e0> (train).
Loaded <torch.utils.data.dataloader.DataLoader object at 0x7f46588c3ee0> (dev).
Starting training on ['ai', 'music', 'news', 'politics', 'science'] data.
Loaded <TransformerEmbeddings: dim=768>.
Using classifier: <LinearClassifier: emb_model = <TransformerEmbeddings: dim=768>>
Using criterion: <LabelLoss: loss=XEnt>.
Optimizing using: AdamW with learning rate 2e-05.
[Epoch 1/50] Train completed with Micro-f1: 0.3606, Macro-f1: 0.1947, Weighted-f1: 0.2871, Loss: 2.1477
[Epoch 1/50] Evaluation completed with Micro-f1: 0.4667, Macro-f1: 0.3127, Weighted-f1: 0.4232, Loss: 1.8194
Saved models from epoch 1 to 'data/predictions/almnps_8878/ood_embedding/ood/literature/newest.pt'.
Saved model with best loss 1.8194 to 'data/predictions/almnps_8878/ood_embedding/ood/literature/best.pt'.
[Epoch 2/50] Train completed with Micro-f1: 0.6769, Macro-f1: 0.5428, Weighted-f1: 0.6497, Loss: 1.1890
[Epoch 2/50] Evaluation completed with Micro-f1: 0.4860, Macro-f1: 0.3293, Weighted-f1: 0.4463, Loss: 1.6081
Saved models from epoch 2 to 'data/predictions/almnps_8878/ood_embedding/ood/literature/newest.pt'.
Saved model with best loss 1.6081 to 'data/predictions/almnps_8878/ood_embedding/ood/literature/best.pt'.
[Epoch 3/50] Train completed with Micro-f1: 0.8127, Macro-f1: 0.7001, Weighted-f1: 0.7948, Loss: 0.7198
[Epoch 3/50] Evaluation completed with Micro-f1: 0.4967, Macro-f1: 0.3414, Weighted-f1: 0.4617, Loss: 1.5653
Saved models from epoch 3 to 'data/predictions/almnps_8878/ood_embedding/ood/literature/newest.pt'.
Saved model with best loss 1.5653 to 'data/predictions/almnps_8878/ood_embedding/ood/literature/best.pt'.
[Epoch 4/50] Train completed with Micro-f1: 0.8935, Macro-f1: 0.8283, Weighted-f1: 0.8830, Loss: 0.4662
[Epoch 4/50] Evaluation completed with Micro-f1: 0.5078, Macro-f1: 0.3554, Weighted-f1: 0.4766, Loss: 1.5316
Saved models from epoch 4 to 'data/predictions/almnps_8878/ood_embedding/ood/literature/newest.pt'.
Saved model with best loss 1.5316 to 'data/predictions/almnps_8878/ood_embedding/ood/literature/best.pt'.
[Epoch 5/50] Train completed with Micro-f1: 0.9499, Macro-f1: 0.9062, Weighted-f1: 0.9468, Loss: 0.2869
[Epoch 5/50] Evaluation completed with Micro-f1: 0.5156, Macro-f1: 0.3647, Weighted-f1: 0.4868, Loss: 1.5659
Saved models from epoch 5 to 'data/predictions/almnps_8878/ood_embedding/ood/literature/newest.pt'.
[Epoch 6/50] Train completed with Micro-f1: 0.9709, Macro-f1: 0.9527, Weighted-f1: 0.9694, Loss: 0.1914
[Epoch 6/50] Evaluation completed with Micro-f1: 0.5233, Macro-f1: 0.3747, Weighted-f1: 0.4971, Loss: 1.5852
Saved models from epoch 6 to 'data/predictions/almnps_8878/ood_embedding/ood/literature/newest.pt'.
[Epoch 7/50] Train completed with Micro-f1: 0.9889, Macro-f1: 0.9796, Weighted-f1: 0.9888, Loss: 0.1187
[Epoch 7/50] Evaluation completed with Micro-f1: 0.5283, Macro-f1: 0.3801, Weighted-f1: 0.5038, Loss: 1.6418
Saved models from epoch 7 to 'data/predictions/almnps_8878/ood_embedding/ood/literature/newest.pt'.
No improvement since 3 epochs (1.5316 loss). Early stop.
OOD training completed for test topic literature after 7 epochs.
Loaded <torch.utils.data.dataloader.DataLoader object at 0x7f464ff11370> (train).
Loaded <torch.utils.data.dataloader.DataLoader object at 0x7f45f024faf0> (dev).
Starting training on ['ai', 'literature', 'news', 'politics', 'science'] data.
Loaded <TransformerEmbeddings: dim=768>.
Using classifier: <LinearClassifier: emb_model = <TransformerEmbeddings: dim=768>>
Using criterion: <LabelLoss: loss=XEnt>.
Optimizing using: AdamW with learning rate 2e-05.
[Epoch 1/50] Train completed with Micro-f1: 0.3016, Macro-f1: 0.1689, Weighted-f1: 0.2349, Loss: 2.2630
[Epoch 1/50] Evaluation completed with Micro-f1: 0.4344, Macro-f1: 0.2527, Weighted-f1: 0.3788, Loss: 1.9176
Saved models from epoch 1 to 'data/predictions/almnps_8878/ood_embedding/ood/music/newest.pt'.
Saved model with best loss 1.9176 to 'data/predictions/almnps_8878/ood_embedding/ood/music/best.pt'.
[Epoch 2/50] Train completed with Micro-f1: 0.6377, Macro-f1: 0.4907, Weighted-f1: 0.5967, Loss: 1.3368
[Epoch 2/50] Evaluation completed with Micro-f1: 0.4625, Macro-f1: 0.2958, Weighted-f1: 0.4200, Loss: 1.6868
Saved models from epoch 2 to 'data/predictions/almnps_8878/ood_embedding/ood/music/newest.pt'.
Saved model with best loss 1.6868 to 'data/predictions/almnps_8878/ood_embedding/ood/music/best.pt'.
[Epoch 3/50] Train completed with Micro-f1: 0.7840, Macro-f1: 0.6704, Weighted-f1: 0.7658, Loss: 0.8341
[Epoch 3/50] Evaluation completed with Micro-f1: 0.4797, Macro-f1: 0.3227, Weighted-f1: 0.4452, Loss: 1.5913
Saved models from epoch 3 to 'data/predictions/almnps_8878/ood_embedding/ood/music/newest.pt'.
Saved model with best loss 1.5913 to 'data/predictions/almnps_8878/ood_embedding/ood/music/best.pt'.
[Epoch 4/50] Train completed with Micro-f1: 0.8714, Macro-f1: 0.8039, Weighted-f1: 0.8585, Loss: 0.5374
[Epoch 4/50] Evaluation completed with Micro-f1: 0.4946, Macro-f1: 0.3403, Weighted-f1: 0.4626, Loss: 1.4985
Saved models from epoch 4 to 'data/predictions/almnps_8878/ood_embedding/ood/music/newest.pt'.
Saved model with best loss 1.4985 to 'data/predictions/almnps_8878/ood_embedding/ood/music/best.pt'.
[Epoch 5/50] Train completed with Micro-f1: 0.9343, Macro-f1: 0.8784, Weighted-f1: 0.9259, Loss: 0.3471
[Epoch 5/50] Evaluation completed with Micro-f1: 0.5050, Macro-f1: 0.3531, Weighted-f1: 0.4740, Loss: 1.5290
Saved models from epoch 5 to 'data/predictions/almnps_8878/ood_embedding/ood/music/newest.pt'.
[Epoch 6/50] Train completed with Micro-f1: 0.9633, Macro-f1: 0.9292, Weighted-f1: 0.9616, Loss: 0.2228
[Epoch 6/50] Evaluation completed with Micro-f1: 0.5115, Macro-f1: 0.3617, Weighted-f1: 0.4829, Loss: 1.5539
Saved models from epoch 6 to 'data/predictions/almnps_8878/ood_embedding/ood/music/newest.pt'.
[Epoch 7/50] Train completed with Micro-f1: 0.9860, Macro-f1: 0.9767, Weighted-f1: 0.9856, Loss: 0.1548
[Epoch 7/50] Evaluation completed with Micro-f1: 0.5170, Macro-f1: 0.3684, Weighted-f1: 0.4896, Loss: 1.5893
Saved models from epoch 7 to 'data/predictions/almnps_8878/ood_embedding/ood/music/newest.pt'.
No improvement since 3 epochs (1.4985 loss). Early stop.
OOD training completed for test topic music after 7 epochs.
Loaded <torch.utils.data.dataloader.DataLoader object at 0x7f451e4e2ca0> (train).
Loaded <torch.utils.data.dataloader.DataLoader object at 0x7f451e6f6eb0> (dev).
Starting training on ['ai', 'literature', 'music', 'politics', 'science'] data.
Loaded <TransformerEmbeddings: dim=768>.
Using classifier: <LinearClassifier: emb_model = <TransformerEmbeddings: dim=768>>
Using criterion: <LabelLoss: loss=XEnt>.
Optimizing using: AdamW with learning rate 2e-05.
[Epoch 1/50] Train completed with Micro-f1: 0.3889, Macro-f1: 0.2297, Weighted-f1: 0.3296, Loss: 2.0962
[Epoch 1/50] Evaluation completed with Micro-f1: 0.4888, Macro-f1: 0.3103, Weighted-f1: 0.4337, Loss: 1.7527
Saved models from epoch 1 to 'data/predictions/almnps_8878/ood_embedding/ood/news/newest.pt'.
Saved model with best loss 1.7527 to 'data/predictions/almnps_8878/ood_embedding/ood/news/best.pt'.
[Epoch 2/50] Train completed with Micro-f1: 0.6944, Macro-f1: 0.5578, Weighted-f1: 0.6624, Loss: 1.1341
[Epoch 2/50] Evaluation completed with Micro-f1: 0.5179, Macro-f1: 0.3441, Weighted-f1: 0.4730, Loss: 1.5139
Saved models from epoch 2 to 'data/predictions/almnps_8878/ood_embedding/ood/news/newest.pt'.
Saved model with best loss 1.5139 to 'data/predictions/almnps_8878/ood_embedding/ood/news/best.pt'.
[Epoch 3/50] Train completed with Micro-f1: 0.8275, Macro-f1: 0.7298, Weighted-f1: 0.8121, Loss: 0.6921
[Epoch 3/50] Evaluation completed with Micro-f1: 0.5369, Macro-f1: 0.3686, Weighted-f1: 0.4973, Loss: 1.4227
Saved models from epoch 3 to 'data/predictions/almnps_8878/ood_embedding/ood/news/newest.pt'.
Saved model with best loss 1.4227 to 'data/predictions/almnps_8878/ood_embedding/ood/news/best.pt'.
[Epoch 4/50] Train completed with Micro-f1: 0.9047, Macro-f1: 0.8403, Weighted-f1: 0.8931, Loss: 0.4329
[Epoch 4/50] Evaluation completed with Micro-f1: 0.5467, Macro-f1: 0.3842, Weighted-f1: 0.5125, Loss: 1.4347
Saved models from epoch 4 to 'data/predictions/almnps_8878/ood_embedding/ood/news/newest.pt'.
[Epoch 5/50] Train completed with Micro-f1: 0.9460, Macro-f1: 0.9000, Weighted-f1: 0.9440, Loss: 0.2788
[Epoch 5/50] Evaluation completed with Micro-f1: 0.5552, Macro-f1: 0.3955, Weighted-f1: 0.5235, Loss: 1.5115
Saved models from epoch 5 to 'data/predictions/almnps_8878/ood_embedding/ood/news/newest.pt'.
[Epoch 6/50] Train completed with Micro-f1: 0.9736, Macro-f1: 0.9468, Weighted-f1: 0.9710, Loss: 0.1765
[Epoch 6/50] Evaluation completed with Micro-f1: 0.5629, Macro-f1: 0.4049, Weighted-f1: 0.5336, Loss: 1.4644
Saved models from epoch 6 to 'data/predictions/almnps_8878/ood_embedding/ood/news/newest.pt'.
No improvement since 3 epochs (1.4227 loss). Early stop.
OOD training completed for test topic news after 6 epochs.
Loaded <torch.utils.data.dataloader.DataLoader object at 0x7f451e3e8250> (train).
Loaded <torch.utils.data.dataloader.DataLoader object at 0x7f464ff8aa90> (dev).
Starting training on ['ai', 'literature', 'music', 'news', 'science'] data.
Loaded <TransformerEmbeddings: dim=768>.
Using classifier: <LinearClassifier: emb_model = <TransformerEmbeddings: dim=768>>
Using criterion: <LabelLoss: loss=XEnt>.
Optimizing using: AdamW with learning rate 2e-05.
[Epoch 1/50] Train completed with Micro-f1: 0.3350, Macro-f1: 0.1859, Weighted-f1: 0.2704, Loss: 2.1946
[Epoch 1/50] Evaluation completed with Micro-f1: 0.4640, Macro-f1: 0.2893, Weighted-f1: 0.4119, Loss: 1.8470
Saved models from epoch 1 to 'data/predictions/almnps_8878/ood_embedding/ood/politics/newest.pt'.
Saved model with best loss 1.8470 to 'data/predictions/almnps_8878/ood_embedding/ood/politics/best.pt'.
[Epoch 2/50] Train completed with Micro-f1: 0.6631, Macro-f1: 0.4977, Weighted-f1: 0.6250, Loss: 1.2157
[Epoch 2/50] Evaluation completed with Micro-f1: 0.5003, Macro-f1: 0.3271, Weighted-f1: 0.4556, Loss: 1.5582
Saved models from epoch 2 to 'data/predictions/almnps_8878/ood_embedding/ood/politics/newest.pt'.
Saved model with best loss 1.5582 to 'data/predictions/almnps_8878/ood_embedding/ood/politics/best.pt'.
[Epoch 3/50] Train completed with Micro-f1: 0.8112, Macro-f1: 0.7125, Weighted-f1: 0.7930, Loss: 0.7467
[Epoch 3/50] Evaluation completed with Micro-f1: 0.5195, Macro-f1: 0.3458, Weighted-f1: 0.4779, Loss: 1.4759
Saved models from epoch 3 to 'data/predictions/almnps_8878/ood_embedding/ood/politics/newest.pt'.
Saved model with best loss 1.4759 to 'data/predictions/almnps_8878/ood_embedding/ood/politics/best.pt'.
[Epoch 4/50] Train completed with Micro-f1: 0.8893, Macro-f1: 0.8282, Weighted-f1: 0.8833, Loss: 0.4900
[Epoch 4/50] Evaluation completed with Micro-f1: 0.5352, Macro-f1: 0.3640, Weighted-f1: 0.4968, Loss: 1.4089
Saved models from epoch 4 to 'data/predictions/almnps_8878/ood_embedding/ood/politics/newest.pt'.
Saved model with best loss 1.4089 to 'data/predictions/almnps_8878/ood_embedding/ood/politics/best.pt'.
[Epoch 5/50] Train completed with Micro-f1: 0.9377, Macro-f1: 0.8892, Weighted-f1: 0.9309, Loss: 0.3086
[Epoch 5/50] Evaluation completed with Micro-f1: 0.5453, Macro-f1: 0.3774, Weighted-f1: 0.5105, Loss: 1.4198
Saved models from epoch 5 to 'data/predictions/almnps_8878/ood_embedding/ood/politics/newest.pt'.
[Epoch 6/50] Train completed with Micro-f1: 0.9682, Macro-f1: 0.9450, Weighted-f1: 0.9647, Loss: 0.2068
[Epoch 6/50] Evaluation completed with Micro-f1: 0.5524, Macro-f1: 0.3870, Weighted-f1: 0.5196, Loss: 1.4498
Saved models from epoch 6 to 'data/predictions/almnps_8878/ood_embedding/ood/politics/newest.pt'.
[Epoch 7/50] Train completed with Micro-f1: 0.9805, Macro-f1: 0.9636, Weighted-f1: 0.9792, Loss: 0.1423
[Epoch 7/50] Evaluation completed with Micro-f1: 0.5595, Macro-f1: 0.3947, Weighted-f1: 0.5282, Loss: 1.4733
Saved models from epoch 7 to 'data/predictions/almnps_8878/ood_embedding/ood/politics/newest.pt'.
No improvement since 3 epochs (1.4089 loss). Early stop.
OOD training completed for test topic politics after 7 epochs.
Loaded <torch.utils.data.dataloader.DataLoader object at 0x7f451e6cfaf0> (train).
Loaded <torch.utils.data.dataloader.DataLoader object at 0x7f46500afc40> (dev).
Starting training on ['ai', 'literature', 'music', 'news', 'politics'] data.
Loaded <TransformerEmbeddings: dim=768>.
Using classifier: <LinearClassifier: emb_model = <TransformerEmbeddings: dim=768>>
Using criterion: <LabelLoss: loss=XEnt>.
Optimizing using: AdamW with learning rate 2e-05.
[Epoch 1/50] Train completed with Micro-f1: 0.3774, Macro-f1: 0.2147, Weighted-f1: 0.3099, Loss: 2.1026
[Epoch 1/50] Evaluation completed with Micro-f1: 0.5163, Macro-f1: 0.3416, Weighted-f1: 0.4700, Loss: 1.7093
Saved models from epoch 1 to 'data/predictions/almnps_8878/ood_embedding/ood/science/newest.pt'.
Saved model with best loss 1.7093 to 'data/predictions/almnps_8878/ood_embedding/ood/science/best.pt'.
[Epoch 2/50] Train completed with Micro-f1: 0.6743, Macro-f1: 0.5129, Weighted-f1: 0.6389, Loss: 1.1899
[Epoch 2/50] Evaluation completed with Micro-f1: 0.5427, Macro-f1: 0.3714, Weighted-f1: 0.5019, Loss: 1.4464
Saved models from epoch 2 to 'data/predictions/almnps_8878/ood_embedding/ood/science/newest.pt'.
Saved model with best loss 1.4464 to 'data/predictions/almnps_8878/ood_embedding/ood/science/best.pt'.
[Epoch 3/50] Train completed with Micro-f1: 0.8109, Macro-f1: 0.6946, Weighted-f1: 0.7889, Loss: 0.7389
[Epoch 3/50] Evaluation completed with Micro-f1: 0.5567, Macro-f1: 0.3864, Weighted-f1: 0.5191, Loss: 1.4012
Saved models from epoch 3 to 'data/predictions/almnps_8878/ood_embedding/ood/science/newest.pt'.
Saved model with best loss 1.4012 to 'data/predictions/almnps_8878/ood_embedding/ood/science/best.pt'.
[Epoch 4/50] Train completed with Micro-f1: 0.8823, Macro-f1: 0.8038, Weighted-f1: 0.8726, Loss: 0.4800
[Epoch 4/50] Evaluation completed with Micro-f1: 0.5660, Macro-f1: 0.3974, Weighted-f1: 0.5303, Loss: 1.3845
Saved models from epoch 4 to 'data/predictions/almnps_8878/ood_embedding/ood/science/newest.pt'.
Saved model with best loss 1.3845 to 'data/predictions/almnps_8878/ood_embedding/ood/science/best.pt'.
[Epoch 5/50] Train completed with Micro-f1: 0.9349, Macro-f1: 0.8909, Weighted-f1: 0.9298, Loss: 0.3100
[Epoch 5/50] Evaluation completed with Micro-f1: 0.5724, Macro-f1: 0.4052, Weighted-f1: 0.5392, Loss: 1.4284
Saved models from epoch 5 to 'data/predictions/almnps_8878/ood_embedding/ood/science/newest.pt'.
[Epoch 6/50] Train completed with Micro-f1: 0.9729, Macro-f1: 0.9487, Weighted-f1: 0.9709, Loss: 0.1935
[Epoch 6/50] Evaluation completed with Micro-f1: 0.5777, Macro-f1: 0.4123, Weighted-f1: 0.5462, Loss: 1.4745
Saved models from epoch 6 to 'data/predictions/almnps_8878/ood_embedding/ood/science/newest.pt'.
[Epoch 7/50] Train completed with Micro-f1: 0.9875, Macro-f1: 0.9738, Weighted-f1: 0.9871, Loss: 0.1255
[Epoch 7/50] Evaluation completed with Micro-f1: 0.5820, Macro-f1: 0.4187, Weighted-f1: 0.5525, Loss: 1.4999
Saved models from epoch 7 to 'data/predictions/almnps_8878/ood_embedding/ood/science/newest.pt'.
No improvement since 3 epochs (1.3845 loss). Early stop.
OOD training completed for test topic science after 7 epochs.
TRAINING COMPLETED with:
	Domains:		['ai', 'literature', 'music', 'news', 'politics', 'science']
	OOD validaation:	True
	Mapping type:		ood_embedding
