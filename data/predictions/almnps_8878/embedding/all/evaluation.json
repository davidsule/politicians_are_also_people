{"related-to": {"precision": 0.05357142857142857, "recall": 0.07971014492753623, "f1-score": 0.06407766990291261, "support": 414}, "artifact": {"precision": 0.05981794538361508, "recall": 0.07244094488188976, "f1-score": 0.06552706552706551, "support": 635}, "cause-effect": {"precision": 0.0, "recall": 0.0, "f1-score": 0.0, "support": 86}, "compare": {"precision": 0.0, "recall": 0.0, "f1-score": 0.0, "support": 82}, "general-affiliation": {"precision": 0.1480284421460892, "recall": 0.1848264729620662, "f1-score": 0.16439339554917445, "support": 1239}, "named": {"precision": 0.08178438661710037, "recall": 0.07885304659498207, "f1-score": 0.0802919708029197, "support": 558}, "opposite": {"precision": 0.015625, "recall": 0.0078125, "f1-score": 0.010416666666666666, "support": 128}, "origin": {"precision": 0.03680981595092025, "recall": 0.019736842105263157, "f1-score": 0.02569593147751606, "support": 304}, "part-of": {"precision": 0.08043478260869565, "recall": 0.10263522884882108, "f1-score": 0.09018890920170627, "support": 721}, "physical": {"precision": 0.1736150770988007, "recall": 0.20893470790378008, "f1-score": 0.18964441671865256, "support": 1455}, "role": {"precision": 0.2303120356612184, "recall": 0.15453639082751744, "f1-score": 0.18496420047732695, "support": 2006}, "social": {"precision": 0.0, "recall": 0.0, "f1-score": 0.0, "support": 105}, "temporal": {"precision": 0.04017857142857143, "recall": 0.04411764705882353, "f1-score": 0.042056074766355145, "support": 408}, "topic": {"precision": 0.0, "recall": 0.0, "f1-score": 0.0, "support": 170}, "type-of": {"precision": 0.057971014492753624, "recall": 0.011904761904761904, "f1-score": 0.01975308641975309, "support": 336}, "usage": {"precision": 0.0, "recall": 0.0, "f1-score": 0.0, "support": 200}, "win-defeat": {"precision": 0.059190031152647975, "recall": 0.05993690851735016, "f1-score": 0.059561128526645774, "support": 317}, "micro avg": {"precision": 0.12551915089986157, "recall": 0.11872544740288084, "f1-score": 0.12202781516375055, "support": 9164}, "macro avg": {"precision": 0.06101991359481418, "recall": 0.06032032920781127, "f1-score": 0.058621795060982036, "support": 9164}, "weighted avg": {"precision": 0.12326929236266193, "recall": 0.11872544740288084, "f1-score": 0.11790079490917628, "support": 9164}, "samples avg": {"precision": 0.12551915089986157, "recall": 0.11907783417935704, "f1-score": 0.12121212121212119, "support": 9164}}