{"related-to": {"precision": 0.02857142857142857, "recall": 0.013888888888888888, "f1-score": 0.018691588785046724, "support": 72}, "artifact": {"precision": 0.19638242894056848, "recall": 0.25333333333333335, "f1-score": 0.2212518195050946, "support": 300}, "cause-effect": {"precision": 0.0, "recall": 0.0, "f1-score": 0.0, "support": 1}, "compare": {"precision": 0.0, "recall": 0.0, "f1-score": 0.0, "support": 9}, "general-affiliation": {"precision": 0.1485148514851485, "recall": 0.04573170731707317, "f1-score": 0.06993006993006992, "support": 328}, "named": {"precision": 0.06, "recall": 0.03125, "f1-score": 0.0410958904109589, "support": 96}, "opposite": {"precision": 0.0, "recall": 0.0, "f1-score": 0.0, "support": 15}, "origin": {"precision": 0.007518796992481203, "recall": 0.02127659574468085, "f1-score": 0.011111111111111112, "support": 47}, "part-of": {"precision": 0.07971014492753623, "recall": 0.11578947368421053, "f1-score": 0.09442060085836909, "support": 95}, "physical": {"precision": 0.1271186440677966, "recall": 0.17341040462427745, "f1-score": 0.14669926650366746, "support": 173}, "role": {"precision": 0.19210526315789472, "recall": 0.2896825396825397, "f1-score": 0.2310126582278481, "support": 252}, "social": {"precision": 0.0, "recall": 0.0, "f1-score": 0.0, "support": 47}, "temporal": {"precision": 0.06896551724137931, "recall": 0.06451612903225806, "f1-score": 0.06666666666666667, "support": 31}, "topic": {"precision": 0.0, "recall": 0.0, "f1-score": 0.0, "support": 42}, "type-of": {"precision": 0.0, "recall": 0.0, "f1-score": 0.0, "support": 18}, "usage": {"precision": 0.0, "recall": 0.0, "f1-score": 0.0, "support": 2}, "win-defeat": {"precision": 0.05660377358490566, "recall": 0.030927835051546393, "f1-score": 0.04, "support": 97}, "micro avg": {"precision": 0.1350502512562814, "recall": 0.13230769230769232, "f1-score": 0.1336649051911719, "support": 1625}, "macro avg": {"precision": 0.056793579351125834, "recall": 0.061165112197576976, "f1-score": 0.05534586305875486, "support": 1625}, "weighted avg": {"precision": 0.12393916237842559, "recall": 0.13230769230769232, "f1-score": 0.11916099545203254, "support": 1625}, "samples avg": {"precision": 0.1350502512562814, "recall": 0.13086264656616417, "f1-score": 0.13222361809045227, "support": 1625}}