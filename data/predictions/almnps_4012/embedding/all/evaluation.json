{"related-to": {"precision": 0.049342105263157895, "recall": 0.07246376811594203, "f1-score": 0.05870841487279844, "support": 414}, "artifact": {"precision": 0.08108108108108109, "recall": 0.09921259842519685, "f1-score": 0.08923512747875353, "support": 635}, "cause-effect": {"precision": 0.0, "recall": 0.0, "f1-score": 0.0, "support": 86}, "compare": {"precision": 0.0, "recall": 0.0, "f1-score": 0.0, "support": 82}, "general-affiliation": {"precision": 0.13790504898266767, "recall": 0.14769975786924938, "f1-score": 0.14263445050662513, "support": 1239}, "named": {"precision": 0.07061068702290077, "recall": 0.06630824372759857, "f1-score": 0.06839186691312386, "support": 558}, "opposite": {"precision": 0.029411764705882353, "recall": 0.0078125, "f1-score": 0.012345679012345678, "support": 128}, "origin": {"precision": 0.047244094488188976, "recall": 0.019736842105263157, "f1-score": 0.02784222737819025, "support": 304}, "part-of": {"precision": 0.08662613981762918, "recall": 0.07905686546463246, "f1-score": 0.0826686004350979, "support": 721}, "physical": {"precision": 0.1699230313795145, "recall": 0.1972508591065292, "f1-score": 0.1825699745547074, "support": 1455}, "role": {"precision": 0.23295454545454544, "recall": 0.22482552342971088, "f1-score": 0.22881785895484524, "support": 2006}, "social": {"precision": 0.045454545454545456, "recall": 0.01904761904761905, "f1-score": 0.02684563758389262, "support": 105}, "temporal": {"precision": 0.05714285714285714, "recall": 0.06862745098039216, "f1-score": 0.062360801781737196, "support": 408}, "topic": {"precision": 0.0, "recall": 0.0, "f1-score": 0.0, "support": 170}, "type-of": {"precision": 0.03597122302158273, "recall": 0.01488095238095238, "f1-score": 0.021052631578947368, "support": 336}, "usage": {"precision": 0.0, "recall": 0.0, "f1-score": 0.0, "support": 200}, "win-defeat": {"precision": 0.03146853146853147, "recall": 0.028391167192429023, "f1-score": 0.029850746268656716, "support": 317}, "micro avg": {"precision": 0.13371019843101062, "recall": 0.1264731558271497, "f1-score": 0.1299910273665321, "support": 9164}, "macro avg": {"precision": 0.06324327384018147, "recall": 0.061489067520324424, "f1-score": 0.06078376572468949, "support": 9164}, "weighted avg": {"precision": 0.12303113179461063, "recall": 0.1264731558271497, "f1-score": 0.12384886386548463, "support": 9164}, "samples avg": {"precision": 0.13371019843101062, "recall": 0.124980772188894, "f1-score": 0.12788417166589755, "support": 9164}}