{"related-to": {"precision": 0.08823529411764706, "recall": 0.14285714285714285, "f1-score": 0.10909090909090909, "support": 126}, "artifact": {"precision": 0.0, "recall": 0.0, "f1-score": 0.0, "support": 33}, "cause-effect": {"precision": 0.0, "recall": 0.0, "f1-score": 0.0, "support": 76}, "compare": {"precision": 0.0, "recall": 0.0, "f1-score": 0.0, "support": 39}, "general-affiliation": {"precision": 0.045112781954887216, "recall": 0.0821917808219178, "f1-score": 0.05825242718446602, "support": 73}, "named": {"precision": 0.08713692946058091, "recall": 0.19444444444444445, "f1-score": 0.12034383954154727, "support": 108}, "opposite": {"precision": 0.0, "recall": 0.0, "f1-score": 0.0, "support": 5}, "origin": {"precision": 0.1282051282051282, "recall": 0.05319148936170213, "f1-score": 0.07518796992481204, "support": 94}, "part-of": {"precision": 0.03879310344827586, "recall": 0.1, "f1-score": 0.05590062111801243, "support": 90}, "physical": {"precision": 0.1735159817351598, "recall": 0.16964285714285715, "f1-score": 0.17155756207674944, "support": 224}, "role": {"precision": 0.13125, "recall": 0.07342657342657342, "f1-score": 0.09417040358744395, "support": 286}, "social": {"precision": 0.0, "recall": 0.0, "f1-score": 0.0, "support": 14}, "temporal": {"precision": 0.03225806451612903, "recall": 0.038461538461538464, "f1-score": 0.03508771929824561, "support": 26}, "topic": {"precision": 0.0, "recall": 0.0, "f1-score": 0.0, "support": 66}, "type-of": {"precision": 0.125, "recall": 0.017094017094017096, "f1-score": 0.030075187969924817, "support": 117}, "usage": {"precision": 0.0, "recall": 0.0, "f1-score": 0.0, "support": 24}, "win-defeat": {"precision": 0.07142857142857142, "recall": 0.06818181818181818, "f1-score": 0.0697674418604651, "support": 44}, "micro avg": {"precision": 0.08908045977011494, "recall": 0.08581314878892733, "f1-score": 0.08741628480789566, "support": 1445}, "macro avg": {"precision": 0.05417269734508115, "recall": 0.05526421539953009, "f1-score": 0.0482020048030927, "support": 1445}, "weighted avg": {"precision": 0.09299375544211225, "recall": 0.08581314878892733, "f1-score": 0.08024651622232389, "support": 1445}, "samples avg": {"precision": 0.08908045977011494, "recall": 0.08548850574712644, "f1-score": 0.08668582375478927, "support": 1445}}