{"related-to": {"precision": 0.06077348066298342, "recall": 0.10628019323671498, "f1-score": 0.07732864674868191, "support": 414}, "artifact": {"precision": 0.06464379947229551, "recall": 0.07716535433070866, "f1-score": 0.07035175879396983, "support": 635}, "cause-effect": {"precision": 0.0, "recall": 0.0, "f1-score": 0.0, "support": 86}, "compare": {"precision": 0.0, "recall": 0.0, "f1-score": 0.0, "support": 82}, "general-affiliation": {"precision": 0.13917122752150118, "recall": 0.14366424535916061, "f1-score": 0.1413820492454329, "support": 1239}, "named": {"precision": 0.05009276437847866, "recall": 0.04838709677419355, "f1-score": 0.049225159525979945, "support": 558}, "opposite": {"precision": 0.03125, "recall": 0.0078125, "f1-score": 0.0125, "support": 128}, "origin": {"precision": 0.04081632653061224, "recall": 0.019736842105263157, "f1-score": 0.026607538802660754, "support": 304}, "part-of": {"precision": 0.08170310701956271, "recall": 0.09847434119278779, "f1-score": 0.08930817610062892, "support": 721}, "physical": {"precision": 0.16262975778546712, "recall": 0.16151202749140894, "f1-score": 0.16206896551724137, "support": 1455}, "role": {"precision": 0.22141662018962632, "recall": 0.19790628115653042, "f1-score": 0.2090023690444854, "support": 2006}, "social": {"precision": 0.0, "recall": 0.0, "f1-score": 0.0, "support": 105}, "temporal": {"precision": 0.04157549234135667, "recall": 0.04656862745098039, "f1-score": 0.04393063583815029, "support": 408}, "topic": {"precision": 0.022727272727272728, "recall": 0.0058823529411764705, "f1-score": 0.009345794392523364, "support": 170}, "type-of": {"precision": 0.05102040816326531, "recall": 0.02976190476190476, "f1-score": 0.037593984962406006, "support": 336}, "usage": {"precision": 0.0, "recall": 0.0, "f1-score": 0.0, "support": 200}, "win-defeat": {"precision": 0.032362459546925564, "recall": 0.031545741324921134, "f1-score": 0.03194888178913737, "support": 317}, "micro avg": {"precision": 0.12090447623442548, "recall": 0.11436054124836316, "f1-score": 0.11754149842978914, "support": 9164}, "macro avg": {"precision": 0.05883427743172631, "recall": 0.05733514753680888, "f1-score": 0.05650552710360577, "support": 9164}, "weighted avg": {"precision": 0.1168623180100952, "recall": 0.11436054124836316, "f1-score": 0.11466043948683095, "support": 9164}, "samples avg": {"precision": 0.12090447623442548, "recall": 0.11261728964774649, "f1-score": 0.11536686663590215, "support": 9164}}