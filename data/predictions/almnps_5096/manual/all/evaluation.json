{"related-to": {"precision": 0.05011389521640091, "recall": 0.05314009661835749, "f1-score": 0.05158264947245018, "support": 414}, "artifact": {"precision": 0.07202216066481995, "recall": 0.08188976377952756, "f1-score": 0.07663964627855564, "support": 635}, "cause-effect": {"precision": 0.0, "recall": 0.0, "f1-score": 0.0, "support": 86}, "compare": {"precision": 0.0, "recall": 0.0, "f1-score": 0.0, "support": 82}, "general-affiliation": {"precision": 0.16410940627084722, "recall": 0.19854721549636803, "f1-score": 0.17969320672023376, "support": 1239}, "named": {"precision": 0.059813084112149535, "recall": 0.05734767025089606, "f1-score": 0.0585544373284538, "support": 558}, "opposite": {"precision": 0.0, "recall": 0.0, "f1-score": 0.0, "support": 128}, "origin": {"precision": 0.05194805194805195, "recall": 0.039473684210526314, "f1-score": 0.04485981308411215, "support": 304}, "part-of": {"precision": 0.08097165991902834, "recall": 0.13869625520110956, "f1-score": 0.10224948875255625, "support": 721}, "physical": {"precision": 0.17156286721504113, "recall": 0.2006872852233677, "f1-score": 0.18498574596135572, "support": 1455}, "role": {"precision": 0.24735557363710334, "recall": 0.15154536390827517, "f1-score": 0.18794435857805256, "support": 2006}, "social": {"precision": 0.00847457627118644, "recall": 0.009523809523809525, "f1-score": 0.008968609865470854, "support": 105}, "temporal": {"precision": 0.06858407079646017, "recall": 0.07598039215686274, "f1-score": 0.07209302325581395, "support": 408}, "topic": {"precision": 0.0, "recall": 0.0, "f1-score": 0.0, "support": 170}, "type-of": {"precision": 0.030927835051546393, "recall": 0.008928571428571428, "f1-score": 0.013856812933025405, "support": 336}, "usage": {"precision": 0.0, "recall": 0.0, "f1-score": 0.0, "support": 200}, "win-defeat": {"precision": 0.025559105431309903, "recall": 0.025236593059936908, "f1-score": 0.025396825396825397, "support": 317}, "micro avg": {"precision": 0.1272496538994001, "recall": 0.12036228721082497, "f1-score": 0.1237101839389861, "support": 9164}, "macro avg": {"precision": 0.060673075678467366, "recall": 0.061235100050447556, "f1-score": 0.05922497750746505, "support": 9164}, "weighted avg": {"precision": 0.12773315445723768, "recall": 0.12036228721082497, "f1-score": 0.12024518769032844, "support": 9164}, "samples avg": {"precision": 0.1272496538994001, "recall": 0.11984694662359636, "f1-score": 0.12230810644516227, "support": 9164}}