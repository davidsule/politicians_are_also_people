{"related-to": {"precision": 0.11464968152866242, "recall": 0.3333333333333333, "f1-score": 0.17061611374407581, "support": 108}, "artifact": {"precision": 0.047619047619047616, "recall": 0.04878048780487805, "f1-score": 0.04819277108433735, "support": 41}, "cause-effect": {"precision": 0.0, "recall": 0.0, "f1-score": 0.0, "support": 4}, "compare": {"precision": 0.0, "recall": 0.0, "f1-score": 0.0, "support": 24}, "general-affiliation": {"precision": 0.02666666666666667, "recall": 0.05333333333333334, "f1-score": 0.03555555555555556, "support": 75}, "named": {"precision": 0.10454545454545454, "recall": 0.16312056737588654, "f1-score": 0.12742382271468142, "support": 141}, "opposite": {"precision": 0.0, "recall": 0.0, "f1-score": 0.0, "support": 14}, "origin": {"precision": 0.12903225806451613, "recall": 0.0449438202247191, "f1-score": 0.06666666666666667, "support": 89}, "part-of": {"precision": 0.23853211009174313, "recall": 0.12093023255813953, "f1-score": 0.16049382716049385, "support": 215}, "physical": {"precision": 0.08547008547008547, "recall": 0.09803921568627451, "f1-score": 0.09132420091324202, "support": 102}, "role": {"precision": 0.09448818897637795, "recall": 0.11320754716981132, "f1-score": 0.10300429184549356, "support": 106}, "social": {"precision": 0.0, "recall": 0.0, "f1-score": 0.0, "support": 1}, "temporal": {"precision": 0.0, "recall": 0.0, "f1-score": 0.0, "support": 21}, "topic": {"precision": 0.0, "recall": 0.0, "f1-score": 0.0, "support": 39}, "type-of": {"precision": 0.0, "recall": 0.0, "f1-score": 0.0, "support": 54}, "usage": {"precision": 0.0, "recall": 0.0, "f1-score": 0.0, "support": 122}, "win-defeat": {"precision": 0.125, "recall": 0.14285714285714285, "f1-score": 0.13333333333333333, "support": 7}, "micro avg": {"precision": 0.10470275066548358, "recall": 0.10146173688736028, "f1-score": 0.10305676855895197, "support": 1163}, "macro avg": {"precision": 0.056823734880150224, "recall": 0.06579680472608933, "f1-score": 0.055094740177522326, "support": 1163}, "weighted avg": {"precision": 0.09755152797531992, "recall": 0.10146173688736028, "f1-score": 0.0882564337946695, "support": 1163}, "samples avg": {"precision": 0.10470275066548358, "recall": 0.1023365868086365, "f1-score": 0.10307601301390121, "support": 1163}}