{"related-to": {"precision": 0.03619047619047619, "recall": 0.04589371980676329, "f1-score": 0.04046858359957401, "support": 414}, "artifact": {"precision": 0.05699481865284974, "recall": 0.06929133858267716, "f1-score": 0.06254442075337598, "support": 635}, "cause-effect": {"precision": 0.0, "recall": 0.0, "f1-score": 0.0, "support": 86}, "compare": {"precision": 0.0, "recall": 0.0, "f1-score": 0.0, "support": 82}, "general-affiliation": {"precision": 0.14538310412573674, "recall": 0.1791767554479419, "f1-score": 0.16052060737527118, "support": 1239}, "named": {"precision": 0.06282722513089005, "recall": 0.06451612903225806, "f1-score": 0.0636604774535809, "support": 558}, "opposite": {"precision": 0.0, "recall": 0.0, "f1-score": 0.0, "support": 128}, "origin": {"precision": 0.044642857142857144, "recall": 0.03289473684210526, "f1-score": 0.03787878787878788, "support": 304}, "part-of": {"precision": 0.0783625730994152, "recall": 0.09292649098474341, "f1-score": 0.0850253807106599, "support": 721}, "physical": {"precision": 0.1751283513976041, "recall": 0.21099656357388316, "f1-score": 0.19139650872817954, "support": 1455}, "role": {"precision": 0.2250351617440225, "recall": 0.15952143569292124, "f1-score": 0.18669778296382733, "support": 2006}, "social": {"precision": 0.01282051282051282, "recall": 0.009523809523809525, "f1-score": 0.01092896174863388, "support": 105}, "temporal": {"precision": 0.06666666666666667, "recall": 0.07352941176470588, "f1-score": 0.06993006993006994, "support": 408}, "topic": {"precision": 0.05, "recall": 0.011764705882352941, "f1-score": 0.01904761904761905, "support": 170}, "type-of": {"precision": 0.035398230088495575, "recall": 0.011904761904761904, "f1-score": 0.017817371937639197, "support": 336}, "usage": {"precision": 0.125, "recall": 0.005, "f1-score": 0.009615384615384616, "support": 200}, "win-defeat": {"precision": 0.04363636363636364, "recall": 0.03785488958990536, "f1-score": 0.04054054054054054, "support": 317}, "micro avg": {"precision": 0.12401938163359483, "recall": 0.11730685290266259, "f1-score": 0.1205697622252131, "support": 9164}, "macro avg": {"precision": 0.06812272592328766, "recall": 0.05910557344875465, "f1-score": 0.05859249984018494, "support": 9164}, "weighted avg": {"precision": 0.12335635536545032, "recall": 0.11730685290266259, "f1-score": 0.11680178672815343, "support": 9164}, "samples avg": {"precision": 0.12401938163359483, "recall": 0.11690509152438086, "f1-score": 0.11927011229041685, "support": 9164}}