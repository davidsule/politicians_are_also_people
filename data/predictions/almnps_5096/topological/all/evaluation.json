{"related-to": {"precision": 0.04421052631578947, "recall": 0.050724637681159424, "f1-score": 0.047244094488188976, "support": 414}, "artifact": {"precision": 0.07097591888466413, "recall": 0.08818897637795275, "f1-score": 0.07865168539325842, "support": 635}, "cause-effect": {"precision": 0.0, "recall": 0.0, "f1-score": 0.0, "support": 86}, "compare": {"precision": 0.0, "recall": 0.0, "f1-score": 0.0, "support": 82}, "general-affiliation": {"precision": 0.15654520917678813, "recall": 0.18724778046811946, "f1-score": 0.17052554208011764, "support": 1239}, "named": {"precision": 0.04742268041237113, "recall": 0.04121863799283154, "f1-score": 0.04410354745925216, "support": 558}, "opposite": {"precision": 0.0, "recall": 0.0, "f1-score": 0.0, "support": 128}, "origin": {"precision": 0.06779661016949153, "recall": 0.039473684210526314, "f1-score": 0.04989604989604989, "support": 304}, "part-of": {"precision": 0.08021390374331551, "recall": 0.12482662968099861, "f1-score": 0.09766684753119914, "support": 721}, "physical": {"precision": 0.16557474687313878, "recall": 0.19106529209621992, "f1-score": 0.17740906190172304, "support": 1455}, "role": {"precision": 0.23215476984656438, "recall": 0.17347956131605186, "f1-score": 0.19857346647646218, "support": 2006}, "social": {"precision": 0.0, "recall": 0.0, "f1-score": 0.0, "support": 105}, "temporal": {"precision": 0.06359649122807018, "recall": 0.07107843137254902, "f1-score": 0.06712962962962964, "support": 408}, "topic": {"precision": 0.0, "recall": 0.0, "f1-score": 0.0, "support": 170}, "type-of": {"precision": 0.0449438202247191, "recall": 0.011904761904761904, "f1-score": 0.018823529411764704, "support": 336}, "usage": {"precision": 0.0, "recall": 0.0, "f1-score": 0.0, "support": 200}, "win-defeat": {"precision": 0.026490066225165563, "recall": 0.025236593059936908, "f1-score": 0.025848142164781908, "support": 317}, "micro avg": {"precision": 0.12701892016612829, "recall": 0.12014404190309909, "f1-score": 0.12348586810228802, "support": 9164}, "macro avg": {"precision": 0.0588191025352987, "recall": 0.059084999185947513, "f1-score": 0.05740421155484869, "support": 9164}, "weighted avg": {"precision": 0.12203166721297021, "recall": 0.12014404190309909, "f1-score": 0.11887341906994976, "support": 9164}, "samples avg": {"precision": 0.12701892016612829, "recall": 0.1192124288570989, "f1-score": 0.12180818335640672, "support": 9164}}