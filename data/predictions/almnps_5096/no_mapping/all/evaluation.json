{"related-to": {"precision": 0.051233396584440226, "recall": 0.06521739130434782, "f1-score": 0.05738575982996812, "support": 414}, "artifact": {"precision": 0.05547850208044383, "recall": 0.06299212598425197, "f1-score": 0.058997050147492625, "support": 635}, "cause-effect": {"precision": 0.0, "recall": 0.0, "f1-score": 0.0, "support": 86}, "compare": {"precision": 0.0, "recall": 0.0, "f1-score": 0.0, "support": 82}, "general-affiliation": {"precision": 0.1426553672316384, "recall": 0.16303470540758677, "f1-score": 0.15216572504708095, "support": 1239}, "named": {"precision": 0.06481481481481481, "recall": 0.06272401433691756, "f1-score": 0.06375227686703096, "support": 558}, "opposite": {"precision": 0.024390243902439025, "recall": 0.0078125, "f1-score": 0.011834319526627219, "support": 128}, "origin": {"precision": 0.02717391304347826, "recall": 0.01644736842105263, "f1-score": 0.020491803278688523, "support": 304}, "part-of": {"precision": 0.07795698924731183, "recall": 0.12066574202496533, "f1-score": 0.09471965160587917, "support": 721}, "physical": {"precision": 0.1625821876867902, "recall": 0.18694158075601375, "f1-score": 0.17391304347826084, "support": 1455}, "role": {"precision": 0.2165991902834008, "recall": 0.1600199401794616, "f1-score": 0.18405963302752293, "support": 2006}, "social": {"precision": 0.017543859649122806, "recall": 0.009523809523809525, "f1-score": 0.01234567901234568, "support": 105}, "temporal": {"precision": 0.04904051172707889, "recall": 0.056372549019607844, "f1-score": 0.0524515393386545, "support": 408}, "topic": {"precision": 0.0, "recall": 0.0, "f1-score": 0.0, "support": 170}, "type-of": {"precision": 0.03333333333333333, "recall": 0.011904761904761904, "f1-score": 0.017543859649122806, "support": 336}, "usage": {"precision": 0.0, "recall": 0.0, "f1-score": 0.0, "support": 200}, "win-defeat": {"precision": 0.04861111111111111, "recall": 0.04416403785488959, "f1-score": 0.0462809917355372, "support": 317}, "micro avg": {"precision": 0.11905860636825104, "recall": 0.11261457878655609, "f1-score": 0.11574697173620459, "support": 9164}, "macro avg": {"precision": 0.05714196592325903, "recall": 0.05693061921868625, "f1-score": 0.055643607796718335, "support": 9164}, "weighted avg": {"precision": 0.11528386804545591, "recall": 0.11261457878655609, "f1-score": 0.11205745775045703, "support": 9164}, "samples avg": {"precision": 0.11905860636825104, "recall": 0.11132902630364559, "f1-score": 0.11388632518074142, "support": 9164}}