{"related-to": {"precision": 0.036011080332409975, "recall": 0.06280193236714976, "f1-score": 0.045774647887323945, "support": 414}, "artifact": {"precision": 0.06826801517067003, "recall": 0.08503937007874016, "f1-score": 0.07573632538569425, "support": 635}, "cause-effect": {"precision": 0.0, "recall": 0.0, "f1-score": 0.0, "support": 86}, "compare": {"precision": 0.0, "recall": 0.0, "f1-score": 0.0, "support": 82}, "general-affiliation": {"precision": 0.12538226299694188, "recall": 0.13236481033091202, "f1-score": 0.12877895563407932, "support": 1239}, "named": {"precision": 0.05647840531561462, "recall": 0.06093189964157706, "f1-score": 0.05862068965517242, "support": 558}, "opposite": {"precision": 0.0, "recall": 0.0, "f1-score": 0.0, "support": 128}, "origin": {"precision": 0.026143790849673203, "recall": 0.013157894736842105, "f1-score": 0.0175054704595186, "support": 304}, "part-of": {"precision": 0.07142857142857142, "recall": 0.06934812760055478, "f1-score": 0.07037297677691766, "support": 721}, "physical": {"precision": 0.16846105129829006, "recall": 0.18281786941580755, "f1-score": 0.17534607778510217, "support": 1455}, "role": {"precision": 0.2409297052154195, "recall": 0.211864406779661, "f1-score": 0.22546419098143236, "support": 2006}, "social": {"precision": 0.00909090909090909, "recall": 0.009523809523809525, "f1-score": 0.009302325581395349, "support": 105}, "temporal": {"precision": 0.036613272311212815, "recall": 0.0392156862745098, "f1-score": 0.0378698224852071, "support": 408}, "topic": {"precision": 0.03773584905660377, "recall": 0.011764705882352941, "f1-score": 0.017937219730941704, "support": 170}, "type-of": {"precision": 0.03676470588235294, "recall": 0.01488095238095238, "f1-score": 0.021186440677966104, "support": 336}, "usage": {"precision": 0.0, "recall": 0.0, "f1-score": 0.0, "support": 200}, "win-defeat": {"precision": 0.04597701149425287, "recall": 0.03785488958990536, "f1-score": 0.04152249134948097, "support": 317}, "micro avg": {"precision": 0.1221735117674204, "recall": 0.11556089044085552, "f1-score": 0.11877523553162854, "support": 9164}, "macro avg": {"precision": 0.05642850767311308, "recall": 0.054798020858986725, "f1-score": 0.05443633143471953, "support": 9164}, "weighted avg": {"precision": 0.11809487018191325, "recall": 0.11556089044085552, "f1-score": 0.11594710434365559, "support": 9164}, "samples avg": {"precision": 0.1221735117674204, "recall": 0.11519381633594832, "f1-score": 0.11752038147977233, "support": 9164}}