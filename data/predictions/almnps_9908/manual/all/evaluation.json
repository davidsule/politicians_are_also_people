{"related-to": {"precision": 0.058519793459552494, "recall": 0.0821256038647343, "f1-score": 0.06834170854271357, "support": 414}, "artifact": {"precision": 0.0625, "recall": 0.07401574803149606, "f1-score": 0.06777217015140591, "support": 635}, "cause-effect": {"precision": 0.0, "recall": 0.0, "f1-score": 0.0, "support": 86}, "compare": {"precision": 0.0, "recall": 0.0, "f1-score": 0.0, "support": 82}, "general-affiliation": {"precision": 0.13879485443466485, "recall": 0.16545601291364004, "f1-score": 0.15095729013254788, "support": 1239}, "named": {"precision": 0.07573415765069552, "recall": 0.08781362007168458, "f1-score": 0.08132780082987552, "support": 558}, "opposite": {"precision": 0.0, "recall": 0.0, "f1-score": 0.0, "support": 128}, "origin": {"precision": 0.05084745762711865, "recall": 0.039473684210526314, "f1-score": 0.044444444444444446, "support": 304}, "part-of": {"precision": 0.0798650168728909, "recall": 0.09847434119278779, "f1-score": 0.08819875776397515, "support": 721}, "physical": {"precision": 0.18851878100637845, "recall": 0.18281786941580755, "f1-score": 0.1856245638520586, "support": 1455}, "role": {"precision": 0.22642642642642644, "recall": 0.18793619142572282, "f1-score": 0.20539362571506403, "support": 2006}, "social": {"precision": 0.014084507042253521, "recall": 0.009523809523809525, "f1-score": 0.011363636363636364, "support": 105}, "temporal": {"precision": 0.04086021505376344, "recall": 0.04656862745098039, "f1-score": 0.04352806414662085, "support": 408}, "topic": {"precision": 0.0, "recall": 0.0, "f1-score": 0.0, "support": 170}, "type-of": {"precision": 0.05555555555555555, "recall": 0.020833333333333332, "f1-score": 0.030303030303030304, "support": 336}, "usage": {"precision": 0.0625, "recall": 0.005, "f1-score": 0.009259259259259259, "support": 200}, "win-defeat": {"precision": 0.036544850498338874, "recall": 0.03470031545741325, "f1-score": 0.03559870550161812, "support": 317}, "micro avg": {"precision": 0.12690355329949238, "recall": 0.12003491924923614, "f1-score": 0.12337371018393897, "support": 9164}, "macro avg": {"precision": 0.06416185974280227, "recall": 0.06086700922893741, "f1-score": 0.06012429747095588, "support": 9164}, "weighted avg": {"precision": 0.12446409280026137, "recall": 0.12003491924923614, "f1-score": 0.12060482883412381, "support": 9164}, "samples avg": {"precision": 0.12690355329949238, "recall": 0.12055837563451777, "f1-score": 0.12265420704507, "support": 9164}}