{"related-to": {"precision": 0.0594059405940594, "recall": 0.057971014492753624, "f1-score": 0.05867970660146699, "support": 414}, "artifact": {"precision": 0.0729483282674772, "recall": 0.07559055118110236, "f1-score": 0.074245939675174, "support": 635}, "cause-effect": {"precision": 0.0, "recall": 0.0, "f1-score": 0.0, "support": 86}, "compare": {"precision": 0.0, "recall": 0.0, "f1-score": 0.0, "support": 82}, "general-affiliation": {"precision": 0.14829396325459318, "recall": 0.1824051654560129, "f1-score": 0.163590300398118, "support": 1239}, "named": {"precision": 0.07308377896613191, "recall": 0.07347670250896057, "f1-score": 0.07327971403038427, "support": 558}, "opposite": {"precision": 0.02631578947368421, "recall": 0.0078125, "f1-score": 0.012048192771084338, "support": 128}, "origin": {"precision": 0.033783783783783786, "recall": 0.01644736842105263, "f1-score": 0.022123893805309738, "support": 304}, "part-of": {"precision": 0.09059633027522936, "recall": 0.10957004160887657, "f1-score": 0.09918392969240428, "support": 721}, "physical": {"precision": 0.16102236421725238, "recall": 0.1731958762886598, "f1-score": 0.16688741721854303, "support": 1455}, "role": {"precision": 0.23148148148148148, "recall": 0.22432701894317048, "f1-score": 0.2278481012658228, "support": 2006}, "social": {"precision": 0.0, "recall": 0.0, "f1-score": 0.0, "support": 105}, "temporal": {"precision": 0.033482142857142856, "recall": 0.03676470588235294, "f1-score": 0.035046728971962614, "support": 408}, "topic": {"precision": 0.1, "recall": 0.0058823529411764705, "f1-score": 0.011111111111111112, "support": 170}, "type-of": {"precision": 0.04032258064516129, "recall": 0.01488095238095238, "f1-score": 0.021739130434782608, "support": 336}, "usage": {"precision": 0.02857142857142857, "recall": 0.005, "f1-score": 0.00851063829787234, "support": 200}, "win-defeat": {"precision": 0.045774647887323945, "recall": 0.04100946372239748, "f1-score": 0.04326123128119801, "support": 317}, "micro avg": {"precision": 0.1339409321642824, "recall": 0.1266914011348756, "f1-score": 0.1302153432032301, "support": 9164}, "macro avg": {"precision": 0.06735779766322057, "recall": 0.06025492434279226, "f1-score": 0.059856237385602015, "support": 9164}, "weighted avg": {"precision": 0.12412322181445691, "recall": 0.1266914011348756, "f1-score": 0.12370037121913723, "support": 9164}, "samples avg": {"precision": 0.1339409321642824, "recall": 0.12532687278880172, "f1-score": 0.1281725888324873, "support": 9164}}