{"related-to": {"precision": 0.05597579425113464, "recall": 0.0893719806763285, "f1-score": 0.06883720930232556, "support": 414}, "artifact": {"precision": 0.06751054852320675, "recall": 0.07559055118110236, "f1-score": 0.07132243684992569, "support": 635}, "cause-effect": {"precision": 0.0, "recall": 0.0, "f1-score": 0.0, "support": 86}, "compare": {"precision": 0.0, "recall": 0.0, "f1-score": 0.0, "support": 82}, "general-affiliation": {"precision": 0.14233841684822077, "recall": 0.15819209039548024, "f1-score": 0.14984709480122324, "support": 1239}, "named": {"precision": 0.06553911205073996, "recall": 0.05555555555555555, "f1-score": 0.06013579049466538, "support": 558}, "opposite": {"precision": 0.024793388429752067, "recall": 0.0234375, "f1-score": 0.024096385542168676, "support": 128}, "origin": {"precision": 0.03286384976525822, "recall": 0.023026315789473683, "f1-score": 0.027079303675048353, "support": 304}, "part-of": {"precision": 0.07682619647355164, "recall": 0.08460471567267684, "f1-score": 0.08052805280528054, "support": 721}, "physical": {"precision": 0.19430992736077482, "recall": 0.22061855670103092, "f1-score": 0.20663018989378823, "support": 1455}, "role": {"precision": 0.22085889570552147, "recall": 0.1794616151545364, "f1-score": 0.19801980198019803, "support": 2006}, "social": {"precision": 0.008695652173913044, "recall": 0.009523809523809525, "f1-score": 0.009090909090909092, "support": 105}, "temporal": {"precision": 0.03665987780040733, "recall": 0.04411764705882353, "f1-score": 0.040044493882091206, "support": 408}, "topic": {"precision": 0.0, "recall": 0.0, "f1-score": 0.0, "support": 170}, "type-of": {"precision": 0.040983606557377046, "recall": 0.01488095238095238, "f1-score": 0.021834061135371178, "support": 336}, "usage": {"precision": 0.05555555555555555, "recall": 0.005, "f1-score": 0.009174311926605505, "support": 200}, "win-defeat": {"precision": 0.04247104247104247, "recall": 0.03470031545741325, "f1-score": 0.03819444444444444, "support": 317}, "micro avg": {"precision": 0.12690355329949238, "recall": 0.12003491924923614, "f1-score": 0.12337371018393897, "support": 9164}, "macro avg": {"precision": 0.06266952140979153, "recall": 0.059887153267481355, "f1-score": 0.05910791093082618, "support": 9164}, "weighted avg": {"precision": 0.12303647292997409, "recall": 0.12003491924923614, "f1-score": 0.11990702086279971, "support": 9164}, "samples avg": {"precision": 0.12690355329949238, "recall": 0.12055837563451777, "f1-score": 0.12265420704506998, "support": 9164}}