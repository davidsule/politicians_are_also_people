{"related-to": {"precision": 0.07272727272727272, "recall": 0.15873015873015872, "f1-score": 0.0997506234413965, "support": 126}, "artifact": {"precision": 0.024390243902439025, "recall": 0.030303030303030304, "f1-score": 0.027027027027027025, "support": 33}, "cause-effect": {"precision": 0.0, "recall": 0.0, "f1-score": 0.0, "support": 76}, "compare": {"precision": 0.0, "recall": 0.0, "f1-score": 0.0, "support": 39}, "general-affiliation": {"precision": 0.052083333333333336, "recall": 0.0684931506849315, "f1-score": 0.05917159763313609, "support": 73}, "named": {"precision": 0.061855670103092786, "recall": 0.1111111111111111, "f1-score": 0.07947019867549669, "support": 108}, "opposite": {"precision": 0.0, "recall": 0.0, "f1-score": 0.0, "support": 5}, "origin": {"precision": 0.06557377049180328, "recall": 0.0425531914893617, "f1-score": 0.05161290322580645, "support": 94}, "part-of": {"precision": 0.05181347150259067, "recall": 0.1111111111111111, "f1-score": 0.0706713780918728, "support": 90}, "physical": {"precision": 0.17592592592592593, "recall": 0.16964285714285715, "f1-score": 0.17272727272727273, "support": 224}, "role": {"precision": 0.2, "recall": 0.13636363636363635, "f1-score": 0.16216216216216214, "support": 286}, "social": {"precision": 0.0, "recall": 0.0, "f1-score": 0.0, "support": 14}, "temporal": {"precision": 0.043478260869565216, "recall": 0.038461538461538464, "f1-score": 0.04081632653061224, "support": 26}, "topic": {"precision": 0.0, "recall": 0.0, "f1-score": 0.0, "support": 66}, "type-of": {"precision": 0.045454545454545456, "recall": 0.017094017094017096, "f1-score": 0.024844720496894408, "support": 117}, "usage": {"precision": 0.0, "recall": 0.0, "f1-score": 0.0, "support": 24}, "win-defeat": {"precision": 0.02564102564102564, "recall": 0.022727272727272728, "f1-score": 0.024096385542168676, "support": 44}, "micro avg": {"precision": 0.09554597701149425, "recall": 0.09204152249134948, "f1-score": 0.09376101515685584, "support": 1445}, "macro avg": {"precision": 0.04817314823244672, "recall": 0.053328886777589776, "f1-score": 0.04778532915022622, "support": 1445}, "weighted avg": {"precision": 0.09374559592716258, "recall": 0.09204152249134948, "f1-score": 0.08835460254827006, "support": 1445}, "samples avg": {"precision": 0.09554597701149425, "recall": 0.08979885057471264, "f1-score": 0.09171455938697318, "support": 1445}}