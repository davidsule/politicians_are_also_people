{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "import math\n",
    "import word_dist_script as ws\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading finished\n"
     ]
    }
   ],
   "source": [
    "twitEmbs = ws.load_twitter_embs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_word2vec = False\n",
    "\n",
    "if load_word2vec:\n",
    "    word2vec = ws.load_word2vec_embs()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nicklas\\anaconda3\\envs\\syp\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "c:\\Users\\Nicklas\\anaconda3\\envs\\syp\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "every_emb = ws.get_every_embeddings(word2vec)\n",
    "\n",
    "clf = KMeans(n_clusters=5, random_state=0)\n",
    "\n",
    "clf.fit(every_emb)\n",
    "\n",
    "pred_emb = clf.predict(every_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nicklas\\anaconda3\\envs\\syp\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "every_dist = ws.get_every_distance(word2vec)\n",
    "\n",
    "clf = KMeans(n_clusters=5, random_state=0, n_init=1)\n",
    "\n",
    "clf.fit(every_dist)\n",
    "\n",
    "pred_dist = clf.predict(every_dist)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_dist = ws.sort_zip_labels(pred_dist)\n",
    "groups_dist = ws.group_by_cluster(sorted_dist)\n",
    "\n",
    "sorted_emb = ws.sort_zip_labels(pred_emb)\n",
    "groups_emb = ws.group_by_cluster(sorted_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ['journal', 'astronomer', 'book', 'magazine', 'researcher', 'scientist', 'theory', 'university', 'writer']\n",
      "1 ['album', 'band', 'genre', 'artist', 'instrument', 'poem', 'politics', 'politician', 'song']\n",
      "2 ['country', 'event', 'field', 'location', 'metrics', 'person', 'product', 'java', 'task']\n",
      "3 ['algorithm', 'chemical', 'enzyme', 'protein']\n",
      "4 ['award', 'conference', 'discipline', 'election', 'misc', 'Organisation']\n"
     ]
    }
   ],
   "source": [
    "for i, group in enumerate(groups_dist):\n",
    "    print(i, group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ['astronomer', 'researcher', 'scientist']\n",
      "1 ['algorithm', 'chemical', 'conference', 'country', 'discipline', 'election', 'event', 'field', 'location', 'metrics', 'instrument', 'Organisation', 'person', 'politics', 'politician', 'product', 'task', 'university']\n",
      "2 ['journal', 'album', 'award', 'band', 'book', 'genre', 'magazine', 'artist', 'poem', 'java', 'song', 'theory', 'writer']\n",
      "3 ['enzyme', 'protein']\n",
      "4 ['misc']\n"
     ]
    }
   ],
   "source": [
    "for i, group in enumerate(groups_emb):\n",
    "    print(i, group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "journal ['journal', 'astronomer', 'book', 'magazine', 'researcher', 'scientist', 'theory', 'university', 'writer']\n",
      "artist ['album', 'band', 'genre', 'artist', 'instrument', 'poem', 'politics', 'politician', 'song']\n",
      "location ['country', 'event', 'field', 'location', 'metrics', 'person', 'product', 'java', 'task']\n",
      "enzyme ['algorithm', 'chemical', 'enzyme', 'protein']\n",
      "conference ['award', 'conference', 'discipline', 'election', 'misc', 'Organisation']\n"
     ]
    }
   ],
   "source": [
    "for group in groups_dist:\n",
    "    ## find distance to centroid\n",
    "    label = ws.find_label_for_cluster(word2vec, group)\n",
    "    print(label, group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scientist ['astronomer', 'researcher', 'scientist']\n",
      "country ['algorithm', 'chemical', 'conference', 'country', 'discipline', 'election', 'event', 'field', 'location', 'metrics', 'instrument', 'Organisation', 'person', 'politics', 'politician', 'product', 'task', 'university']\n",
      "book ['journal', 'album', 'award', 'band', 'book', 'genre', 'magazine', 'artist', 'poem', 'java', 'song', 'theory', 'writer']\n",
      "enzyme ['enzyme', 'protein']\n",
      "misc ['misc']\n"
     ]
    }
   ],
   "source": [
    "for group in groups_emb:\n",
    "    ## find distance to centroid\n",
    "    label = ws.find_label_for_cluster_emb(word2vec, group)\n",
    "    print(label, group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('scientist', 0.9096941351890564)\n",
      "('By_Jonas_Elmerraji', 0.5770610570907593)\n",
      "('album', 0.7002332210540771)\n",
      "('enzyme', 0.9519215226173401)\n",
      "('misc', 1.0)\n"
     ]
    }
   ],
   "source": [
    "for group in groups_emb:\n",
    "    # find most similar word\n",
    "    centroid = ws.find_vector_for_cluster(word2vec, group)\n",
    "    most_sim = word2vec.most_similar(centroid)[0]\n",
    "    print(most_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity2cluster = dict()\n",
    "for i, pred in enumerate(pred_dist):\n",
    "    entity2cluster[ws.ENTITY_LABELS_SPLIT[i]] = pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster2label = dict()\n",
    "for i, group in enumerate(groups_dist):\n",
    "    label = ws.find_label_for_cluster_emb(word2vec, group)\n",
    "    cluster2label[i] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = ['journal', 'journal','journal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapped = map(lambda entity: entity2cluster[entity], example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/manual_groups.csv')\n",
    "entities = df[\"entity_name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_problematic_words(word2vec_model, entities):\n",
    "    PROBLEMATIC_WORDS = []\n",
    "    for entity in entities:\n",
    "        try:\n",
    "            word2vec_model[entity]\n",
    "        except:\n",
    "            PROBLEMATIC_WORDS.append(entity)\n",
    "    return PROBLEMATIC_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['musicalartist',\n",
       " 'organisation',\n",
       " 'politicalparty',\n",
       " 'academicjournal',\n",
       " 'chemicalcompound',\n",
       " 'chemicalelement',\n",
       " 'astronomicalobject',\n",
       " 'musicgenre',\n",
       " 'literarygenre',\n",
       " 'programlang',\n",
       " 'musicalinstrument']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_problematic_words(word2vec_model=word2vec, entities=entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem2work = {\"musicalartist\": \"artist\", \"organisation\": \"Organisation\", \"politicalparty\": \"politics\", \"academicjournal\": \"journal\", \"chemicalcompound\": \"chemical\", \"chemicalelement\": \"chemical\", \"astronomicalobject\": \"astronomer\", \"musicgenre\": \"genre\", \"literarygenre\": \"genre\", \"programlang\": \"java\", \"musicalinstrument\": \"instrument\"  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entity2label(entities):\n",
    "    return map(lambda entity: cluster2label[entity2cluster[entity]], entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "working = entities.map(lambda entity: problem2work[entity] if entity in problem2work else entity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'party'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[77], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mlist\u001b[39;49m(entity2label(working))\n",
      "Cell \u001b[1;32mIn[74], line 2\u001b[0m, in \u001b[0;36mentity2label.<locals>.<lambda>\u001b[1;34m(entity)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mentity2label\u001b[39m(entities):\n\u001b[1;32m----> 2\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mmap\u001b[39m(\u001b[39mlambda\u001b[39;00m entity: cluster2label[entity2cluster[entity]], entities)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'party'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "syp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
