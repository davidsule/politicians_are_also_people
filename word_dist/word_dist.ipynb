{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "import math\n",
    "import word_dist_script as ws\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading finished\n"
     ]
    }
   ],
   "source": [
    "twitEmbs = ws.load_twitter_embs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading word2vec model...\n",
      "This can take several minutes...\n"
     ]
    }
   ],
   "source": [
    "load_word2vec = True\n",
    "\n",
    "if load_word2vec:\n",
    "    word2vec = ws.load_word2vec_embs()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nicklas\\anaconda3\\envs\\syp\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "c:\\Users\\Nicklas\\anaconda3\\envs\\syp\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "every_emb = ws.get_every_embeddings(word2vec)\n",
    "\n",
    "clf = KMeans(n_clusters=5, random_state=0)\n",
    "\n",
    "clf.fit(every_emb)\n",
    "\n",
    "pred_emb = clf.predict(every_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nicklas\\anaconda3\\envs\\syp\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "every_dist = ws.get_every_distance(word2vec)\n",
    "import random\n",
    "random.seed(0)\n",
    "clf = KMeans(n_clusters=5, random_state=0, n_init=1)\n",
    "\n",
    "clf.fit(every_dist)\n",
    "\n",
    "pred_dist = clf.predict(every_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_dist = ws.sort_zip_labels(pred_dist)\n",
    "groups_dist = ws.group_by_cluster(sorted_dist)\n",
    "\n",
    "sorted_emb = ws.sort_zip_labels(pred_emb)\n",
    "groups_emb = ws.group_by_cluster(sorted_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ['journal', 'astronomer', 'book', 'magazine', 'researcher', 'scientist', 'theory', 'university', 'writer']\n",
      "1 ['album', 'band', 'genre', 'artist', 'instrument', 'poem', 'politics', 'politician', 'song']\n",
      "2 ['country', 'event', 'field', 'location', 'metrics', 'person', 'product', 'java', 'task']\n",
      "3 ['algorithm', 'chemical', 'enzyme', 'protein']\n",
      "4 ['award', 'conference', 'discipline', 'election', 'misc', 'Organisation']\n"
     ]
    }
   ],
   "source": [
    "for i, group in enumerate(groups_dist):\n",
    "    print(i, group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ['astronomer', 'researcher', 'scientist']\n",
      "1 ['algorithm', 'chemical', 'conference', 'country', 'discipline', 'election', 'event', 'field', 'location', 'metrics', 'instrument', 'Organisation', 'person', 'politics', 'politician', 'product', 'task', 'university']\n",
      "2 ['journal', 'album', 'award', 'band', 'book', 'genre', 'magazine', 'artist', 'poem', 'java', 'song', 'theory', 'writer']\n",
      "3 ['enzyme', 'protein']\n",
      "4 ['misc']\n"
     ]
    }
   ],
   "source": [
    "for i, group in enumerate(groups_emb):\n",
    "    print(i, group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "journal ['journal', 'astronomer', 'book', 'magazine', 'researcher', 'scientist', 'theory', 'university', 'writer']\n",
      "artist ['album', 'band', 'genre', 'artist', 'instrument', 'poem', 'politics', 'politician', 'song']\n",
      "location ['country', 'event', 'field', 'location', 'metrics', 'person', 'product', 'java', 'task']\n",
      "enzyme ['algorithm', 'chemical', 'enzyme', 'protein']\n",
      "conference ['award', 'conference', 'discipline', 'election', 'misc', 'Organisation']\n"
     ]
    }
   ],
   "source": [
    "for group in groups_dist:\n",
    "    ## find distance to centroid\n",
    "    label = ws.find_label_for_cluster(word2vec, group)\n",
    "    print(label, group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scientist ['astronomer', 'researcher', 'scientist']\n",
      "country ['algorithm', 'chemical', 'conference', 'country', 'discipline', 'election', 'event', 'field', 'location', 'metrics', 'instrument', 'Organisation', 'person', 'politics', 'politician', 'product', 'task', 'university']\n",
      "book ['journal', 'album', 'award', 'band', 'book', 'genre', 'magazine', 'artist', 'poem', 'java', 'song', 'theory', 'writer']\n",
      "enzyme ['enzyme', 'protein']\n",
      "misc ['misc']\n"
     ]
    }
   ],
   "source": [
    "for group in groups_emb:\n",
    "    ## find distance to centroid\n",
    "    label = ws.find_label_for_cluster_emb(word2vec, group)\n",
    "    print(label, group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('scientist', 0.9096941351890564)\n",
      "('By_Jonas_Elmerraji', 0.5770610570907593)\n",
      "('album', 0.7002332210540771)\n",
      "('enzyme', 0.9519215226173401)\n",
      "('misc', 1.0)\n"
     ]
    }
   ],
   "source": [
    "for group in groups_emb:\n",
    "    # find most similar word\n",
    "    centroid = ws.find_vector_for_cluster(word2vec, group)\n",
    "    most_sim = word2vec.most_similar(centroid)[0]\n",
    "    print(most_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity2cluster_dist = ws.create_entity2cluster_dict(pred_dist)\n",
    "entity2cluster_emb = ws.create_entity2cluster_dict(pred_emb)\n",
    "\n",
    "cluster2label_dist = ws.create_cluster2label_dict(word2vec, pred_dist)\n",
    "cluster2label_emb = ws.create_cluster2label_dict(word2vec, pred_emb)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load csv\n",
    "df = pd.read_csv('../data/manual_groups.csv')\n",
    "## get entity names\n",
    "entities = df[\"entity_name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_problematic_words(word2vec_model, entities):\n",
    "    PROBLEMATIC_WORDS = []\n",
    "    for entity in entities:\n",
    "        try:\n",
    "            word2vec_model[entity]\n",
    "        except:\n",
    "            PROBLEMATIC_WORDS.append(entity)\n",
    "    return PROBLEMATIC_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## find the problematic words\n",
    "problem_words = find_problematic_words(word2vec_model=word2vec, entities=entities)\n",
    "problem2work = {\"musicalartist\": \"artist\", \"organisation\": \"Organisation\", \"politicalparty\": \"politics\", \"academicjournal\": \"journal\", \"chemicalcompound\": \"chemical\", \"chemicalelement\": \"chemical\", \"astronomicalobject\": \"astronomer\", \"musicgenre\": \"genre\", \"literarygenre\": \"genre\", \"programlang\": \"java\", \"musicalinstrument\": \"instrument\"  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## map the problematic entities to working ones\n",
    "working = entities.map(lambda entity: problem2work[entity] if entity in problem2work else entity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## map the words to their cluster(word) label\n",
    "mapped_words_dist = working.map(lambda entity: cluster2label_dist[entity2cluster_dist[entity]])\n",
    "mapped_words_emb = working.map(lambda entity: cluster2label_emb[entity2cluster_emb[entity]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## add the new columns to the dataframe\n",
    "df[\"label_word_dist\"] = mapped_words_dist\n",
    "df[\"label_word_emb\"] = mapped_words_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## write to csv\n",
    "df.to_csv('../data/manual_groups.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_list = [\"jounal\", \"journal\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = pd.read_csv(\"../data/manual_groups.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'organisation'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file[\"label_ours\"][\"politicalparty\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['politician',\n",
       " 'person',\n",
       " 'writer',\n",
       " 'researcher',\n",
       " 'scientist',\n",
       " 'musicalartist',\n",
       " 'organisation',\n",
       " 'politicalparty',\n",
       " 'university',\n",
       " 'band',\n",
       " 'country',\n",
       " 'location',\n",
       " 'event',\n",
       " 'election',\n",
       " 'award',\n",
       " 'conference',\n",
       " 'album',\n",
       " 'song',\n",
       " 'academicjournal',\n",
       " 'poem',\n",
       " 'magazine',\n",
       " 'book',\n",
       " 'metrics',\n",
       " 'enzyme',\n",
       " 'protein',\n",
       " 'chemicalcompound',\n",
       " 'chemicalelement',\n",
       " 'astronomicalobject',\n",
       " 'theory',\n",
       " 'musicgenre',\n",
       " 'field',\n",
       " 'discipline',\n",
       " 'algorithm',\n",
       " 'literarygenre',\n",
       " 'product',\n",
       " 'programlang',\n",
       " 'misc',\n",
       " 'musicalinstrument',\n",
       " 'task']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_to_map = file.index.tolist()\n",
    "list_to_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_use = file[\"label_ours\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<map at 0x178b7248a60>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(lambda entity: df_to_use[entity], list_to_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "syp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
